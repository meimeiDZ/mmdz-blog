# MySQL



### 数据库范式

> 在实际开发中最为常见的设计范式有三个：
>
> 1. 第一范式(确保每列保持原子性)
>
> 2. 第二范式(在第一范式的基础上，非主键列完全依赖于主键，而不能是依赖于主键的一部分)
>
> 3. 第三范式(在第二范式的基础上，非主键列只依赖于主键，不依赖于其他非主键)
>

------



### MySQL 基础架构

> 简单来说 MySQL 主要分为 **Server 层和存储引擎层**：
>
> - **Server 层**：主要包括**连接器、查询缓存、分析器、优化器、执行器**等，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图，函数等，还有一个通用的日志模块 binlog 日志模块。
> - **存储引擎**： 主要负责数据的存储和读取，采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory 等多个存储引擎，其中 InnoDB 引擎有自有的日志模块 redolog 模块。**现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5 版本开始就被当做默认存储引擎了。**
>
> ![](mysql/13526879-3037b144ed09eb88.png)
>
> 从上图可以看出， MySQL 主要由下面几部分构成：
>
> - **连接器：** 身份认证和权限相关(登录 MySQL 的时候)。
> - **查询缓存：** 执行查询语句的时候，会先查询缓存（MySQL 8.0 版本后移除，因为这个功能不太实用）。
> - **分析器：** 没有命中缓存的话，SQL 语句就会经过分析器，分析器说白了就是要先看你的 SQL 语句要干嘛，再检查你的 SQL 语句语法是否正确。
> - **优化器：** 按照 MySQL 认为最优的方案去执行。
> - **执行器：** 执行语句，然后从存储引擎返回数据。 执行语句之前会先判断是否有权限，如果没有权限的话，就会报错。
> - **插件式存储引擎** ： 主要负责数据的存储和读取，采用的是插件式架构，支持 InnoDB、MyISAM、Memory 等多种存储引擎。

------



### MySQL 索引



### MySQL 日志

> [!Tip]
>
> **binlog、redolog、undolog 作用和区别**

> `MySQL` 日志 主要包括错误日志、查询日志、慢查询日志、事务日志、二进制日志几大类。其中，比较重要的还要属二进制日志 `binlog`（归档日志）和事务日志 `redo log`（重做日志）和 `undo log`（回滚日志）。
>
> - **binlog**
>
>   `binlog` 是逻辑日志，记录内容是语句的原始逻辑，类似于“给 ID=2 这一行的 c 字段加 1”，属于`MySQL Server` 层。
>
>   不管用什么存储引擎，只要发生了表数据更新，都会产生 `binlog` 日志。
>
>   那 `binlog` 到底是用来干嘛的？
>
>   可以说`MySQL`数据库的**数据备份、主备、主主、主从**都离不开`binlog`，需要依靠`binlog`来同步数据，保证数据一致性。
>
> - **redolog**
>
>   `redo log`（重做日志）是`InnoDB`存储引擎独有的，它让`MySQL`拥有了崩溃恢复能力。
>
>   比如 `MySQL` 实例挂了或宕机了，重启时，`InnoDB`存储引擎会使用`redo log`恢复数据，保证数据的持久性与完整性。
>
> - **undolog**
>
>   我们知道如果想要保证事务的原子性，就需要在异常发生时，对已经执行的操作进行**回滚**，在 MySQL 中，恢复机制是通过 **回滚日志（undo log）** 实现的，所有事务进行的修改都会先记录到这个回滚日志中，然后再执行相关的操作。



> [!Tip]
>
> **为什么要刷盘到redolog而不直接写入磁盘**

> redo log 的作用就像是在记账时的临时小账本，先临时记录某人的账目变化情况，在之后将这个变化记录到真正的账本中。如此一来当需要记账的人很多时可以提高效率（比从账本中查找某人再记录效率高）。
>
> 在 MySQL 中，如果没有 redo log 更新语句成本最高的地方就是每次都要从表中找到对应数据行并对其修改，这一次次的磁盘 IO 操作是最耗时的，因此 redo log 的出现提高了效率，因为有大量更新语句时不会一次次操作磁盘写入表中，而是将这些操作临时记录在 redo log 中，在空闲时执行一次磁盘 IO 操作写入表中。

------



### MySQL 事务

> [!Tip]
>
> **MySQL 事务隔离级别**

> SQL 标准定义了四个隔离级别：
>
> - **READ-UNCOMMITTED(读取未提交)** ：最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
> - **READ-COMMITTED(读取已提交)** ：允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
> - **REPEATABLE-READ(可重复读)** ：对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
> - **SERIALIZABLE(可串行化)** ：最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。
>
> |     隔离级别     | 脏读 | 不可重复读 | 幻读 |
> | :--------------: | :--: | :--------: | :--: |
> | READ-UNCOMMITTED |  √   |     √      |  √   |
> |  READ-COMMITTED  |  ×   |     √      |  √   |
> | REPEATABLE-READ  |  ×   |     ×      |  √   |
> |   SERIALIZABLE   |  ×   |     ×      |  ×   |







### MySQL 锁

### MySQL MVCC

### MySQL 性能优化⭐







## MySQL 存储引擎

### MySQL存储引擎MyISAM与InnoDB区别⭐

> - Innodb引擎：Innodb引擎提供了对数据库ACID事务的支持。并且还提供了行级锁和外键的约束。它的设计的目标就是处理大数据容量的数据库系统。
> - MyIASM引擎(原本Mysql的默认引擎)：不提供事务的支持，也不支持行级锁和外键。

### MyISAM索引与InnoDB索引的区别？

> - InnoDB索引是聚簇索引，MyISAM索引是非聚簇索引。
> - InnoDB的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
> - MyISAM索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。
> - InnoDB非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会非常高效。



### 索引的优缺点

> **优点** ：
>
> - 使用索引可以大大加快 数据的检索速度（大大减少检索的数据量）, 这也是创建索引的最主要的原因。
> - 通过创建唯一性索引，可以保证数据库表中每一行数据的唯一性。
>
> **缺点** ：
>
> - 创建索引和维护索引需要耗费许多时间。
> - 当对表中有索引的数据进行增删改的时候，那么索引也需要动态的修改，会降低 SQL 执行效率。
> - 索引需要使用物理文件存储，也会耗费一定空间。
>
> 但是，**使用索引一定能提高查询性能吗?**
>
> 大多数情况下，索引查询都是比全表扫描要快的。但是如果数据库的数据量不大，那么使用索引也不一定能够带来很大提升。

### 索引的数据结构

> - **Hash 表**
>
>   哈希表是键值对的集合，通过键(key)即可快速取出对应的值(value)，因此哈希表可以快速检索数据（接近 O（1））。
>
>   **为何能够通过 key 快速取出 value 呢？** 原因在于 **哈希算法**（也叫散列算法）。通过哈希算法，我们可以快速找到 key 对应的 index，找到了 index 也就找到了对应的 value。
>
> - **B 树& B+树**
>
>   B 树也称 B-树,全称为 **多路平衡查找树** ，B+ 树是 B 树的一种变体。B 树和 B+树中的 B 是 `Balanced` （平衡）的意思。
>
>   目前大部分数据库系统及文件系统都采用 B-Tree 或其变种 B+Tree 作为索引结构。
>
>   **B 树& B+树两者有何异同呢？**
>
>   - B 树的所有节点既存放键(key) 也存放 数据(data)，而 B+树只有叶子节点存放 key 和 data，其他内节点只存放 key。
>   - B 树的叶子节点都是独立的;B+树的叶子节点有一条引用链指向与它相邻的叶子节点。
>   - B 树的检索的过程相当于对范围内的每个节点的关键字做二分查找，可能还没有到达叶子节点，检索就结束了。而 B+树的检索效率就很稳定了，任何查找都是从根节点到叶子节点的过程，叶子节点的顺序检索很明显。

### MySQL索引底层是什么？为什么采用B+树？

> 1. B+树能显著减少IO次数，提高效率
> 2. B+树的查询效率更加稳定，因为数据放在叶子节点
> 3. B+树能提高范围查询的效率，因为叶子节点指向下一个叶子节点

### 索引类型

> `主键索引(Primary Key)`
>
> 数据表的主键列使用的就是主键索引。
>
> 一张数据表有只能有一个主键，并且主键不能为 null，不能重复。
>
> 在 MySQL 的 InnoDB 的表中，当没有显示的指定表的主键时，InnoDB 会自动先检查表中是否有唯一索引且不允许存在 null 值的字段，如果有，则选择该字段为默认的主键，否则 InnoDB 将会自动创建一个 6Byte 的自增主键。
>
> ![img](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/cluster-index.png)
>
> `二级索引(辅助索引)`
>
> **二级索引又称为辅助索引，是因为二级索引的叶子节点存储的数据是主键。也就是说，通过二级索引，可以定位主键的位置。**
>
> 唯一索引，普通索引，前缀索引等索引属于二级索引。
>
> PS: 不懂的同学可以暂存疑，慢慢往下看，后面会有答案的，也可以自行搜索。
>
> 1. **唯一索引(Unique Key)** ：唯一索引也是一种约束。**唯一索引的属性列不能出现重复的数据，但是允许数据为 NULL，一张表允许创建多个唯一索引。** 建立唯一索引的目的大部分时候都是为了该属性列的数据的唯一性，而不是为了查询效率。
> 2. **普通索引(Index)** ：**普通索引的唯一作用就是为了快速查询数据，一张表允许创建多个普通索引，并允许数据重复和 NULL。**
> 3. **前缀索引(Prefix)** ：前缀索引只适用于字符串类型的数据。前缀索引是对文本的前几个字符创建索引，相比普通索引建立的数据更小， 因为只取前几个字符。
> 4. **全文索引(Full Text)** ：全文索引主要是为了检索大文本数据中的关键字的信息，是目前搜索引擎数据库使用的一种技术。Mysql5.6 之前只有 MYISAM 引擎支持全文索引，5.6 之后 InnoDB 也支持了全文索引。
>
> 二级索引:
>
> ![img](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/no-cluster-index.png)

### 聚簇索引与非聚簇索引

> - 聚簇索引（聚集索引）
>
>   聚簇索引即索引和数据一起存放的索引，找到了索引就找到了需要的数据。InnoDB 中的主键索引就属于聚簇索引。
>
>   **优点** ：
>
>   - **查询速度非常快** ：因为整个 B+树本身就是一颗多叉平衡树，叶子节点也都是有序的，定位到索引的节点，就相当于定位到了数据。
>   - **对排序查找和范围查找优化** ：因为叶子节点指向下一个叶子节点，聚簇索引对于主键的排序查找和范围查找速度非常快。
>
>   **缺点** ：
>
>   - **依赖于有序的数据** ：因为 B+树是多路平衡树，如果索引的数据不是有序的，那么就需要在插入时排序，如果数据是整型还好，否则类似于字符串或 UUID 这种又长又难比较的数据，插入或查找的速度肯定比较慢。
>   - **更新代价大** ： 如果对索引列的数据被修改时，那么对应的索引也将会被修改，而且聚簇索引的叶子节点还存放着数据，修改代价肯定是较大的，所以对于主键索引来说，主键一般都是不可被修改的。
>
> - 非聚簇索引
>
>   索引的存储和数据的存储是分离的，也就是说找到了索引但没找到数据，需要根据索引上的值(主键)再次回表查询,非聚簇索引也叫做辅助索引。
>
>   **优点** ：
>
>   - 更新代价比聚簇索引要小 。非聚簇索引的更新代价就没有聚簇索引那么大了，非聚簇索引的叶子节点是不存放数据的
>
>
>   **缺点** ：
>
>   - **依赖于有序的数据** ：跟聚簇索引一样，非聚簇索引也依赖于有序的数据
>   - **可能会二次查询(回表)** ：这应该是非聚簇索引最大的缺点了。 当查到索引对应的指针或主键后，可能还需要根据指针或主键再到数据文件或表中查询。
>
> !>`注意：`澄清一个概念：innodb中，在聚簇索引之上创建的索引称之为辅助索引，辅助索引访问数据总是需要二次查找，非聚簇索引都是辅助索引，像复合索引、前缀索引、唯一索引，辅助索引叶子节点存储的不再是行的物理位置，而是主键值

### 非聚簇索引一定会回表查询吗？

> 不一定，索引包含所有需要查询的字段的值，那么就不必再进行回表查询。
>
> 举个简单的例子，假设我们在员工表的年龄上建立了索引，那么当进行select age from employee where age < 20的查询时，在索引的叶子节点上，已经包含了age信息，不会再次进行回表查询。

### 覆盖索引和联合索引

> - `联合索引`
>
>   **使用表中的多个字段创建索引**，就是 **联合索引**，也叫 **组合索引** 或 **复合索引**。比如index(a,b)就是将a,b两个列组合起来构成一个索引。
>
>   如果是index(a,b)在索引构建上，包含了两个意思：
>
>   1、先把各个记录按照 a 列进行排序。
>
>   2、在记录的 a 列相同的情况下，采用b列进行排序
>
>   从原理可知，为什么有最佳左前缀法则，就是这个道理
>
> - `覆盖索引`
>
>   如果一个索引包含（或者说覆盖）所有需要查询的字段的值，我们就称之为“覆盖索引”。**覆盖索引即需要查询的字段正好是索引的字段，那么直接根据该索引，就可以查到数据了，而无需回表查询。**
>
>   可以减少大量的IO操作。

### 最左前缀匹配原则

> 最左前缀匹配原则指的是，在使用联合索引时，**MySQL** 会根据联合索引中的字段顺序，从左到右依次到查询条件中去匹配，如果查询条件中存在与联合索引中最左侧字段相匹配的字段，则就会使用该字段过滤一批数据，直至联合索引中全部字段匹配完成，或者在执行过程中遇到范围查询，如 **`>`**、**`<`**、**`between`** 和 **`以%开头的like查询`** 等条件，才会停止匹配。
>
> 所以，我们在使用联合索引时，可以将区分度高的字段放在最左边，这也可以过滤更多数据。

### 索引下推

> **索引下推（Index Condition Pushdown）** 是 **MySQL 5.6** 版本中提供的一项索引优化功能，可以在非聚簇索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数。

### 索引失效

> 索引失效也是慢查询的主要原因之一，常见的导致索引失效的情况有下面这些：
>
> - 使用 `SELECT *` 进行查询;
>
> - **创建了组合索引，但查询条件未准守最左匹配原则；（跨列或无序使用）**
>
> - **不要在索引上进行任何操作;（在索引列上进行计算、函数、类型转换等操作）**
>
> - **以 % 开头的 LIKE 查询比如 `like '%abc';`;**
>
> - **查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;**
>
> - **复合索引不能使用不等于（!= <>）或 is null (is not null)，否则自身以及右侧所有全部失效**
>
> - 尽量不要使用类型转换（显示、隐式），否则索引失效
>
>   ```sql
>   explain select * from teacher where tname = 'abc' ;
>   
>   -- 程序底层将 123 -> '123'，即进行了类型转换，因此索引失效
>   explain select * from teacher where tname = 123 ;
>   ```

## 锁机制⭐

> 基于锁的属性分类：**共享锁**、**排他锁**。
>
> 基于锁的粒度分类：**行级锁**（innodb ）、**表级锁**（ innodb 、myisam）、**页级锁**（ innodb引擎）、**记录锁**、**间隙锁**、**临键锁**。
>
> 基于锁的状态分类：**意向共享锁**、**意向排它锁**。 

### 锁的属性分类(共享锁和排他锁)

> 不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类：
>
> - **共享锁（S 锁）** ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。共享锁的特性主要是为了支持并发的读取数据，读取数据的时候不支持修改，避免出现重复读的问题。
> - **排他锁（X 锁）** ：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。
>
> ```sql
> # 共享锁
> SELECT ... LOCK IN SHARE MODE;
> # 排他锁
> SELECT ... FOR UPDATE;
> ```

### 锁的粒度分类

> - **行级锁**：MySQL中锁定粒度最细的一种锁，表示只针对当前操作的行进行加锁。行级锁能大大减少数据库操作的冲突。其加锁粒度最小，但加锁的开销也最大。行级锁分为共享锁和排他锁。
>
>   特点：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。
>
> - **表级锁**：MySQL中锁定粒度最大的一种锁，表示对当前操作的整张表加锁，它实现简单，资源消耗较少，被大部分MySQL引擎支持。最常使用的MyISAM与InnoDB都支持表级锁定。表级锁定分为表共享读锁(共享锁)与表独占写锁(排他锁)。
>
>   特点：开销小，加锁快；不会出现死锁；锁定粒度大，发出锁冲突的概率最高，并发度最低。
>
> - **页级锁**：是MySQL中锁定粒度介于行级锁和表级锁中间的一种锁。表级锁速度快，但冲突多，行级冲突少，但速度慢。所以取了折衷的页级，一次锁定相邻的一组记录。
>
>   特点：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般
>
> - InnoDB 行锁是通过对索引数据页上的记录加锁实现的，MySQL InnoDB 支持三种行锁定方式：
>
>   - **记录锁（Record Lock）** ：记录锁也属于行锁中的一种，只不过记录**锁的范围只是表中的某一条记录**，记录锁是说事务在加锁后锁住的只是表的某一条记录，加了记录锁之后数据可以避免数据在查询的时候被修改的重复读问题，也避免了在修改的事务未提交前被其他事务读取的脏读问题
>
>     记录锁是 **封锁记录，记录锁也叫行锁**，例如：
>
>     ```sql
>     SELECT * FROM `test` WHERE `id`=1 FOR UPDATE;
>     ```
>
>     它会在 id=1 的记录上加上记录锁，以阻止其他事务插入，更新，删除 id=1 这一行。
>
>   - **间隙锁（Gap Lock）** ：锁定一个范围，不包括记录本身。
>
>     当我们采用范围条件查询数据时，InnoDB 会对这个范围内的数据进行加锁。比如有 id 为：1、3、5、7 的 4 条数据，我们查找 1-7 范围的数据。那么 1-7 都会被加上锁。2、4、6 也在 1-7 的范围中，但是不存在这些数据记录，这些 2、4、6 就被称为间隙。
>
>   - **临键锁（Next-Key Lock）** ：也属于行锁的一种，并且它是INNODB的行锁默认算法，总结来说它就是记录锁和间隙锁的组合，临键锁会把查询出来的记录锁住，同时也会把该范围查询内的所有间隙空间也会锁住，再之它会把相邻的下一个区间也会锁住。
>
>   **在 InnoDB 默认的隔离级别 REPEATABLE-READ 下，行锁默认使用的是 Next-Key Lock。但是，如果操作的索引是唯一索引或主键，InnoDB 会对 Next-Key Lock 进行优化，将其降级为 Record Lock，即仅锁住索引本身，而不是范围。**
>
>   ?>**了解**：一些大厂面试中可能会问到 Next-Key Lock 的加锁范围，这里推荐一篇文章：[MySQL next-key lock 加锁范围是什么？ - 程序员小航 - 2021open in new window](https://segmentfault.com/a/1190000040129107)

### 行级锁的使用有什么注意事项？

> InnoDB 的行锁是针对索引字段加的锁，表级锁是针对非索引字段加的锁。当我们执行 `UPDATE`、`DELETE` 语句时，如果 `WHERE`条件中字段没有命中唯一索引或者索引失效的话，就会导致扫描全表对表中的所有行记录进行加锁。这个在我们日常工作开发中经常会遇到，一定要多多注意！！！
>
> 不过，很多时候即使用了索引也有可能会走全表扫描，这是因为 MySQL 优化器的原因。

### 锁的状态分类(意向锁)

> 如果需要用到表锁的话，如何判断表中的记录没有行锁呢，一行一行遍历肯定是不行，性能太差。我们需要用到一个叫做意向锁的东东来快速判断是否可以对某个表使用表锁。
>
> 需要强调一下，意向锁是一种`不与行级锁冲突表级锁`，这一点非常重要。意向锁分为两种：
>
> - **意向共享锁**（intention shared lock, IS）：事务有意向对表中的某些行加**共享锁**（S锁）
>
> ```text
> -- 事务要获取某些行的 S 锁，必须先获得表的 IS 锁。
> SELECT column FROM table ... LOCK IN SHARE MODE;
> ```
>
> - **意向排他锁**（intention exclusive lock, IX）：事务有意向对表中的某些行加**排他锁**（X锁）
>
> ```sql
> -- 事务要获取某些行的 X 锁，必须先获得表的 IX 锁。
> SELECT column FROM table ... FOR UPDATE;
> ```
>
> 即：`意向锁是有数据引擎自己维护的，用户无法手动操作意向锁`，在为数据行加共享 / 排他锁之前，InooDB 会先获取该数据行所在在数据表的对应意向锁。

### 当前读和快照读有什么区别？

> - **当前读**
>
>   顾名思义，就是读取当前版本的数据。
>
>   当前读包含的 SQL 语句如下：
>
>   1. update , delete , insert
>   2. select......for update
>   3. select......lock in share mode
>
>   当前读, 对读取的记录加锁, 阻塞其他事务同时改动相同记录，避免出现安全问题。
>
>   这里有个例子：
>
>   假设要 update 一条记录，但另一个事务已经delete这条数据且commit了，如果不加锁就会产生冲突。所以update的时候肯定要是当前读，得到最新的信息并且锁定相应的记录。
>
>   当前读的实现方式是 next-key锁，即行记录锁+Gap间隙锁。至于到底是用记录锁，还是Gap间隙锁，得看索引命中情况
>
> - **快照读**
>
>   同样顾名思义，就是读取快照的数据，这个快照一般指的是历史快照。
>
>   快照读包含的 SQL 语句为简单的 select 语句，就是不包含 ...for update, ...lock in share mode 关键字的。
>
>   因为查询不涉及数据的更新，一般查询只关注当前时机的历史快照数据，不像update那样更新数据是要最新版本才行。所以快照读能够在一定程度上提升 Mysql 的并发性能。
>
>   快照读的实现方式：undolog和MVCC。由于篇幅原因，这里不做介绍。

### 什么是死锁？怎么解决？⭐

> 死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方的资源，从而导致恶性循环的现象。
>
> **常见的解决死锁的方法**
>
> 1、如果不同程序会并发存取多个表，尽量约定以相同的顺序访问表，可以大大降低死锁机会。
>
> 2、在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；
>
> 3、对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率；
>
> 如果业务处理不好可以用分布式事务锁或者使用乐观锁

### Mysql 的乐观锁和悲观锁

> - **乐观锁**
>
>   乐观锁一般来说有以下2种方式：
>
>   1. 使用**数据版本（Version）**记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。
>   2. **使用时间戳（timestamp）**。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。
>
> - **悲观锁**
>
>   ```sql
>   SELECT ... LOCK IN SHARE MODE
>   SELECT ... FOR UPDATE
>   ```

## 事务特性、隔离级别、数据安全⭐

### 事务特性

> - **原子性**： 事务是最小的执行单位，不允许分割。事务的原子性确保动作要么全部完成，要么完全不起作用；
> - **一致性**： 执行事务前后，数据保持一致，多个事务对同一个数据读取的结果是相同的；
> - **隔离性**： 并发访问数据库时，一个用户的事务不被其他事务所干扰，各并发事务之间数据库是独立的；
> - **持久性**： 一个事务被提交之后。它对数据库中数据的改变是持久的，即使数据库发生故障也不应该对其有任何影响。
>
> ![](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/ACID.png)

### 并发事务带来了哪些问题?

> - `脏读（Dirty read）`
>
>   一个事务读取数据并且对数据进行了修改，这个修改对其他事务来说是可见的，即使当前事务没有提交。这时另外一个事务读取了这个还未提交的数据，但第一个事务突然回滚，导致数据并没有被提交到数据库，那第二个事务读取到的就是脏数据，这也就是脏读的由来。
>
>   例如：事务 1 读取某表中的数据 A=20，事务 1 修改 A=A-1，事务 2 读取到 A = 19,事务 1 回滚导致对 A 的修改并为提交到数据库， A 的值还是 20。
>
>   ![](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/concurrency-consistency-issues-dirty-reading.ee15b0b9.png)
>
> - `不可重复读（Unrepeatable read）`
>
>   指在一个事务内多次读同一数据。在这个事务还没有结束时，另一个事务也访问该数据。那么，在第一个事务中的两次读数据之间，由于第二个事务的修改导致第一个事务两次读取的数据可能不太一样。这就发生了在一个事务内两次读到的数据是不一样的情况，因此称为不可重复读。
>
>   例如：事务 1 读取某表中的数据 A=20，事务 2 也读取 A=20，事务 1 修改 A=A-1，事务 2 再次读取 A =19，此时读取的结果和第一次读取的结果不同。
>
>   ![](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/concurrency-consistency-issues-unrepeatable-read.ff9186e1.png)
>
>   `幻读（Phantom read）`
>
>   幻读与不可重复读类似。它发生在一个事务读取了几行数据，接着另一个并发事务插入了一些数据时。在随后的查询中，第一个事务就会发现多了一些原本不存在的记录，就好像发生了幻觉一样，所以称为幻读。
>
>   例如：事务 2 读取某个范围的数据，事务 1 在这个范围插入了新的数据，事务 2 再次读取这个范围的数据发现相比于第一次读取的结果多了新的数据。
>
>   ![](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/concurrency-consistency-issues-phantom-read.7cba7a85.png)

### 事务隔离级别总结⭐

> SQL 标准定义了四个隔离级别：
>
> - **READ-UNCOMMITTED(读取未提交)** ： 最低的隔离级别，允许读取尚未提交的数据变更，可能会导致脏读、幻读或不可重复读。
>
> - **READ-COMMITTED(读取已提交)** ： 允许读取并发事务已经提交的数据，可以阻止脏读，但是幻读或不可重复读仍有可能发生。
>
> - **REPEATABLE-READ(可重复读)** ： 对同一字段的多次读取结果都是一致的，除非数据是被本身事务自己所修改，可以阻止脏读和不可重复读，但幻读仍有可能发生。
>
> - **SERIALIZABLE(可串行化)** ： 最高的隔离级别，完全服从 ACID 的隔离级别。所有的事务依次逐个执行，这样事务之间就完全不可能产生干扰，也就是说，该级别可以防止脏读、不可重复读以及幻读。
>
>   |     隔离级别     | 脏读 | 不可重复读 | 幻读 |
>   | :--------------: | :--: | :--------: | :--: |
>   | READ-UNCOMMITTED |  √   |     √      |  √   |
>   |  READ-COMMITTED  |  ×   |     √      |  √   |
>   | REPEATABLE-READ  |  ×   |     ×      |  √   |
>   |   SERIALIZABLE   |  ×   |     ×      |  ×   |
>
> `这里需要注意的是`：Mysql 默认采用的 REPEATABLE_READ隔离级别 Oracle 默认采用的 READ_COMMITTED隔离级别

### 并发事务的控制方式有哪些？

> MySQL 中并发事务的控制方式无非就两种：**锁** 和 **MVCC**。锁可以看作是**悲观控制的模式**，**多版本并发控制**（MVCC，Multiversion concurrency control）可以看作是**乐观控制的模式**。
>
> **锁** 控制方式下会通过锁来显示控制共享资源而不是通过调度手段，MySQL 中主要是通过 **读写锁** 来实现并发控制。
>
> - **共享锁（S 锁）** ：又称读锁，事务在读取记录的时候获取共享锁，允许多个事务同时获取（锁兼容）。
> - **排他锁（X 锁）** ：又称写锁/独占锁，事务在修改记录的时候获取排他锁，不允许多个事务同时获取。如果一个记录已经被加了排他锁，那其他事务不能再对这条事务加任何类型的锁（锁不兼容）。
>
> 读写锁可以做到读读并行，但是无法做到写读、写写并行。另外，根据根据锁粒度的不同，又被分为 **表级锁(table-level locking)** 和 **行级锁(row-level locking)** 。InnoDB 不光支持表级锁，还支持行级锁，默认为行级锁。行级锁的粒度更小，仅对相关的记录上锁即可（对一行或者多行记录加锁），所以对于并发写入操作来说， InnoDB 的性能更高。不论是表级锁还是行级锁，都存在共享锁（Share Lock，S 锁）和排他锁（Exclusive Lock，X 锁）这两类。
>
> **MVCC** 是多版本并发控制方法，即对一份数据会存储多个版本，通过事务的可见性来保证事务能看到自己应该看到的版本。通常会有一个全局的版本分配器来为每一行数据设置版本号，版本号是唯一的。
>
> MVCC 在 MySQL 中实现所依赖的手段主要是: **隐藏字段、read view、undo log**。
>
> - undo log : undo log 用于记录某行数据的多个版本的数据。
> - read view 和 隐藏字段 : 用来判断当前版本数据的可见性。

### MySQL 的隔离级别是基于锁实现的吗？

> MySQL 的隔离级别基于锁和 MVCC 机制共同实现的。
>
> SERIALIZABLE 隔离级别是通过锁来实现的，READ-COMMITTED 和 REPEATABLE-READ 隔离级别是基于 MVCC 实现的。不过， SERIALIZABLE 之外的其他隔离级别可能也需要用到锁机制，就比如 REPEATABLE-READ 在当前读情况下需要使用加锁读来保证不会出现幻读。

## MVCC⭐⭐

### InnoDB 对 MVCC 的实现

> `MVCC` 的实现依赖于：**隐藏字段、Read View、undo log**。在内部实现中，`InnoDB` 通过数据行的 `DB_TRX_ID` 和 `Read View` 来判断数据的可见性，如不可见，则通过数据行的 `DB_ROLL_PTR` 找到 `undo log` 中的历史版本。每个事务读到的数据版本可能是不一样的，在同一个事务中，用户只能看到该事务创建 `Read View` 之前已经提交的修改和该事务本身做的修改

### 隐藏字段

> 在内部，`InnoDB` 存储引擎为每行数据添加了三个 **隐藏字段**：
>
> - `DB_TRX_ID（6字节）`：表示最后一次插入或更新该行的事务 id。此外，`delete` 操作在内部被视为更新，只不过会在记录头 `Record header` 中的 `deleted_flag` 字段将其标记为已删除
> - `DB_ROLL_PTR（7字节）` 回滚指针，指向该行的 `undo log` 。如果该行未被更新，则为空
> - `DB_ROW_ID（6字节）`：如果没有设置主键且该表没有唯一非空索引时，`InnoDB` 会使用该 id 来生成聚簇索引

### Read View

> - **Read View是什么呢？** 它就是事务执行SQL语句时，产生的读视图。实际上在innodb中，每个SQL语句执行前都会得到一个Read View。
> - **Read View有什么用呢？** 它主要是用来做可见性判断的，即判断当前事务可见哪个版本的数据~
>
> Read View是如何保证可见性判断的呢？我们先看看Read view 的几个重要属性
>
> - m_ids:当前系统中那些活跃(未提交)的读写事务ID, 它数据结构为一个List。
> - min_limit_id:表示在生成ReadView时，当前系统中活跃的读写事务中最小的事务id，即m_ids中的最小值。
> - max_limit_id:表示生成ReadView时，系统中应该分配给下一个事务的id值。
> - creator_trx_id: 创建当前read view的事务ID
>
> ![](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/trans_visible.048192c5.png)

### undo-log

> undo log，**回滚日志**，用于记录数据被修改前的信息。在表记录修改之前，会先把数据拷贝到undo log里，如果事务回滚，即可以通过undo log来还原数据。
>
> 可以这样认为，当delete一条记录时，undo log 中会记录一条对应的insert记录，当update一条记录时，它记录一条对应相反的update记录。
>
> `undo log` 主要有两个作用：
>
> - 当事务回滚时用于将数据恢复到修改前的样子
> - 另一个作用是 `MVCC` ，当读取记录时，若该记录被其他事务占用或当前版本对该事务不可见，则可以通过 `undo log` 读取之前的版本数据，以此实现非锁定读
>
> **不同事务或者相同事务的对同一记录行的修改，会使该记录行的 `undo log` 成为一条链表，链首就是最新的记录，链尾就是最早的旧记录。**
>
> ![](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/85471f9eaddf4d42a51259b6878056ed.png)

### MVCC实现原理

### RC 和 RR 隔离级别下 MVCC 的差异

> 在事务隔离级别 `RC` 和 `RR` （InnoDB 存储引擎的默认事务隔离级别）下，`InnoDB` 存储引擎使用 `MVCC`（非锁定一致性读），但它们生成 `Read View` 的时机却不同
>
> - 在 RC 隔离级别下的 **`每次select`** 查询前都生成一个`Read View` (m_ids 列表)
> - 在 RR 隔离级别下只在事务开始后 **`第一次select`** 数据前生成一个`Read View`（m_ids 列表）

### READ COMMITTED

> ?>**在 RC 隔离级别下的 `每次select` 查询前都生成一个`Read View` (m_ids 列表)**
>
> - 脏读问题的解决
>
> - 不能避免不可重复读现象
>
>   同一个事务里面，**每一次查询都会产生一个新的Read View副本**，这样就可能造成同一个事务里前后读取数据可能不一致的问题（不可重复读并发问题）。

### REPEATABLE READ

> - 解决不可重复读问题
>
>   在可重复读（RR）隔离级别下，**一个事务里只会获取一次read view**，都是副本共用的，从而保证每次查询的数据都是一样的。
>
> - MVCC 并不能完全禁止幻读（**就是第一次读如果是空的情况，且在自己事务中进行了该条数据的修改**）。

## sql优化

### 日常工作中你是怎么优化SQL的？⭐

> sql 优化可以从 硬件、系统配置、数据库表结构、SQL及索引 这几个方面优化（然而实际上我们只能决定 数据库表结构、SQL及索引 的优化，有可能 数据库表结构 我们也没权限）
>
> - 优化成本：硬件>系统配置>数据库表结构>SQL及索引。
> - 优化效果：硬件<系统配置<数据库表结构<SQL及索引。
>
> 从数据库查询数据需要注意额地方蛮多的，其中很多都是平时积累来的：
>
> **可以从优化表结构、优化索引、优化sql这三个方向优化sql：**
>
> 1. **优化表结构**
>
>    首先你要对该表结构熟悉，同时对该业务也明白，从而避免修改表结构影响到其它的业务正常运行。
>
>    主要优化的是 设置合理的字段类型，尽量让 字段存储空间小，可以节省存储空间，减少磁盘IO
>
>    例如：
>
>    - 尽量使用数字型字段
>
>      尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。
>      这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。
>
>    - 用varchar/nvarchar 代替 char/nchar
>
>      尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。
>      不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。
>
> 2. **优化索引**
>
>    - `选择合适的字段创建索引`
>
>      - **非空字段**：应该指定列为NOT NULL，除非你想存储NULL。在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；
>      - **取值离散大的字段**：（变量各个取值之间的差异程度）的列放到联合索引的前面，可以通过count()函数查看字段的差异值，返回值越大说明字段的唯一值越多字段的离散程度高；
>      - **索引字段越小越好**：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。
>      - **被频繁查询的字段** ：我们创建索引的字段应该是查询操作非常频繁的字段。
>      - **被作为条件查询的字段** ：被作为 WHERE 条件查询的字段，应该被考虑建立索引。
>      - **频繁需要排序的字段** ：索引已经排序，这样查询可以利用索引的排序，加快排序查询时间。
>      - **被经常频繁用于连接的字段** ：经常用于连接的字段可能是一些外键列，对于外键列并不一定要建立外键，只是说该列涉及到表与表的关系。对于频繁被连接查询的字段，可以考虑建立索引，提高多表连接查询的效率。
>
>    - `被频繁更新的字段应该慎重建立索引`
>
>      **虽然索引能带来查询上的效率，但是维护索引的成本也是不小的**。 如果一个字段不被经常查询，反而被经常修改，那么就更不应该在这种字段上建立索引了。
>
>    - `尽可能的考虑建立联合索引而不是单列索引`
>
>      因为索引是需要占用磁盘空间的，可以简单理解为每个索引都对应着一颗 B+树。如果一个表的字段过多，索引过多，那么当这个表的数据达到一个体量后，索引占用的空间也是很多的，且修改索引时，耗费的时间也是较多的。如果是联合索引，多个字段在一个索引上，那么将会节约很大磁盘空间，且修改数据的操作效率也会提升。
>
>    - `注意避免冗余索引`
>
>      冗余索引指的是索引的功能相同，能够命中索引(a, b)就肯定能命中索引(a) ，那么索引(a)就是冗余索引。如（name,city ）和（name ）这两个索引就是冗余索引，能够命中前者的查询肯定是能够命中后者的 在大多数情况下，都应该尽量扩展已有的索引而不是创建新索引。
>
>    - `虑在字符串类型的字段上使用前缀索引代替普通索引`
>
>      前缀索引仅限于字符串类型，较普通索引会占用更小的空间，所以可以考虑使用前缀索引带替普通索引。
>
> 3. **优化sql**
>
>    1. 返回更少的数据
>
>       只返回需要的字段和数据分页处理 减少磁盘io及网络io
>
>    2. 减少交互次数
>
>       批量DML操作，函数存储等减少数据连接次数
>
>    3. 通过索引访问（尽可能的不让索引失效）
>
>       - 使用 `SELECT *` 进行查询;
>       - **创建组合索引，但查询条件未准守最左匹配原则；（跨列或无序使用）**
>       - **不要在索引上进行任何操作;（在索引列上进行计算、函数、类型转换等操作）**
>       - **查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;**
>       - **复合索引不能使用不等于（!= <>）或 is null (is not null)，否则自身以及右侧所有全部失效**
>       - 尽量不要使用类型转换（显示、隐式），否则索引失效
>       - **以 % 开头的 LIKE 查询比如 `like '%abc';`;**
>
> 通过 explain 命令来查看 SQL 的执行计划，看看自己写的 SQL 是否走索引，走什么索引。

### 怎么看执行计划（explain），如何理解其中各个字段的含义？⭐

> 在 select 语句之前增加 explain 关键字，会返回执行计划的信息。
>
> ![图片](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/640sadsadsa.png)
>
> 1. **id**
>
>    SELECT 标识符，是查询中 SELECT 的序号，用来标识整个查询中 SELELCT 语句的顺序。
>
>    id 如果相同，从上往下依次执行。id 不同，id 值越大，执行优先级越高，如果行引用其他行的并集结果，则该值可以为 NULL。
>
> 2. **select_type**
>
>    查询的类型，主要用于区分普通查询、联合查询、子查询等复杂的查询，常见的值有：
>
>    - **SIMPLE**：简单查询，不包含 UNION 或者子查询。
>    - **PRIMARY**：查询中如果包含子查询或其他部分，外层的 SELECT 将被标记为 PRIMARY。
>    - **SUBQUERY**：子查询中的第一个 SELECT。
>    - **UNION**：在 UNION 语句中，UNION 之后出现的 SELECT。
>    - **DERIVED**：在 FROM 中出现的子查询将被标记为 DERIVED。
>    - **UNION RESULT**：UNION 查询的结果。
>
> 3. **table**
>
>    查询用到的表名，每行都有对应的表名，表名除了正常的表之外，也可能是以下列出的值：
>
>    - **`<unionM,N>`** : 本行引用了 id 为 M 和 N 的行的 UNION 结果；
>    - **`<derivedN>`** : 本行引用了 id 为 N 的表所产生的的派生表结果。派生表有可能产生自 FROM 语句中的子查询。 -**`<subqueryN>`** : 本行引用了 id 为 N 的表所产生的的物化子查询结果。
>
> 4. **type（重要）**
>
>    查询执行的类型，描述了查询是如何执行的。所有值的顺序从最优到最差排序为：system > const > eq_ref > ref > fulltext > ref_or_null > index_merge > unique_subquery > index_subquery > range > index > ALL
>
>    常见的几种类型具体含义如下：
>
>    - **system**：如果表使用的引擎对于表行数统计是精确的（如：MyISAM），且表中只有一行记录的情况下，访问方法是 system ，是 const 的一种特例。
>    - **const**：表中最多只有一行匹配的记录，一次查询就可以找到，常用于使用主键或唯一索引的所有字段作为查询条件。
>    - **eq_ref**：当连表查询时，前一张表的行在当前这张表中只有一行与之对应。是除了 system 与 const 之外最好的 join 方式，常用于使用主键或唯一索引的所有字段作为连表条件。
>    - **ref**：使用普通索引作为查询条件，查询结果可能找到多个符合条件的行。
>    - **index_merge**：当查询条件使用了多个索引时，表示开启了 Index Merge 优化，此时执行计划中的 key 列列出了使用到的索引。
>    - **range**：对索引列进行范围查询，执行计划中的 key 列表示哪个索引被使用了。
>    - **index**：查询遍历了整棵索引树，与 ALL 类似，只不过扫描的是索引，而索引一般在内存中，速度更快。
>    - **ALL**：全表扫描。
>
> 5. possible_keys
>
>    possible_keys 列表示 MySQL 执行查询时可能用到的索引。如果这一列为 NULL ，则表示没有可能用到的索引；这种情况下，需要检查 WHERE 语句中所使用的的列，看是否可以通过给这些列中某个或多个添加索引的方法来提高查询性能。
>
> 6. **key（重要）**
>
>    key 列表示 MySQL 实际使用到的索引。如果为 NULL，则表示未用到索引。
>
> 7. **key_len**
>
>    key_len 列表示 MySQL 实际使用的索引的最大长度；当使用到联合索引时，有可能是多个列的长度和。在满足需求的前提下越短越好。如果 key 列显示 NULL ，则 key_len 列也显示 NULL 。
>
> 8. **rows**
>
>    rows 列表示根据表统计信息及选用情况，大致估算出找到所需的记录或所需读取的行数，数值越小越好。
>
> 9. **Extra（重要）**
>
>    这列包含了 MySQL 解析查询的额外信息，通过这些信息，可以更准确的理解 MySQL 到底是如何执行查询的。常见的值如下：
>
>    - **Using filesort**：在排序时使用了外部的索引排序，没有用到表内索引进行排序。
>    - **Using temporary**：MySQL 需要创建临时表来存储查询的结果，常见于 ORDER BY 和 GROUP BY。
>    - **Using index**：表明查询使用了覆盖索引，不用回表，查询效率非常高。
>    - **Using index condition**：表示查询优化器选择使用了索引条件下推这个特性。
>    - **Using where**：表明查询使用了 WHERE 子句进行条件过滤。一般在没有使用到索引的时候会出现。
>    - **Using join buffer (Block Nested Loop)**：连表查询的方式，表示当被驱动表的没有使用索引的时候，MySQL 会先将驱动表读出来放到 join buffer 中，再遍历被驱动表与驱动表进行查询。

### 关心过业务系统里面的sql耗时吗？统计过慢查询吗？对慢查询都怎么优化过？⭐

> 我们平时写Sql时，都要养成用explain分析的习惯。慢查询的统计，运维会定期统计给我们（或者开启慢查询日志slow_query_log）
>
> 优化慢查询思路：
>
> - 分析语句，是否加载了不必要的字段/数据
> - 分析 SQL 执行句话，是否命中索引等
> - 如果 SQL 很复杂，优化 SQL 结构
> - 如果表数据量太大，考虑分表

### Mysql 数据库 cpu 飙升到 100% 的化怎么处理

> 当 cpu 飙升到 100% 时，先用操作系统命令 top 命令观察是不是 mysqld 占用导致的；
>
> 如果不是，找出占用高的进程，并进行相关处理；
>
> 如果是 mysqld 造成的，使用 show processlist（**show processlist 是显示用户正在运行的线程，需要注意的是，除了 root 用户能看到所有正在运行的线程外，其他用户都只能看到自己正在运行的线程，看不到其它用户正在运行的线程。除非单独个这个用户赋予了PROCESS 权限**。） 进行排查，看看里面跑的 session 情况，是不是有消耗资源的 sql 在运行。找出消耗高的 sql，看看执行计划是否准确，index 是否缺失或者失效，或者是数据量太大造成的；
>
> 一般来说，肯定要 kill 掉这个线程（同时观察这个 cpu 使用率是否下降），等进行相应的调整（比如 加索引、改 sql、改 内存参数）之后，再重新跑 sql
>
> 也有可能是每个 sql 消耗的资源不多，但是突然之间，有大量的 session 连进来导致的 cpu 飙升，这种情况就需要跟应用一起分析为何连接数会激增，再做出相应的调整，比如说现在连接数等。

## 集群

### 什么是mysql的主从复制？

​		MySQL 主从复制是指数据可以从一个MySQL数据库服务器主节点复制到一个或多个从节点。MySQL 默认采用异步复制方式，这样从节点不用一直访问主服务器来更新自己的数据，数据的更新可以在远程连接上进行，从节点可以复制主数据库中的所有数据库或者特定的数据库，或者特定的表。

### mysql为什么需要主从同步？

1、在业务复杂的系统中，有这么一个情景，有一句sql语句需要锁表，导致暂时不能使用读的服务，那么就很影响运行中的业务，使用主从复制，让主库负责写，从库负责读，这样，即使主库出现了锁表的情景，通过读从库也可以保证业务的正常运作。

2、做数据的热备

3、架构的扩展。业务量越来越大，I/O访问频率过高，单机无法满足，此时做多库的存储，降低磁盘I/O访问的频率，提高单个机器的I/O性能。

### mysql复制原理是什么？

​		（1）master服务器将数据的改变记录二进制binlog日志，当master上的数据发生改变时，则将其改变写入二进制日志中；		

​		（2）slave服务器会在一定时间间隔内对master二进制日志进行探测其是否发生改变，如果发生改变，则开始一个I/OThread请求master二进制事件

​		（3）同时主节点为每个I/O线程启动一个dump线程，用于向其发送二进制事件，并保存至从节点本地的中继日志中，从节点将启动SQL线程从中继日志中读取二进制日志，在本地重放，使得其数据和主节点的保持一致，最后I/OThread和SQLThread将进入睡眠状态，等待下一次被唤醒。

也就是说：

- 从库会生成两个线程,一个I/O线程,一个SQL线程;
- I/O线程会去请求主库的binlog,并将得到的binlog写到本地的relay-log(中继日志)文件中;
- 主库会生成一个log dump线程,用来给从库I/O线程传binlog;
- SQL线程,会读取relay log文件中的日志,并解析成sql语句逐一执行;

注意：

1--master将操作语句记录到binlog日志中，然后授予slave远程连接的权限（master一定要开启binlog二进制日志功能；通常为了数据安全考虑，slave也开启binlog功能）。
2--slave开启两个线程：IO线程和SQL线程。其中：IO线程负责读取master的binlog内容到中继日志relay log里；SQL线程负责从relay log日志里读出binlog内容，并更新到slave的数据库里，这样就能保证slave数据和master数据保持一致了。
3--Mysql复制至少需要两个Mysql的服务，当然Mysql服务可以分布在不同的服务器上，也可以在一台服务器上启动多个服务。
4--Mysql复制最好确保master和slave服务器上的Mysql版本相同（如果不能满足版本一致，那么要保证master主节点的版本低于slave从节点的版本）
5--master和slave两节点间时间需同步

![](D:/mmdz-blog/docs/其他/Interview/mysql_imgs/主从原理.png)

具体步骤：

1、从库通过手工执行change  master to 语句连接主库，提供了连接的用户一切条件（user 、password、port、ip），并且让从库知道，二进制日志的起点位置（file名 position 号）；    start  slave

2、从库的IO线程和主库的dump线程建立连接。

3、从库根据change  master  to 语句提供的file名和position号，IO线程向主库发起binlog的请求。

4、主库dump线程根据从库的请求，将本地binlog以events的方式发给从库IO线程。

5、从库IO线程接收binlog  events，并存放到本地relay-log中，传送过来的信息，会记录到master.info中

6、从库SQL线程应用relay-log，并且把应用过的记录到relay-log.info中，默认情况下，已经应用过的relay 会自动被清理purge

------





# 《对线面试官》 MySQL 索引

**面试官**：**我看你简历上写了MySQL，对MySQL InnoDB引擎的索引了解吗？**

> **候选者**：嗯啊，使用索引可以加快查询速度，其实上就是将无序的数据变成有序（有序就能加快检索速度）
>
> **候选者**：在InnoDB引擎中，索引的底层数据结构是B+树

**面试官**：**那为什么不使用红黑树或者B树呢？**

> **候选者**：MySQL的数据是存储在硬盘的，在查询时一般是不能「一次性」把全部数据加载到内存中
>
> **候选者**：红黑树是「二叉查找树」的变种，一个Node节点只能存储一个Key和一个Value
>
> **候选者**：B和B+树跟红黑树不一样，它们算是「多路搜索树」，相较于「二叉搜索树」而言，一个Node节点可以存储的信息会更多，「多路搜索树」的高度会比「二叉搜索树」更低。
>
> **候选者**：了解了区别之后，其实就很容易发现，在数据不能一次加载至内存的场景下，数据需要被检索出来，选择B或B+树的理由就很充分了（一个Node节点存储信息更多（相较于二叉搜索树），树的高度更低，树的高度影响检索的速度）
>
> **候选者**：B+树相对于B树而言，它又有两种特性。
>
> **候选者**：一、B+树非叶子节点不存储数据，在相同的数据量下，B+树更加矮壮。（这个应该不用多解释了，数据都存储在叶子节点上，非叶子节点的存储能存储更多的索引，所以整棵树就更加矮壮）
>
> **候选者**：二、B+树叶子节点之间组成一个链表，方便于遍历查询（遍历操作在MySQL中比较常见）
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbicmaLKV1XausXay56RtYQOpm2ic2Gd9hgwkCRTwd2ACtlRqu3uS23JkW4rHJEAiaawd8qFOZTniaUqQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：我稍微解释一下吧，你可以脑补下画面
>
> **候选者**：我们在MySQL InnoDB引擎下，每创建一个索引，相当于生成了一颗B+树。
>
> **候选者**：如果该索引是「聚集(聚簇)索引」，那当前B+树的叶子节点存储着「主键和当前行的数据」
>
> **候选者**：如果该索引是「非聚簇索引」，那当前B+树的叶子节点存储着「主键和当前索引列值」
>
> **候选者**：比如写了一句sql：select * from user where id >=10，那只要定位到id为10的记录，然后在叶子节点之间通过遍历链表(叶子节点组成的链表)，即可找到往后的记录了。
>
> **候选者**：由于B树是会在非叶子节点也存储数据，要遍历的时候可能就得跨层检索，相对麻烦些。
>
> **候选者**：基于树的层级以及业务使用场景的特性，所以MySQL选择了B+树作为索引的底层数据结构。
>
> **候选者**：对于哈希结构，其实InnoDB引擎是「自适应」哈希索引的（hash索引的创建由InnoDB存储引擎引擎自动优化创建，我们是干预不了）

**面试官**：嗯…**那我了解了，顺便想问下，你知道什么叫做回表吗？**

> **候选者**：所谓的回表其实就是，当我们使用索引查询数据时，检索出来的数据可能包含其他列，但走的索引树叶子节点只能查到当前列值以及主键ID，所以需要根据主键ID再去查一遍数据，得到SQL 所需的列
>
> **候选者**：举个例子，我这边建了给订单号ID建了个索引，但我的SQL 是：select orderId,orderName from orderdetail where orderId = 123
>
> **候选者**：SQL都订单ID索引，但在订单ID的索引树的叶子节点只有orderId和Id，而我们还想检索出orderName，所以MySQL 会拿到ID再去查出orderName给我们返回，这种操作就叫回表
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbicmaLKV1XausXay56RtYQOdym1gY4RCuOY8djlNsc8icbzQwZuPvqbQiciaTb43f0Jic8VFC0m6Z4I0g/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：想要避免回表，也可以使用覆盖索引（能使用就使用，因为避免了回表操作）。
>
> **候选者**：所谓的覆盖索引，实际上就是你想要查出的列刚好在叶子节点上都存在，比如我建了orderId和orderName联合索引，刚好我需要查询也是orderId和orderName，这些数据都存在索引树的叶子节点上，就不需要回表操作了。

**面试官**：**既然你也提到了联合索引，我想问下你了解最左匹配原则吗？**

> **候选者**：嗯，说明这个概念，还是举例子比较容易说明
>
> **候选者**：如有索引 (a,b,c,d)，查询条件 a=1 and b=2 and c>3 and d=4，则会在每个节点依次命中a、b、c，无法命中d
>
> **候选者**：先匹配最左边的，索引只能用于查找key是否存在（相等），遇到范围查询 (>、<、between、like左匹配)等就不能进一步匹配了，后续退化为线性查找
>
> **候选者**：这就是最左匹配原则
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbicmaLKV1XausXay56RtYQOhtwEXwIaj9TkwEFOtzHE4wfyiaRoYsXV4q2SCuo7OFwvqLbiaKxcT4WQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**面试官**：**嗯嗯，我还想问下你们主键是怎么生成的？**

**候选者**：主键就自增的

**面试官**：**那假设我不用MySQL自增的主键，你觉得会有什么问题呢？**

> **候选者**：首先主键得保证它的唯一性和空间尽可能短吧，这两块是需要考虑的。
>
> **候选者**：另外，由于索引的特性（有序），如果生成像uuid类似的主键，那插入的的性能是比自增的要差的
>
> **候选者**：因为生成的uuid，在插入时有可能需要移动磁盘块（比如，块内的空间在当前时刻已经存储满了，但新生成的uuid需要插入已满的块内，就需要移动块的数据）

**面试官**：OK…

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbicmaLKV1XausXay56RtYQOVCd2ZV0cUVToEhxgqichPwjhKTaLVNapdlWWYc5ABOibHVTnSfBibZRGQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

------

# 《对线面试官》 MySQL 事务、锁和MVCC

**面试官**：**你是怎么理解InnoDB引擎中的事务的？**

> **候选者**：在我的理解下，事务可以使「一组操作」要么全部成功，要么全部失败
>
> **候选者**：事务其目的是为了「保证数据最终的一致性」。
>
> **候选者**：举个例子，我给你发支付宝转了888块红包。那自然我的支付宝余额会扣减888块，你的支付宝余额会增加888块。
>
> **候选者**：而事务就是保证我的余额扣减跟你的余额增添是同时成功或者同时失败的，这样这次转账就正常了
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkAKxJTaBtVe32xiaymVw7CicBdluWTibIas5LQJBLTygC7Js99TQ5Ot40w/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**面试官**：**嗯，那你了解事务的几大特性吗？**

> **候选者**：嗯，就是ACID嘛，分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。
>
> **候选者**：原子性指的是：当前事务的操作要么同时成功，要么同时失败。原子性由undo log日志来保证，因为undo log记载着数据修改前的信息。
>
> **候选者**：比如我们要 insert 一条数据了，那undo log 会记录的一条对应的 delete 日志。我们要 update 一条记录时，那undo log会记录之前的「旧值」的update记录。
>
> **候选者**：如果执行事务过程中出现异常的情况，那执行「回滚」。InnoDB引擎就是利用undo log记录下的数据，来将数据「恢复」到事务开始之前
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkE8pqn1s3E9Nqboh0Xib3JiaPzgKgC2Ixsasvgfr23DTxF4QbLld1iaNrg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：一致性我稍稍往后讲，我先来说下隔离性
>
> **面试官**：嗯…
>
> **候选者**：隔离性指的是：在事务「并发」执行时，他们内部的操作不能互相干扰。如果多个事务可以同时操作一个数据，那么就会产生脏读、重复读、幻读的问题。
>
> **候选者**：于是，事务与事务之间需要存在「一定」的隔离。在InnoDB引擎中，定义了四种隔离级别供我们使用：
>
> **候选者**：分别是：read uncommit(读未提交)、read commit (读已提交)、repeatable read (可重复复读)、serializable (串行)
>
> **候选者**：不同的隔离级别对事务之间的隔离性是不一样的（级别越高事务隔离性越好，但性能就越低），而隔离性是由MySQL的各种锁来实现的，只是它屏蔽了加锁的细节。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkIG6KWgbuVZbp7natNMTI3cqVtZL81micdZsJDBANGgCtaJniaRS8kzpA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：持久性指的就是：一旦提交了事务，它对数据库的改变就应该是永久性的。说白了就是，会将数据持久化在硬盘上。
>
> **候选者**：而持久性由redo log 日志来保证，当我们要修改数据时，MySQL是先把这条记录所在的「页」找到，然后把该页加载到内存中，将对应记录进行修改。
>
> **候选者**：为了防止内存修改完了，MySQL就挂掉了（如果内存改完，直接挂掉，那这次的修改相当于就丢失了）。
>
> **候选者**：MySQL引入了redo log，内存写完了，然后会写一份redo log，这份redo log记载着这次在某个页上做了什么修改。
>
> **候选者**：即便MySQL在中途挂了，我们还可以根据redo log来对数据进行恢复。
>
> **候选者**：redo log 是顺序写的，写入速度很快。并且它记录的是物理修改（xxxx页做了xxx修改），文件的体积很小，恢复速度也很快。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkAnSl1ahVTEJY1DficWiay2jZlunDPBUPaNwpuwq5dNico1X1IyjIMvlTg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：回头再来讲一致性，「一致性」可以理解为我们使用事务的「目的」，而「隔离性」「原子性」「持久性」均是为了保障「一致性」的手段，保证一致性需要由应用程序代码来保证
>
> **候选者**：比如，如果事务在发生的过程中，出现了异常情况，此时你就得回滚事务，而不是强行提交事务来导致数据不一致。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkABXmN47ySQxgF0ReESdl5KuQE4GRreYRebJqoOVzKibrvPlAtvBicia5A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**面试官**：嗯，挺好的，讲了蛮多的

**面试官**：刚才你也提到了隔离性嘛，**然后你说在MySQL中有四种隔离级别，能分别来介绍下吗？**

> **候选者**：嗯，为了讲清楚隔离级别，我顺带来说下MySQL锁相关的知识吧。
>
> **候选者**：在InnoDB引擎下，按锁的粒度分类，可以简单分为行锁和表锁。
>
> **候选者**：行锁实际上是作用在索引之上的（索引上次已经说过了，这里就不赘述了）。当我们的SQL命中了索引，那锁住的就是命中条件内的索引节点（这种就是行锁），如果没有命中索引，那我们锁的就是整个索引树（表锁）。
>
> **候选者**：简单来说就是：锁住的是整棵树还是某几个节点，完全取决于SQL条件是否有命中到对应的索引节点。
>
> **候选者**：而行锁又可以简单分为读锁（共享锁、S锁）和写锁（排它锁、X锁）。
>
> **候选者**：读锁是共享的，多个事务可以同时读取同一个资源，但不允许其他事务修改。写锁是排他的，写锁会阻塞其他的写锁和读锁。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkHcnHuT3go1n2Dvs3KmPHUUx5sxwHgULpeIZvob8K9Rhdy27XtmSRtA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：我现在就再回到隔离级别上吧，就直接以例子来说明啦。
>
> **面试官**：嗯…
>
> **候选者**：首先来说下read uncommit(读未提交)。比如说：A向B转账，A执行了转账语句，但A还没有提交事务，B读取数据，发现自己账户钱变多了！B跟A说，我已经收到钱了。A回滚事务【rollback】，等B再查看账户的钱时，发现钱并没有多。
>
> **候选者**：简单的定义就是：事务B读取到了事务A还没提交的数据，这种用专业术语来说叫做「脏读」。
>
> **候选者**：对于锁的维度而言，其实就是在read uncommit隔离级别下，读不会加任何锁，而写会加排他锁。读什么锁都不加，这就让排他锁无法排它了。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkdaMujEgBNL1IuqNwaBBNazBxV91cu0ZqSBVOz7Ea87RNa5ywfCcEvA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：而我们又知道，对于更新操作而言，InnoDB是肯定会加写锁的（数据库是不可能允许在同一时间，更新同一条记录的）。而读操作，如果不加任何锁，那就会造成上面的脏读。
>
> **候选者**：脏读在生产环境下肯定是无法接受的，那如果读加锁的话，那意味着：当更新数据的时，就没办法读取了，这会极大地降低数据库性能。
>
> **候选者**：在MySQL InnoDB引擎层面，又有新的解决方案（解决加锁后读写性能问题），叫做MVCC(Multi-Version Concurrency Control)多版本并发控制
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkMxJcNgibZnuFibEHo4FeGPNvTHyZWmrCXgvKMo39VY5ZlSibQqTVEhKTQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：在MVCC下，就可以做到读写不阻塞，且避免了类似脏读这样的问题。那MVCC是怎么做的呢？
>
> **候选者**：MVCC通过生成数据快照（Snapshot)，并用这个快照来提供一定级别（语句级或事务级）的一致性读取
>
> **候选者**：回到事务隔离级别下，针对于 read commit (读已提交) 隔离级别，它生成的就是语句级快照，而针对于repeatable read (可重复读)，它生成的就是事务级的快照。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkhUaj9HkfofHuvuRMJtMIqVBickM84E7jL3McmTDYnCYbOyK85LJhV5g/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：前面提到过read uncommit隔离级别下会产生脏读，而read commit (读已提交) 隔离级别解决了脏读。思想其实很简单：在读取的时候生成一个”版本号”，等到其他事务commit了之后，才会读取最新已commit的”版本号”数据。
>
> **候选者**：比如说：事务A读取了记录(生成版本号)，事务B修改了记录(此时加了写锁)，事务A再读取的时候，是依据最新的版本号来读取的(当事务B执行commit了之后，会生成一个新的版本号)，如果事务B还没有commit，那事务A读取的还是之前版本号的数据。
>
> **候选者**：通过「版本」的概念，这样就解决了脏读的问题，而「版本」其实就是对应快照的数据。
>
> **候选者**：read commit (读已提交) 解决了脏读，但也会有其他并发的问题。「不可重复读」：一个事务读取到另外一个事务已经提交的数据，也就是说一个事务可以看到其他事务所做的修改。
>
> **候选者**：不可重复读的例子：A查询数据库得到数据，B去修改数据库的数据，导致A多次查询数据库的结果都不一样【危害：A每次查询的结果都是受B的影响的】
>
> **候选者**：了解MVCC基础之后，就很容易想到repeatable read (可重复复读)隔离级别是怎么避免不可重复读的问题了（前面也提到了）。
>
> **候选者**：repeatable read (可重复复读)隔离级别是「事务级别」的快照！每次读取的都是「当前事务的版本」，即使当前数据被其他事务修改了(commit)，也只会读取当前事务版本的数据。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkGek0TdDYQVwBNo1F7LdqKMTvfXjAVbRSyib2MBM6xsic6E0fDeV7JOPA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：而repeatable read (可重复复读)隔离级别会存在幻读的问题，「幻读」指的是指在一个事务内读取到了别的事务插入的数据，导致前后读取不一致。
>
> **候选者**：在InnoDB引擎下的的repeatable read (可重复复读)隔离级别下，快照读MVCC影响下，已经解决了幻读的问题（因为它是读历史版本的数据）
>
> **候选者**：而如果是当前读（指的是 select * from table for update），则需要配合间隙锁来解决幻读的问题。
>
> **候选者**：剩下的就是serializable (串行)隔离级别了，它的最高的隔离级别，相当于不允许事务的并发，事务与事务之间执行是串行的，它的效率最低，但同时也是最安全的。

**面试官**：嗯，可以的。**我看你提到了MVCC了，不妨来说下他的原理？**

> **候选者**：MVCC的主要是通过read view和undo log来实现的
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkcZbr7670ibA1w8icW2bjgpcjyewAD2a5a7yWhK2F50RNicnSNvGOnahvA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：undo log前面也提到了，它会记录修改数据之前的信息，事务中的原子性就是通过undo log来实现的。所以，有undo log可以帮我们找到「版本」的数据
>
> **候选者**：而read view 实际上就是在查询时，InnoDB会生成一个read view，read view 有几个重要的字段，分别是：trx_ids（尚未提交commit的事务版本号集合），up_limit_id（下一次要生成的事务ID值），low_limit_id（尚未提交版本号的事务ID最小值）以及creator_trx_id（当前的事务版本号）
>
> **候选者**：在每行数据有两列隐藏的字段，分别是DB_TRX_ID（记录着当前ID）以及DB_ROLL_PTR（指向上一个版本数据在undo log 里的位置指针）
>
> **候选者**：铺垫到这了，很容易就发现，MVCC其实就是靠「比对版本」来实现读写不阻塞，而版本的数据存在于undo log中。
>
> **候选者**：而针对于不同的隔离级别（read commit和repeatable read），无非就是read commit隔离级别下，每次都获取一个新的read view，repeatable read隔离级别则每次事务只获取一个read view

**面试官**：嗯，OK的。细节就不考究了，今天就到这里吧。

------

# 【对线面试官】MySQL调优

?>**MySql的执行顺序：** FROM->JOIN->ON->WHERE->GROUP BY->HAVING->SELECT->DISTINCT->ORDER BY->LIMIT

**面试官**：**你们对MySQL怎么调优的**

> **候选者**：sql 优化可以从 硬件、系统配置、数据库表结构、SQL及索引 这几个方面优化（然而实际上我们只能决定 数据库表结构、SQL及索引 的优化，有可能 数据库表结构 我们也没权限）
>
> **候选者**：对于开发者而言，对MySQL的调优重点一般是【开发规范】【数据库索引】又或者说解决线上慢查询
>
> **候选者**：首先从【开发规范】【数据库索引】开始
>
> **候选者**：首先在开发环境下，创建数据库表（有DBA的话可能需要审批，没有的话 根据公司的开发规范与自己平时积累的经验来 创建）；我们要有创建索引的习惯，其次 设置合理的字段类型，尽量让 字段存储空间小，可以节省存储空间，减少磁盘IO（注意设置字符集，不同表的字符集不同，也会引起慢SQL查询）
>
> 例如：
>
> - 尽量使用数字型字段
>
>   尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。
>   这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。
>
> - 用varchar/nvarchar 代替 char/nchar
>
>   尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。
>   不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。
>
> **候选者**：【数据库索引】
>
> **候选者**：是否能使用【覆盖索引】/【联合索引】，减少【回表】所消耗的时间，并且MySQL5.6对非聚簇索引提供的一项索引优化功能【索引下推】，可以在非聚簇索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数。意味着，我们在 select 的时候，一定要指明对应的列，而不是 select *；【准守最左匹配原则】
>
> **候选者**：考虑组建【覆盖索引】/【联合索引】或者是其它的索引时，尽量选择合适的字段
>
> - **非空字段**：在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；
> - **取值离散大的字段**：返回值越大说明字段的唯一值越多字段的离散程度高；
> - **索引字段越小越好**：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。
> - 频繁查询、排序、表连接……字段
>
> **候选者**：【SQL 写法上】通过索引访问（尽可能的不让索引失效）
>
> - **不要在索引上进行任何操作;（在索引列上进行计算、函数、类型转换等操作）**
> - **查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;**
> - **复合索引不能使用不等于（!= <>）或 is null (is not null)，否则自身以及右侧所有全部失效**
> - 尽量不要使用类型转换（显示、隐式），否则索引失效
> - **以 % 开头的 LIKE 查询比如 `like '%abc';`;**
>
> **候选者**：【减少交互次数】批量DML操作，函数存储等减少数据连接次数
>
> **候选者**：`最主要还是要通过 explain 命令来查看 SQL 的执行计划，看看自己写的 SQL 是否走索引，走什么索引。通过 show profile 来查看 SQL 对资源损耗情况（用的比较少）`
>
> **候选者**：在开启事务后，在事务内尽可能只操作数据库，并有意识的减少锁的持有时间（比如在事务内需要插入&&修改数据，那可以先插入后修改。因为修改是更新操作，会加行锁。如果先更新，那并发下可能会导致多个事务的请求等待行锁释放）

**面试官**：**你们线上使用的什么隔离级别**

> **候选者**：REPEATABLE READ
>
> **候选者**：问题
>
> - 可能因为【间隙锁】导致死锁的问题（解决：软删除）
>
> - 解决了【主从不一致】问题
>
>   **问题：**在mysql5.0以前binlog只支持statement这种格式，这种格式在读已提交（read commited）这个隔离级别下主从复制是有bug的。
>
>   产生bug的原因：在主库上面执行先删除后插入，但是在从库如果binlog为statement格式，记录的顺序就是先插入后删除，从库执行的顺序和主库不一致，最后主库有数据，从库的数据被删掉了。
>
>   **解决：**将binlog_format设置为row格式，基于行的复制，就不会出现sql执行顺序不一样的问题。但是这个格式是mysql5.1以后才有的。由于历史的原因，mysql将默认的隔离级别设置为可重复读，并一直延续了下来，保证主从复制不出问题。

**面试官**：**解决线上慢查询**

> **候选者**：
>
> - 分析语句，是否加载了不必要的字段/数据
> - 分析 SQL 执行句话，是否命中索引等
>
> **候选者**：如果走对了索引，但查询还是很慢，那一般来说就是表的数据量太大了
>
> - 首先，考虑能不能把【旧的数据】给 ”删掉“ ；如果这些【旧的数据】已经没有查询的业务了，那最简单的方法肯定就是”删掉“部分数据了。数据量降低了，那检索的速度就很快了；【但是一般是不会删掉的】
>
>   所以可以考虑做【离线数据】，把数据同步到 Hive 离线存储。
>
> - 随后，就可以考虑走缓存（Redis）；而走缓存的话，又要看业务能不能忍受【数据的非实时性】（毕竟Redis和MySQL的数据一致性需要保证），如果查询条件 复杂且多变的话（涉及各种group by和sum），那么走缓存 可能也不是 一个好的办法，维护起来就不方便了。
>
> - 再看看是不是有【字符串】检索的场景导致查询低效，如果是的话，可以考虑把表的数据导入至Elasticsearch的搜索引擎，后续线上查询就直接走ES。（但是需要增加 MySQL -> ES 需要对应的同步程序，一般就是监听MySQL的binlog，解析binlog后导入ES）
>
> - 还可以考虑根据查询条件的维度，做相应的聚合表，线上的请求就查询聚合表的数据，不走原表。
>
>   比如：有一份订单明细，而该订单明细表的数据量很大。但实际上 用户在页面上只关心 以天为维度的 数据信息。所以 就可以将 每个用户 每天的数据 聚合起来，汇总成一条数据。查询走聚合后的表，那速度肯定杠杠的。
>
>   【思路大致就是 `以空间换时间`，相同的数据换别的地方页存储一份，提高查询效率】
>
> - 最后就是【分库分表】；而【分库分表】的代价时比较大的；`例如：`
>
>   - 分库分表键
>   - 分库分表ID
>   - 数据迁移
>   - 后期扩容
>   - 业务上的统计查询、排序……

**分库分表键**：【主要按照业务来】，按照我们这边来说，一般来说时按照 userId 的（因为按照用户的维度查询比较多）/也有按照 时间 的（这个一般是做 时间跨度统计、计算的）

**分库分表ID**：

- （在分布式的环境下必须【全局且唯一】 。

- 一般都需【要单调递增】，因为一般唯一ID都 会存到数据库，而 innodb 的特性就是将内容存储在主键索引树上的叶子节点而且是从左往右，递增的，所以考虑到数据库性能，一般生成的 id 也最好是单调递增。）

  涉及到分布式ID生成的方式了，思路有很多，有 MySQL 自增，Redis 自增，【雪花算法】自增；

**数据迁移**：一般采取【同步双写】的方式，大致步骤

1. 增量的消息各自往新表和旧表写一份
2. 将旧表的数据迁移至新库
3. 迟早新表的数据会 超过 旧表
4. 校验 新表和旧表 的数据是否正常
5. 开启双读（一部分流量走新表，一部分走老表）这里最好采用灰度的方式来切换，比如开始切换 10% 的流量，如果没有问题再切换到 50% 的流量，最后再切换到 100%。
6. 读流量全部更新至新表，就停止老表的写入
7. 另外，提前准备回滚机制，防止 因为切换失败而影响业务正常运行的程序
