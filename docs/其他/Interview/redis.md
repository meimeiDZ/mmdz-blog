# Redis

> **Redis的具有很多优势：**
>
> （1）读写性能高--100000次/s以上的读速度，80000次/s以上的写速度；
>
> （2）K-V，value支持的数据类型很多：字符串(String)，队列（List）,哈希（Hash），集合（Sets），有序集合（Sorted Sets）5种不同的数据类型。
>
> （3）原子性，Redis的所有操作都是单线程原子性的。
>
> （4）特性丰富--支持订阅-发布模式，通知、设置key过期等特性。
>
> （5）在Redis3.0 版本引入了Redis集群，可用于分布式部署。

## Redis 为什么快

> 1. 基于内存的操作
> 2. 使用了 I/O 多路复用模型，select、epoll 等，基于 reactor 模式开发了自己的网络事件处理器
> 3. Redis高效数据结构，对数据的操作也比较简单
> 4. Redis是单线程模型，从而避开了多线程中上下文频繁切换的操作

<!-- tabs:start -->

#### **基于内存的操作实现**

Redis 是基于内存的数据库，不论读写操作都是在内存上完成的，完全吊打磁盘数据库的速度。Redis之所以可以使用单线程来处理，其中的一个原因是，内存操作对资源损耗较小，保证了处理的高效性。

*如此宝贵的内存资源，Redis是怎么维护和管理的呢？*

1. **Redis数据过期策略**

   Reids中数据过期策略采用定期删除+惰性删除策略。内存和CPU资源都是宝贵的，Redis的**过期键删除**通过定期删除设定合理的执行时长和执行频率，配合惰性删除兜底的方式，来达到CPU时间占用和内存浪费之间的平衡。

   - **定期删除策略**：Redis启用一个定时器定时监视所有key，判断key是否过期，过期的话就删除。这种策略可以保证过期的key最终都会被删除，但是也存在严重的缺点：每次都遍历内存中所有的数据，非常消耗CPU资源，并且当key已过期，但是定时器还处于未唤起状态，这段时间内key任然可以使用。
   - **惰性删除策略**：在获取 key 时，先判断 key 是否过期，如果过期则删除。这种方式存在一个缺点：如果这个 key 一直未被使用，那么它一直在内存中，其实它已经过期了，会浪费大量的空间。

   **定期删除+惰性删除策略是如何工作的？**

   这两种策略天然的互补，结合起来之后，定时删除策略就发生了一些改变，不在是每次扫描全部的 key 了，而是随机抽取一部分 key 进行检查，这样就降低了对 CPU 资源的损耗，惰性删除策略互补了为检查到的key，基本上满足了所有要求。

   但是有时候就是那么的巧，既没有被定时器抽取到，又没有被使用触发惰性删除，是否会把内存撑爆？回答是不会，当内存不够用时，内存淘汰机制就会上场。

   **Redis 内存淘汰机制有以下几种策略：**

   - noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。(Redis 默认策略)
   - allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 Key。(推荐使用)
   - allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 Key。
   - volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 Key。这种情况一般是把 Redis 既当缓存，又做持久化存储的时候才用。
   - volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 Key。
   - volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 Key 优先移除。

   修改内存淘汰机制只需要在 redis.conf 配置文件中配置 maxmemory-policy 参数即可。

   值得一提的是，这里的lru和平常我们所熟知的lru还不完全一样，Redis使用的是采样概率的思想，省略了双向链表的内存消耗。Redis 会在每一次处理命令的时候判断是否达到了最大限制，如果达到则使用对应的算法去删除涉及到的Key，这时，我们前面所维护过键的LRU值就会派上用场了。

#### **高效的数据结构**

在 Redis 中存储value，常用的 5 种数据类型：String、List、Hash、Set、Zset

上面的应该叫做 Redis 支持的数据类型，也就是数据的保存形式。针对这 5 种数据类型，Redis底层都运用了哪些高效的数据结构来支持。

- String

  Redis的String底层数据结构实现并没有直接使用C语言中的字符串，Redis中为了实现方便的扩展，考虑到安全和性能，自己定义了一个结构用来存储字符串，这个数据结构就是：简单动态字符串(Simple Dynamic String 简称sds)，并将 SDS 用作 Redis 的默认字符串。

  ```c
  /*
   * redis中保存字符串对象的结构
   */
  struct sdshdr {
      //用于记录buf数组中使用的字节的数目，和SDS存储的字符串的长度相等 
      int len;
      //用于记录buf数组中没有使用的字节的数目 
      int free;
      //字节数组，用于储存字符串
      char buf[]; //buf的大小等于len+free+1，其中多余的1个字节是用来存储’\0’的
  };
  ```

  相比于C语言来说，也就多了几个字段，分别用来标识空闲空间和当前数据长度，但简直是神来之笔：（这个\0对于用户来说是通用的，系统自动帮我们加上去）

  - **可以O(1)复杂度获取字符串长度**：有len字段的存在，无需像C结构一样遍历计数。
  - **杜绝缓存区溢出**：C字符串不记录已占用的长度，所以需要提前分配足够空间，一旦空间不够则会溢出。而有free字段的存在，让SDS在执行前可以判断并分配足够空间给程序。
  - **减少字符串修改带来的内存重分配次数**：有free字段的存在，使SDS有了空间预分配和惰性释放的能力。
  - **对二进制是安全的**：二进制可能会有字符和C字符串结尾符 '\0' 冲突，在遍历和获取数据时产生截断异常，而SDS有了len字段，准确了标识了数据长度，不需担心被中间的 '\0' 截断。

- Redis数据类型与底层数据结构

  对于链表、hash表和跳表来说，Redis在设计数据结构的时候出发点是一致的，总结起来就是一句话：空间换时间。用牺牲存储空间和微小的计算代价，来换取数据的快速操作。

  为了追求速度，每种数据类型使用不同的数据结构支撑，底层数据结构有 6 种：

  ![](redis_imgs\048725de22897b8bd34def2c4b938760.png)

#### **IO多路复用模型**

多路指的是多个 socket 连接，复用指的是复用一个线程。IO多路复用主要有三种技术：select，poll，epoll。epoll 是目前最新最好的IO多路复用技术。

IO多路复用的基本原理是，内核不是监视应用程序本身的连接，而是监视应用程序的文件描述符。当客户端运行时，它将生成具有不同事件类型的套接字。在服务器端，I / O 多路复用程序（I / O 多路复用模块）会将消息放入队列（也就是 下图的 I/O 多路复用程序的 socket 队列），然后通过文件事件分派器将其转发到不同的事件处理器。

简单来说：Redis 单线程情况下，内核会一直监听 socket 上的连接请求或者数据请求，一旦有请求到达就交给 Redis 线程处理，这就实现了一个 Redis 线程处理多个 IO 流的效果。

select/epoll 提供了基于事件的回调机制，即针对不同事件的发生，调用相应的事件处理器。所以 Redis 一直在处理事件，提升 Redis 的响应性能。

![](redis_imgs\0cf41b4396151159ca969af05c8fcf7b.png)

Redis 线程不会阻塞在某一个特定的监听或已连接套接字上，也就是说，不会阻塞在某一个特定的客户端请求处理上。正因为此，Redis 可以同时和多个客户端连接并处理请求，从而提升并发性

#### **单线程模型**

我们要明确的是：Redis 的单线程指的是 Redis 的网络 IO 以及键值对指令读写是由一个线程来执行的。 对于 Redis 的持久化、集群数据同步、异步删除等都是其他线程执行。

所谓单线程是指对数据的所有操作都是由一个线程按顺序挨个执行的，**使用单线程好处**：

- 不会因为线程创建导致的性能消耗；
- 避免上多线程上下文切换引起的 CPU开销；
- 避免了线程之间的竞争问题，比如添加锁、释放锁、死锁等，不需要考虑各种锁的问题。
- 代码更清晰，处理逻辑简单。

**单线程是否没有充分利用 CPU 资源呢？**

官方答案：因为 Redis 是基于内存的操作，使用Redis时，几乎不存在CPU成为瓶颈的情况， Redis主要受限于服务器内存和网络。例如在一个普通的Linux系统上，Redis通过使用pipelining每秒可以处理10万个请求，所以如果应用程序主要使用O(N)或O(log(N))的命令，它几乎不会占用太多CPU。既然单线程容易实现，而且 CPU 不会成为瓶颈，那就顺理成章地采用单线程的方案了。

**Redis6.0 引入多线程主要是为了提高网络 IO 读写性能**，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

虽然，Redis6.0 引入了多线程，但是 Redis 的多线程只是在网络数据的读写这类耗时操作上使用了，执行命令仍然是单线程顺序执行。因此，你也不需要担心线程安全问题。

<!-- tabs:end -->

## Redis 数据结构

> ?>**Redis核心对象**
>
> 在Redis中有一个**「核心的对象」**叫做`redisObject` ，是用来表示所有的key和value的，用redisObject结构体来表示`String、Hash、List、Set、ZSet`五种数据类型。
>
> 在redisObject中**「type表示属于哪种数据类型，encoding表示该数据的存储方式，lru字段记录对象最后次被访问的时间，refcount字段:记录当前对象被引用的次数」**，也就是底层的实现的该数据类型的数据结构。
>
> ?>`PS面试题，Redis的对象垃圾回收算法-----引用计数法。`
>
> ![image.png](redis_imgs\455898bf4c9b421c9bbcaa09ff7df7f8.png)

### 常用数据结构底层

Redis支持五种数据类型：**string（字符串），hash（哈希），list（列表），set（无序集合）及zset(有序集合)**。

各个数据类型应用场景：

| 类型                 | 特性                                                         | 场景                                                         | 常用命令                                                     |
| -------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| String(字符串)       | 可以包含任何数据,比如jpg图片或者序列化的对象,一个键最大能存储512M | 缓存功能 、计数、共享Session、限速                           | set、get<br />mset、mget<br />Incr、del                      |
| Hash(字典)           | 适合存储对象,并且可以像数据库中update一个属性一样只修改某一项属性值(Memcached中需要取出整个字符串反序列化成对象修改完再序列化存回去) | 存储、读取、修改用户属性                                     | hset、hget、hdel、hlen                                       |
| List(列表)           | 增删快,提供了操作某一段元素的API                             | 1、最新消息排行等功能(比如朋友圈的时间线) <br />2、消息队列  | lpush+lpop =Stack（栈)<br />lpush +rpop =Queue(队列)<br />lpsh+ ltrim =Capped Collection（有限集合)<br />lpush+brpop=Message Queue(消息队列) |
| Set(集合)            | 1、添加、删除、查找的复杂度都是O(1) 2、为集合提供了求交集、并集、差集等操作 | 1、共同好友 <br />2、利用唯一性,统计访问网站的所有独立ip <br />3、好友推荐时,根据tag求交集,大于某个阈值就可以推荐 | sadd、srem                                                   |
| Sorted Set(有序集合) | 数据插入集合时,已经进行天然排序                              | 1、排行榜 2、带权重的消息队列                                | zadd、zcard、zrem                                            |

![](redis_imgs\af97384a1c938a2603a9b28ff7a4da0d.png)

<!-- tabs:start -->

#### **String**

> String类型的数据结构存储方式有三种`int、raw、embstr`。
>
> Redis中规定假如存储的是**「整数型值」**，比如`set num 123`这样的类型，就会使用 int的存储方式进行存储
>
> 假如存储的**「字符串是一个字符串值并且长度大于32个字节」**就会使用`SDS（simple dynamic string）`方式进行存储，并且encoding设置为raw；若是**「字符串长度小于等于32个字节」**就会将encoding改为embstr来保存字符串。
>
> SDS称为**「简单动态字符串」**，对于SDS中的定义在Redis的源码中有的三个属性`int len、int free、char buf[]`。
>
> len保存了字符串的长度，free表示buf数组中未使用的字节数量，buf数组则是保存字符串的每一个字符元素。
>
> ```c
> /*
>  * redis中保存字符串对象的结构
>  */
> struct sdshdr {
>     //用于记录buf数组中使用的字节的数目，和SDS存储的字符串的长度相等 
>     int len;
>     //用于记录buf数组中没有使用的字节的数目 
>     int free;
>     //字节数组，用于储存字符串
>     char buf[]; //buf的大小等于len+free+1，其中多余的1个字节是用来存储’\0’的
> };
> ```
>
> 相比于C语言来说，也就多了几个字段，分别用来标识空闲空间和当前数据长度，但简直是神来之笔：（这个\0对于用户来说是通用的，系统自动帮我们加上去）
>
> - **可以O(1)复杂度获取字符串长度**：有len字段的存在，无需像C结构一样遍历计数。
> - **杜绝缓存区溢出**：C字符串不记录已占用的长度，所以需要提前分配足够空间，一旦空间不够则会溢出。而有free字段的存在，让SDS在执行前可以判断并分配足够空间给程序。
> - **减少字符串修改带来的内存重分配次数**：有free字段的存在，使SDS有了空间预分配和惰性释放的能力。
> - **对二进制是安全的**：二进制可能会有字符和C字符串结尾符 '\0' 冲突，在遍历和获取数据时产生截断异常，而SDS有了len字段，准确了标识了数据长度，不需担心被中间的 '\0' 截断。

#### **Hash**

> Hash对象的实现方式有两种分别是`ziplist、hashtable`，其中hashtable的存储方式key是String类型的，value也是以`key value`的形式进行存储。
>
> 字典类型的底层就是hashtable实现的，明白了字典的底层实现原理也就是明白了hashtable的实现原理，hashtable的实现原理可以于HashMap的是底层原理相类比。

#### **字典**

> 两者在新增时都会通过key计算出数组下标，不同的是计算法方式不同，HashMap中是以hash函数的方式，而hashtable中计算出hash值后，还要通过sizemask 属性和哈希值再次得到数组下标。
>
> 我们知道hash表最大的问题就是hash冲突，为了解决hash冲突，假如hashtable中不同的key通过计算得到同一个index，就会形成单向链表（**「链地址法」**），如下图所示：
>
> ![img](redis_imgs\v2-dd8e346e267fd00c6e8d47f32d15ce1d_1440w.png)
>
> ?>**rehash**
>
> 在字典的底层实现中，value对象以每一个dictEntry的对象进行存储，当hash表中的存放的键值对不断的增加或者减少时，需要对hash表进行一个扩展或者收缩。
>
> 这里就会和HashMap一样也会就进行rehash操作，进行重新散列排布。从上图中可以看到有`ht[0]`和`ht[1]`两个对象，先来看看对象中的属性是干嘛用的。
>
> 在hash表结构定义中有四个属性分别是`dictEntry **table、unsigned long size、unsigned long sizemask、unsigned long used`，分别表示的含义就是**「哈希表数组、hash表大小、用于计算索引值，总是等于size-1、hash表中已有的节点数」**。
>
> ht[0]是用来最开始存储数据的，当要进行扩展或者收缩时，ht[0]的大小就决定了ht[1]的大小，ht[0]中的所有的键值对就会重新散列到ht[1]中。
>
> 扩展操作：ht[1]扩展的大小是比当前 ht[0].used 值的二倍大的第一个 2 的整数幂；收缩操作：ht[0].used 的第一个大于等于的 2 的整数幂。
>
> 当ht[0]上的所有的键值对都rehash到ht[1]中，会重新计算所有的数组下标值，当数据迁移完后ht[0]就会被释放，然后将ht[1]改为ht[0]，并新创建ht[1]，为下一次的扩展和收缩做准备。
>
> ?>**渐进式rehash**
>
> 假如在rehash的过程中数据量非常大，Redis不是一次性把全部数据rehash成功，这样会导致Redis对外服务停止，Redis内部为了处理这种情况采用**「渐进式的rehash」**。
>
> Redis将所有的rehash的操作分成多步进行，直到都rehash完成，具体的实现与对象中的`rehashindex`属性相关，**「若是rehashindex 表示为-1表示没有rehash操作」**。
>
> 当rehash操作开始时会将该值改成0，在渐进式rehash的过程**「更新、删除、查询会在ht[0]和ht[1]中都进行」**，比如更新一个值先更新ht[0]，然后再更新ht[1]。
>
> 而新增操作直接就新增到ht[1]表中，ht[0]不会新增任何的数据，这样保证**「ht[0]只减不增，直到最后的某一个时刻变成空表」**，这样rehash操作完成。
>
> 上面就是字典的底层hashtable的实现原理，说完了hashtable的实现原理，我们再来看看Hash数据结构的两一种存储方式**「ziplist（压缩列表）」**

#### **ziplist**

> 压缩列表`（ziplist）`是一组连续内存块组成的顺序的数据结构，压缩列表能够节省空间，压缩列表中使用多个节点来存储数据。
>
> 压缩列表是列表键和哈希键底层实现的原理之一，**「压缩列表并不是以某种压缩算法进行压缩存储数据，而是它表示一组连续的内存空间的使用，节省空间」**，压缩列表的内存结构图如下：
>
> ![](redis_imgs\20201004223339394.jpeg)
>
> ziplist主要有这么几个部分：
>
> - zlbytes ：记录整个压缩列表占用的内存字节数
> - zltail: 尾节点至起始节点的偏移量
> - zllen : 记录整个压缩列表包含的节点数量
> - entry: 压缩列表包含的各个节点
> - zlend : ziplist的末尾表示，值固定是255.，用于标记压缩列表末端
>
> **entry**
> 这里最核心的就是entry的数据格式，entry还真有些复杂，从上图中可以看出它主要有三个部分。
>
> - prelen: 前一个entry的存储大小，主要是为了方便从后往前遍历。
> - encoding: 数据的编码形式（字符串还是数字，长度是多少）
> - data: 实际存储的数据
>
> 由于内存是**连续分配**的，所以遍历速度很快。

#### **List**

> Redis中的列表在3.2之前的版本是使用`ziplist`和`linkedlist`进行实现的。在3.2之后的版本就是引入了`quicklist`。
>
> ziplist压缩列表上面已经讲过了，我们来看看linkedlist和quicklist的结构是怎么样的。
>
> linkedlist是一个双向链表，他和普通的链表一样都是由指向前后节点的指针。插入、修改、更新的时间复杂度尾O(1)，但是查询的时间复杂度确实O(n)。
>
> linkedlist和quicklist的底层实现是采用链表进行实现，在c语言中并没有内置的链表这种数据结构，Redis实现了自己的链表结构。
>
> ![](redis_imgs\v2-102238a40860c08faf37c492f61f6d94_1440w.png)
>
> Redis中链表的特性：
>
> 1. 每一个节点都有指向前一个节点和后一个节点的指针。
> 2. 头节点和尾节点的prev和next指针指向为null，所以链表是无环的。
> 3. 链表有自己长度的信息，获取长度的时间复杂度为O(1)。

#### **Set**

> Redis中列表和集合都可以用来存储字符串，但是**「Set是不可重复的集合，而List列表可以存储相同的字符串」**，Set集合是无序的这个和后面讲的ZSet有序集合相对。
>
> Set的底层实现是**「ht和intset」**，ht（哈希表）前面已经详细了解过，下面我们来看看inset类型的存储结构。
>
> inset也叫做整数集合，用于保存整数值的数据结构类型，它可以保存`int16_t`、`int32_t` 或者`int64_t` 的整数值。
>
> 在整数集合中，有三个属性值`encoding、length、contents[]`，分别表示编码方式、整数集合的长度、以及元素内容，length就是记录contents里面的大小。
>
> 在整数集合新增元素的时候，若是超出了原集合的长度大小，就会对集合进行升级，具体的升级过程如下：
>
> 1. 首先扩展底层数组的大小，并且数组的类型为新元素的类型。
> 2. 然后将原来的数组中的元素转为新元素的类型，并放到扩展后数组对应的位置。
> 3. 整数集合升级后就不会再降级，编码会一直保持升级后的状态。

#### **ZSet**

> ZSet是有序集合，从上面的图中可以看到ZSet的底层实现是`ziplist`和`skiplist`实现的，ziplist上面已经详细讲过，这里来讲解skiplist的结构实现。
>
> `skiplist`也叫做**「跳跃表」**，跳跃表是一种有序的数据结构，它通过每一个节点维持多个指向其它节点的指针，从而达到快速访问的目的。
>
> skiplist由如下几个特点：
>
> 1. 有很多层组成，由上到下节点数逐渐密集，最上层的节点最稀疏，跨度也最大。
> 2. 每一层都是一个有序链表，只扫包含两个节点，头节点和尾节点。
> 3. 每一层的每一个每一个节点都含有指向同一层下一个节点和下一层同一个位置节点的指针。
> 4. 如果一个节点在某一层出现，那么该以下的所有链表同一个位置都会出现该节点。
>
> 具体实现的结构图如下所示：
>
> ![img](redis_imgs\71739d6f0c7b0a9b75dda2ad507818d5.png)
>
> 在跳跃表的结构中有head和tail表示指向头节点和尾节点的指针，能后快速的实现定位。level表示层数，len表示跳跃表的长度，BW表示后退指针，在从尾向前遍历的时候使用。
>
> BW下面还有两个值分别表示分值（score）和成员对象（各个节点保存的成员对象）。
>
> 跳跃表的实现中，除了最底层的一层保存的是原始链表的完整数据，上层的节点数会越来越少，并且跨度会越来越大。
>
> 跳跃表的上面层就相当于索引层，都是为了找到最后的数据而服务的，数据量越大，条表所体现的查询的效率就越高，和平衡树的查询效率相差无几。

<!-- tabs:end -->

### 高级数据结构

> - **Bitmaps**
>
>   #### Bitmaps优势
>
>   假设网站有1亿用户，每天独立访问的用户有5千万，如果每天用集合类型和 Bitmaps分别存储活跃用户，很明显，假如用户id是Long型，64位，则集合类型占据的空间为64位x50 000 000= 400MB，而Bitmaps则需要1位×100 000 000=12.5MB，可见Bitmaps能节省很多的内存空间。
>
>   ##### 面试题和场景
>
>   1、目前有10亿数量的自然数，乱序排列，需要对其排序。限制条件-在32位机器上面完成，内存限制为 2G。如何完成？
>
>   2、如何快速在亿级黑名单中快速定位URL地址是否在黑名单中？(每条URL平均64字节)
>
>   3、需要进行用户登陆行为分析，来确定用户的活跃情况？
>
>   4、网络爬虫-如何判断URL是否被爬过？
>
>   5、快速定位用户属性（黑名单、白名单等）
>
>   6、数据存储在磁盘中，如何避免大量的无效IO？
>
> - **HyperLogLog**
>
>   应用场景：适合做页面统计。
>   如果允许容错，那么一定要使用Hyperloglog；
>   如果不允许容错，就使用set或者自己的数据类型即可。
>   （容错就是当由于种种原因在系统中出现了数据、文件损坏或丢失时，系统能够自动将这些损坏或丢失的文件和数据恢复到发生事故以前的状态，使系统能够连续正常运行的一种技术，很简单的意思）
>
> - **GEO**
>
>   Redis 3.2版本提供了GEO(地理信息定位)功能，支持存储地理位置信息用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能。
>
>   #### 操作命令
>
>   ##### 增加地理位置信息
>
>   geoadd key longitude latitude member [longitude latitude member ...J
>
>   longitude、latitude、member分别是该地理位置的经度、纬度、成员，例如下面有5个城市的经纬度。
>
>   城市            经度             纬度             成员
>
>   北京            116.28          39.55            beijing
>
>   天津            117.12          39.08            tianjin
>
>   石家庄        114.29          38.02            shijiazhuang
>
>   唐山            118.01          39.38            tangshan
>
>   保定            115.29          38.51            baoding
>
>   cities:locations是上面5个城市地理位置信息的集合，现向其添加北京的地理位置信息:
>
>   geoadd cities :locations 116.28 39.55 beijing
>

## Redis 中的线程和IO模型

### Redis 线程模型

> redis 基于 reactor 模式开发了自己的网络事件处理器，由4个部分组成：套接字、I/O 多路复用程序、文件事件分派器（dispatcher）、以及事件处理器。
>
> ![](redis_imgs\0cf41b4396151159ca969af05c8fcf7b.png)
>
> 套接字：socket 连接，也就是客户端连接。当一个套接字准备好执行连接、写入、读取、关闭等操作时， 就会产生一个相应的文件事件。因为一个服务器通常会连接多个套接字， 所以多个文件事件有可能会并发地出现。
>
> I/O 多路复用程序：提供 select、epoll、evport、kqueue 的实现，会根据当前系统自动选择最佳的方式。负责监听多个套接字，当套接字产生事件时，会向文件事件分派器传送那些产生了事件的套接字。当多个文件事件并发出现时， I/O 多路复用程序会将所有产生事件的套接字都放到一个队列里面，然后通过这个队列，以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字：当上一个套接字产生的事件被处理完毕之后，才会继续传送下一个套接字。
>
> 文件事件分派器：接收 I/O 多路复用程序传来的套接字， 并根据套接字产生的事件的类型， 调用相应的事件处理器。
>
> 事件处理器：事件处理器就是一个个函数， 定义了某个事件发生时， 服务器应该执行的动作。例如：建立连接、命令查询、命令写入、连接关闭等等。

### Redis6.0之前的版本真的是单线程吗？

> 在 redis 6.0 之前，redis 的核心操作是单线程的。这边的核心流程指的是 redis 正常处理客户端请求的流程，通常包括：接收命令、解析命令、执行命令、返回结果等。这就是所谓的“单线程”。但如果严格来讲从Redis4.0之后并不是单线程，除了主线程外，它也有后台线程在处理一些较为缓慢的操作，例如清理脏数据、无用连接的释放、大 key 的删除等等。
>
> 因为 redis 是完全基于内存操作的，通常情况下CPU不会是redis的瓶颈，redis 的瓶颈最有可能是机器内存的大小或者网络带宽。
>
> 既然CPU不会成为瓶颈，那就顺理成章地采用单线程的方案了，因为如果使用多线程的话会更复杂，同时需要引入上下文切换、加锁等等，会带来额外的性能消耗。

### Redis6.0之前为什么一直不使用多线程？

> 官方曾做过类似问题的回复：使用Redis时，几乎不存在CPU成为瓶颈的情况，
> Redis主要受限于内存和网络。例如在一个普通的Linux系统上，Redis通过使用pipelining每秒可以处理100万个请求，所以如果应用程序主要使用O(N)或O(log(N))的命令，它几乎不会占用太多CPU。
>
> 使用了多线程后，可维护性高。多线程模型虽然在某些方面表现优异，但是它却引入了程序执行顺序的不确定性，带来了并发读写的一系列问题，增加了系统复杂度、同时可能存在线程切换、甚至加锁解锁、死锁造成的性能损耗。Redis通过AE事件模型以及IO多路复用等技术，处理性能非常高，因此没有必要使用多线程。单线程机制使得 Redis 内部实现的复杂度大大降低，Hash 的惰性 Rehash、Lpush 等等,“线程不安全” 的命令都可以无锁进行。
>

### Redis6.0为什么要引入多线程呢？

> Redis将所有数据放在内存中，内存的响应时长大约为100纳秒，对于小数据包，Redis服务器可以处理80,000到100,000 QPS，这也是Redis处理的极限了，对于80%的公司来说，单线程的Redis已经足够使用了。
>
> 但随着越来越复杂的业务场景，有些公司动不动就上亿的交易量，因此需要更大的QPS。常见的解决方案是在分布式架构中对数据进行分区并采用多个服务器，但该方案有非常大的缺点，例如要管理的Redis服务器太多，维护代价大；某些适用于单个Redis服务器的命令不适用于数据分区；数据分区无法解决热点读/写问题；数据偏斜，重新分配和放大/缩小变得更加复杂等等。
>
> 所以总结起来，redis支持多线程主要就是两个原因：
>
> • 可以充分利用服务器 CPU 资源，目前主线程只能利用一个核
>
> • 多线程任务可以分摊 Redis 同步 IO 读写负荷
>
> 
>
> **redis 6.0 加入多线程 I/O 之后，处理命令的核心流程如下:**
>
> 1、当有读事件到来时，主线程将该客户端连接放到全局等待读队列
>
> 2、读取数据：1）主线程将等待读队列的客户端连接通过轮询调度算法分配给 I/O 线程处理；2）同时主线程也会自己负责处理一个客户端连接的读事件；3）当主线程处理完该连接的读事件后，会自旋等待所有 I/O 线程处理完毕
>
> 3、命令执行：主线程按照事件被加入全局等待读队列的顺序（这边保证了执行顺序是正确的），串行执行客户端命令，然后将客户端连接放到全局等待写队列
>
> 4、写回结果：跟等待读队列处理类似，主线程将等待写队列的客户端连接使用轮询调度算法分配给 I/O 线程处理，同时自己也会处理一个，当主线程处理完毕后，会自旋等待所有 I/O 线程处理完毕，最后清空队列。
>
> ![](redis_imgs\3608fd4334634c84999bbff00beecb92.png)

## Redis 持久化

### Redis 的持久化机制有哪几种，各自的实现原理和优缺点？

> Redis 的持久化机制有：RDB、AOF、混合持久化（RDB+AOF，Redis 4.0引入）。
>
> - RDB
>
>   **描述**：类似于快照。在某个时间点，将 Redis 在内存中的数据库状态（数据库的键值对等信息）保存到磁盘里面。RDB 持久化功能生成的 RDB 文件是经过压缩的二进制文件。
>
>   **命令**：有两个 Redis 命令可以用于生成 RDB 文件，一个是 SAVE，另一个是 BGSAVE。
>
>   - save：在主线程中执行，会导致阻塞；对于内存比较大的实例会造成长时间阻塞，线上环境不建议使用。
>   - bgsave：创建一个子进程，专门用于写入 RDB 文件，避免了主线程的阻塞，这也是Redis RDB 文件生成的默认配置。
>
>   **开启**：使用 save 相关配置,如“save m n”。表示m秒内数据集存在n次修改时，自动触发bgsave。
>
>   ![](redis_imgs\f05c9dc4808f4d5197058962036a6680.png)
>
>   **bgsave执的行流程**
>
>   为了快照而暂停写操作，肯定是不能接受的。所以这个时候，Redis 就会借助操作系统提供的写时复制技术（Copy-On-Write, COW），在执行快照的同时，正常处理写操作。
>
>   ![](redis_imgs\b43882d7ee83429eb8afe0b92fab7ea0.png)
>
>   bgsave 子进程是由主线程 fork 生成的，可以共享主线程的所有内存数据。bgsave 子进程运行后，开始读取主线程的内存数据，并把它们写入 RDB 文件。
>
>   如果主线程对这些数据也都是读操作（例如图中的键值对 A），那么，主线程和bgsave 子进程相互不影响。但是，如果主线程要修改一块数据（例如图中的键值对 B），那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave 子进程会把这个副本数据写入 RDB 文件，而在这个过程中，主线程仍然可以直接修改原来的数据。
>
>   这既保证了快照的完整性，也允许主线程同时对数据进行修改，避免了对正常业务的影响。
>
>   - **RDB的优点**
>
>     （1）RDB文件紧凑，全量备份，非常适合用于进行备份和灾难恢复。
>
>     （2）生成RDB文件的时候，redis主进程会fork()一个子进程来处理所有保存工作，主进程不需要进行任何磁盘IO操作。
>
>     （3）RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。
>
>   - **RDB的缺点**
>
>     RDB的缺点
>
>     （1）RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程,属于重量级操作，频繁执行成本过高。
>
>     （2）RDB文件使用特定二进制格式保存，Redis版本演进过程中有多个格式的RDB版本，存在老版本Redis服务无法兼容新版RDB格式的问题。
>
>   **Redis中RDB导致的数据丢失问题**
>
>   RDB快照并不是很可靠。如果你的电脑突然宕机了，或者电源断了，又或者不小心杀掉了进程，那么最新的数据就会丢失。
>
> - AOF
>
>   **描述**：全量备份总是耗时的，有时候我们提供一种更加高效的方式AOF，工作机制很简单，redis会将每一个收到的写命令都通过write函数追加到文件中。通俗的理解就是日志记录。
>
>   **开启**：AOF 持久化默认是关闭的，可以通过配置：appendonly yes 开启。
>
>   AOF 持久化功能的实现可以分为**命令追加（append）、文件写入、文件同步（sync）**三个步骤。
>
>   命令追加：当 AOF 持久化功能打开时，服务器在执行完一个写命令之后，会将被执行的写命令追加到服务器状态的 aof 缓冲区（aof_buf）的末尾。
>
>   文件写入与文件同步：可能有人不明白为什么将 aof_buf 的内容写到磁盘上需要两步操作，这边简单解释一下。
>
>   Linux 操作系统中为了提升性能，使用了页缓存（page cache）。当我们将 aof_buf 的内容写到磁盘上时，此时数据并没有真正的落盘，而是在 page cache 中，为了将 page cache 中的数据真正落盘，需要执行 fsync / fdatasync 命令来强制刷盘。这边的文件同步做的就是刷盘操作，或者叫文件刷盘可能更容易理解一些。
>
>   在文章开头，我们提过 serverCron 时间事件中会触发 flushAppendOnlyFile 函数，该函数会根据服务器配置的 appendfsync 参数值，来决定是否将 aof_buf 缓冲区的内容写入和保存到 AOF 文件。
>
>   **AOF缓冲区同步文件策略 由 appendfsync 参数有三个选项：**
>
>   always：每处理一个命令都将 aof_buf 缓冲区中的所有内容写入并同步到AOF 文件，即每个命令都刷盘。
>   everysec：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件，如果上次同步 AOF 文件的时间距离现在超过一秒钟， 那么再次对 AOF 文件进行同步， 并且这个同步操作是异步的，由一个后台线程专门负责执行，即每秒刷盘1次。
>   no：将 aof_buf 缓冲区中的所有内容写入到 AOF 文件， 但并不对 AOF 文件进行同步， 何时同步由操作系统来决定。即不执行刷盘，让操作系统自己执行刷盘。
>
>   - AOF 的优点
>
>     （1）AOF可以更好的保护数据不丢失，一般AOF会每隔1秒，通过一个后台线程执行一次fsync操作，最多丢失1秒钟的数据。
>     （2）AOF日志文件没有任何磁盘寻址的开销，写入性能非常高，文件不容易破损。
>
>     （3）AOF日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。
>
>     （4）AOF日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急恢复。比如某人不小心用flushall命令清空了所有数据，只要这个时候后台rewrite还没有发生，那么就可以立即拷贝AOF文件，将最后一条flushall命令给删了，然后再将该AOF文件放回去，就可以通过恢复机制，自动恢复所有数据
>
>   - AOF 的缺点
>
>     （1）对于同一份数据来说，AOF日志文件通常比RDB数据快照文件更大
>
>     （2）AOF开启后，支持的写QPS会比RDB支持的写QPS低，因为AOF一般会配置成每秒fsync一次日志文件，当然，每秒一次fsync，性能也还是很高的
>
>     （3）以前AOF发生过bug，就是通过AOF记录的日志，进行数据恢复的时候，没有恢复一模一样的数据出来。
>
> - 混合持久化
>
>   **描述**：混合持久化并不是一种全新的持久化方式，而是对已有方式的优化。混合持久化只发生于 AOF 重写过程。使用了混合持久化，重写后的新 AOF 文件前半段是 RDB 格式的全量数据，后半段是 AOF 格式的增量数据。
>
>   **整体格式为**：RDB file
>
>   **开启**：混合持久化的配置参数为 aof-use-rdb-preamble，配置为 yes 时开启混合持久化，在 redis 4 刚引入时，默认是关闭混合持久化的，但是在 redis 5 中默认已经打开了。
>
>   **关闭**：使用 aof-use-rdb-preamble no 配置即可关闭混合持久化。
>
>   混合持久化本质是通过 AOF 后台重写（bgrewriteaof 命令）完成的，不同的是当开启混合持久化时，fork 出的子进程先将当前全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区（aof_rewrite_buf_blocks）的增量命令以 AOF 方式写入到文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。
>
>   **优点**：结合 RDB 和 AOF 的优点, 更快的重写和恢复。
>
>   **缺点**：AOF 文件里面的 RDB 部分不再是 AOF 格式，可读性差。

### 为什么需要 AOF 重写？ AOF 重写的过程、AOF 后台重写存在的问题、如何解决 AOF 后台重写存在的数据不一致问题

> - **为什么需要 AOF 重写？**
>
>   AOF 持久化是通过保存被执行的写命令来记录数据库状态的，随着写入命令的不断增加，AOF 文件中的内容会越来越多，文件的体积也会越来越大。
>
>   如果不加以控制，体积过大的 AOF 文件可能会对 Redis 服务器、甚至整个宿主机造成影响，并且 AOF 文件的体积越大，使用 AOF 文件来进行数据还原所需的时间就越多。
>
>   举个例子， 如果你对一个计数器调用了 100 次 INCR ， 那么仅仅是为了保存这个计数器的当前值， AOF 文件就需要使用 100 条记录。
>
>   然而在实际上， 只使用一条 SET 命令已经足以保存计数器的当前值了， 其余 99 条记录实际上都是多余的。
>
>   为了处理这种情况， Redis 引入了 AOF 重写：可以在不打断服务端处理请求的情况下， 对 AOF 文件进行重建（rebuild）。
>
> -  **AOF 重写的过程**
>
>   描述：Redis 生成新的 AOF 文件来代替旧 AOF 文件，这个新的 AOF 文件包含重建当前数据集所需的最少命令。具体过程是遍历所有数据库的所有键，从数据库读取键现在的值，然后用一条命令去记录键值对，代替之前记录这个键值对的多条命令。
>
>   手动触发:直接调用bgrewriteaof命令。
>
>   自动触发:根据auto-aof-rewrite-min-size和 auto-aof-rewrite-percentage参数确定自动触发时机。
>
>   - auto-aof-rewrite-min-size:表示运行AOF重写时文件最小体积，默认为64MB。
>   - auto-aof-rewrite-percentage  :代表当前AOF 文件空间(aof_currentsize）和上一次重写后AOF 文件空间(aof_base_size)的比值。
>
>   BGREWRITEAOF：fork 子进程来进行 AOF 重写，阻塞只会发生在 fork 子进程的时候，之后主进程可以正常处理请求。
>
> - **AOF 后台重写存在的问题**
>
>   AOF 后台重写使用子进程进行从写，解决了主进程阻塞的问题，但是仍然存在另一个问题：子进程在进行 AOF 重写期间，服务器主进程还需要继续处理命令请求，新的命令可能会对现有的数据库状态进行修改，从而使得当前的数据库状态和重写后的 AOF 文件保存的数据库状态不一致。
>
> - **如何解决 AOF 后台重写存在的数据不一致问题**
>
>   为了解决上述问题，Redis 引入了 AOF 重写缓冲区（aof_rewrite_buf_blocks），这个缓冲区在服务器创建子进程之后开始使用，当 Redis 服务器执行完一个写命令之后，它会同时将这个写命令追加到 AOF 缓冲区和 AOF 重写缓冲区。
>
>   这样一来可以保证：
>
>   1、现有 AOF 文件的处理工作会如常进行。这样即使在重写的中途发生停机，现有的 AOF 文件也还是安全的。
>
>   2、从创建子进程开始，也就是 AOF 重写开始，服务器执行的所有写命令会被记录到 AOF 重写缓冲区里面。
>
>   这样，当子进程完成 AOF 重写工作后，父进程会在 serverCron 中检测到子进程已经重写结束，则会执行以下工作：
>
>   1、将 AOF 重写缓冲区中的所有内容写入到新 AOF 文件中，这时新 AOF 文件所保存的数据库状态将和服务器当前的数据库状态一致。
>
>   2、对新的 AOF 文件进行改名，原子的覆盖现有的 AOF 文件，完成新旧两个 AOF 文件的替换。
>
>   之后，父进程就可以继续像往常一样接受命令请求了。

### RDB、AOF、混合持久，我应该用哪一个？

> 一般来说， 如果想尽量保证数据安全性， 你应该同时使用 RDB 和 AOF 持久化功能，同时可以开启混合持久化。
>
> 如果你非常关心你的数据， 但仍然可以承受数分钟以内的数据丢失， 那么你可以只使用 RDB 持久化。
>
> 如果你的数据是可以丢失的，则可以关闭持久化功能，在这种情况下，Redis 的性能是最高的。
>
> 使用 Redis 通常都是为了提升性能，而如果为了不丢失数据而将 appendfsync  设置为 always 级别时，对 Redis 的性能影响是很大的，在这种不能接受数据丢失的场景，其实可以考虑直接选择 MySQL 等类似的数据库。
>

### 同时开启RDB和AOF，服务重启时如何加载

> 简单来说，如果同时启用了 AOF 和 RDB，Redis 重新启动时，会使用 AOF 文件来重建数据集，因为通常来说， AOF 的数据会更完整。
>
> 而在引入了混合持久化之后，使用 AOF 重建数据集时，会通过文件开头是否为“REDIS”来判断是否为混合持久化。
>

## Redis 事务

> Redis 事务的实现
>
> Redis 可以通过 **`MULTI`，`EXEC`，`DISCARD` 和 `WATCH`** 等命令来实现事务(transaction)功能。
>
> ```bash
> > MULTI
> OK
> > SET PROJECT "JavaGuide"
> QUEUED
> > GET PROJECT
> QUEUED
> > EXEC
> 1) OK
> 2) "JavaGuide"
> ```
>
> `MULTI `命令后可以输入多个命令，Redis 不会立即执行这些命令，而是将它们放到队列，当调用了 `EXEC`  命令后，再执行所有的命令。
>
> 这个过程是这样的：
>
> 1. 开始事务（`MULTI`）；
> 2. 命令入队(批量操作 Redis 的命令，先进先出（FIFO）的顺序执行)；
> 3. 执行事务(`EXEC`)。
>
> 你也可以通过 `DISCARD` 命令取消一个事务，它会清空事务队列中保存的所有命令。
>
> 你可以通过 `WATCH` 命令监听指定的 Key，当调用 `EXEC` 命令执行事务时，如果一个被 `WATCH` 命令监视的 Key 被 **其他客户端/Session** 修改的话，整个事务都不会被执行。
>
> ```bash
> # 客户端 1
> > SET PROJECT "RustGuide"
> OK
> > WATCH PROJECT
> OK
> > MULTI
> OK
> > SET PROJECT "JavaGuide"
> QUEUED
> 
> # 客户端 2
> # 在客户端 1 执行 EXEC 命令提交事务之前修改 PROJECT 的值
> > SET PROJECT "GoGuide"
> 
> # 客户端 1
> # 修改失败，因为 PROJECT 的值被客户端2修改了
> > EXEC
> (nil)
> > GET PROJECT
> "GoGuide"
> ```
>
> 不过，如果 **WATCH** 与 **事务** 在同一个 Session 里，并且被 **WATCH** 监视的 Key 被修改的操作发生在事务内部，这个事务是可以被执行成功的
>
> **不过 redis 的事务并不推荐在实际中使用，如果要使用事务，推荐使用 Lua 脚本，redis 会保证一个 Lua 脚本里的所有命令的原子性。**

## Redis 策略

### Redis 删除过期键的策略（缓存失效策略、数据过期策略）

> 定时删除：在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。对内存最友好，对 CPU 时间最不友好。
>
> 惰性删除：放任键过期不管，但是每次获取键时，都检査键是否过期，如果过期的话，就删除该键；如果没有过期，就返回该键。对 CPU 时间最优化，对内存最不友好。
>
> 定期删除：每隔一段时间，默认100ms，程序就对数据库进行一次检査，删除里面的过期键。至 于要删除多少过期键，以及要检査多少个数据库，则由算法决定。前两种策略的折中，对 CPU 时间和内存的友好程度较平衡。
>
> Redis 使用惰性删除和定期删除。
>

### Redis 的内存淘汰（驱逐）策略

> 当 redis 的内存空间（maxmemory 参数配置）已经用满时，redis 将根据配置的驱逐策略（maxmemory-policy 参数配置），进行相应的动作。
>
> 网上很多资料都是写 6 种，但是其实当前 redis 的淘汰策略已经有 8 种了，多余的两种是 Redis 4.0 新增的，基于 LFU（Least Frequently Used）算法实现的。
>
> - noeviction：默认策略，不淘汰任何 key，直接返回错误
> - allkeys-lru：在所有的 key 中，使用 LRU 算法淘汰部分 key
> - allkeys-lfu：在所有的 key 中，使用 LFU 算法淘汰部分 key，该算法于 Redis 4.0 新增
> - allkeys-random：在所有的 key 中，随机淘汰部分 key
> - volatile-lru：在设置了过期时间的 key 中，使用 LRU 算法淘汰部分 key
> - volatile-lfu：在设置了过期时间的 key 中，使用 LFU 算法淘汰部分 key，该算法于 Redis 4.0 新增
> - volatile-random：在设置了过期时间的 key 中，随机淘汰部分 key
> - volatile-ttl：在设置了过期时间的 key 中，挑选 TTL（time to live，剩余时间）短的 key 淘汰

### Redis 的 LRU 算法怎么实现的？

> Redis 在 redisObject 结构体中定义了一个长度 24 bit 的 unsigned 类型的字段（unsigned lru:LRU_BITS），在 LRU 算法中用来存储对象最后一次被命令程序访问的时间。
>
> 具体的 LRU 算法经历了两个版本。
>
> **版本1：随机选取 N 个淘汰法。**
>
> 最初 Redis 是这样实现的：随机选 N（默认5） 个 key，把空闲时间（idle time）最大的那个 key 移除。这边的 N 可通过 maxmemory-samples 配置项修改。
>
> 就是这么简单，简单得让人不敢相信了，而且十分有效。
>
> 但是这个算法有个明显的缺点：每次都是随机从 N 个里选择 1 个，并没有利用前一轮的历史信息。其实在上一轮移除 key 的过程中，其实是知道了 N 个 key 的 idle time 的情况的，那在下一轮移除 key 时，其实可以利用上一轮的这些信息。这也是 Redis 3.0 的优化思想。
>
> **版本2：Redis 3.0 对 LRU 算法进行改进，引入了缓冲池（pool，默认16）的概念。**
>
> 当每一轮移除 key 时，拿到了 N（默认5）个 key 的 idle time，遍历处理这 N 个 key，如果 key 的 idle time 比 pool 里面的 key 的 idle time 还要大，就把它添加到 pool 里面去。
>
> 当 pool 放满之后，每次如果有新的 key 需要放入，需要将 pool 中 idle time 最小的一个 key 移除。这样相当于 pool 里面始终维护着还未被淘汰的 idle time 最大的 16 个 key。
>
> 当我们每轮要淘汰的时候，直接从 pool 里面取出 idle time 最大的 key（只取1个），将之淘汰掉。
>
> 整个流程相当于随机取 5 个 key 放入 pool，然后淘汰 pool 中空闲时间最大的 key，然后再随机取 5 个 key放入 pool，继续淘汰 pool 中空闲时间最大的 key，一直持续下去。
>
> 在进入淘汰前会计算出需要释放的内存大小，然后就一直循环上述流程，直至释放足够的内存。
>

## Redis 集群⭐

### 集群前置知识

> **数据分布理论**
>
> 分布式数据库首先要解决把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整体数据的一个子集。。
>
> 需要重点关注的是数据分区规则。常见的分区规则有哈希分区和顺序分区两种，哈希分区离散度好、数据分布业务无关、无法顺序访问，顺序分区离散度易倾斜、数据分布业务相关、可顺序访问。
>
> - ##### 节点取余分区
>
>   使用特定的数据，如Redis的键或用户ID，再根据节点数量N使用公式：hash(key)%N计算出哈希值，用来决定数据映射到哪一个节点上。这种方案存在一个问题:当节点数量变化时，如扩容或收缩节点，数据节点映射关系需要重新计算，会导致数据的重新迁移。
>
> - ##### 一致性哈希分区
>
>   一致性哈希分区（ DistributedHash Table)实现思路是为系统中每个节点分配一个 token,范围一般在0~23，这些token构成一个哈希环。数据读写执行节点查找操作时，先根据key计算hash值，然后顺时针找到第一个大于等于该哈希值的token节点。
>
>   但一致性哈希分区存在几个问题:
>
>   1. 当使用少量节点时，节点变化将大范围影响哈希环中数据映射，因此这种方式不适合少量数据节点的分布式方案。
>   2. 增加节点只能对下一个相邻节点有比较好的负载分担效果，对集群中其他的节点基本没有起到负载分担的效果
>
>   ![image.png](redis_imgs\bab557dc5d9c4932bc2682481a50e8b7.png)
>
> - **虚拟一致性哈希分区**
>
>   为了在增删节点的时候，各节点能够保持动态的均衡，将每个真实节点虚拟出若干个虚拟节点，再将这些虚拟节点随机映射到环上。此时每个真实节点不再映射到环上，真实节点只是用来存储键值对，它负责接应各自的一组环上虚拟节点。当对键值对进行存取路由时，首先路由到虚拟节点上，再由虚拟节点找到真实的节点。
>
>   ![image.png](redis_imgs\70c7b32ede304da4bf8498c39e836bc1.png)
>
> - **虚拟槽分区**
>
>   Redis则是利用了虚拟槽分区，可以算上面虚拟一致性哈希分区的变种，它使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽( slot)。这个范围一般远远大于节点数，比如RedisCluster槽范围是0 ～16383。槽是集群内数据管理和迁移的基本单位。采用大范围槽的主要目的是为了方便数据拆分和集群扩展。每个节点会负责一定数量的槽。
>
>   比如集群有3个节点，则每个节点平均大约负责5460个槽。由于采用高质量的哈希算法，每个槽所映射的数据通常比较均匀，将数据平均划分到5个节点进行数据分区。Redis Cluster就是采用虚拟槽分区,下面就介绍Redis 数据分区方法。
>
>   ![image.png](redis_imgs\cbd9c96c04f84d9795c24c5f76cf5234.png)
>
> ?> `面试问题：为什么RedisCluster会设计成16384个槽呢?`
>
> **1.如果槽位为65536，发送心跳信息的消息头达8k，发送的心跳包过于庞大。**
>
> 如上所述，在消息头中，最占空间的是 `myslots[CLUSTER_SLOTS/8]`。 当槽位为65536时，这块的大小是: `65536÷8÷1024=8kb`因为每秒钟，redis节点需要发送一定数量的ping消息作为心跳包，如果槽位为65536，这个ping消息的消息头太大了，浪费带宽。
>
> **2.redis的集群主节点数量基本不可能超过1000个。**
>
> 如上所述，集群节点越多，心跳包的消息体内携带的数据越多。如果节点过1000个，也会导致网络拥堵。因此redis作者，不建议redis cluster节点数量超过1000个。 那么，对于节点数在1000以内的redis cluster集群，16384个槽位够用了。没有必要拓展到65536个。
>
> **3.槽位越小，节点少的情况下，压缩率高**
>
> Redis主节点的配置信息中，它所负责的哈希槽是通过一张bitmap的形式来保存的，在传输过程中，会对bitmap进行压缩，但是如果bitmap的填充率slots / N很高的话(N表示节点数)，bitmap的压缩率就很低。 如果节点数很少，而哈希槽数量很多的话，bitmap的压缩率就很低。
>
> 而16384÷8÷1024=2kb，怎么样，神奇不！

### Redis有哪几种集群方案？

**主从复制、哨兵模式、集群模式。**

<!-- tabs:start -->

#### **《对线面试官》 Redis 主从架构⭐**

**候选者**：不过，我可以给你讲讲现有常见开源的Redis架构（：

**面试官**：那只能这样了，好吧，你开始吧

**候选者**：那我从基础讲起吧？

> **候选者**：在之前提到了Redis有持久化机制，即便Redis重启了，可以依靠RDB或者AOF文件对数据进行重新加载
>
> **候选者**：但在这时，只有一台Redis服务器存储着所有的数据，此时如果Redis服务器「暂时」没办法修复了，那依赖Redis的服务就没了
>
> **候选者**：所以，为了Redis「高可用」，现在基本都会给Redis做「备份」：多启一台Redis服务器，形成「主从架构」
>
> **候选者**：「从服务器」的数据由「主服务器」复制过去，主从服务器的数据是一致的
>
> **候选者**：如果主服务器挂了，那可以「手动」把「从服务器」升级为「主服务器」，缩短不可用时间

![图片](redis_imgs\daefewfdsa.png)

**面试官**：**那「主服务器」是如何把自身的数据「复制」给「从服务器」的呢？**

> **候选者**：「复制」也叫「同步」，在Redis使用的是「PSYNC」命令进行同步，该命令有两种模型：完全重同步和部分重同步
>
> **候选者**：可以简单理解为：如果是第一次「同步」，从服务器没有复制过任何的主服务器，或者从服务器要复制的主服务器跟上次复制的主服务器不一样，那就会采用「完全重同步」模式进行复制
>
> **候选者**：如果只是由于网络中断，只是「短时间」断连，那就会采用「部分重同步」模式进行复制
>
> **候选者**：（假如主从服务器的数据差距实在是过大了，还是会采用「完全重同步」模式进行复制）

![图片](redis_imgs\640dsafdsafds.png)

**面试官**：**那「同步」的原理过程可以稍微讲下嘛？**

> **候选者**：嗯，没问题的
>
> **候选者**：主服务器要复制数据到从服务器，首先是建立Socket「连接」，这个过程会干一些信息校验啊、身份校验啊等事情
>
> **候选者**：然后从服务器就会发「PSYNC」命令给主服务器，要求同步（这时会带「服务器ID」RUNID和「复制进度」offset参数，如果从服务器是新的，那就没有）
>
> **候选者**：主服务器发现这是一个新的从服务器（因为参数没带上来），就会采用「完全重同步」模式，并把「服务器ID」(runId)和「复制进度」(offset)发给从服务器，从服务器就会记下这些信息。
>
> **面试官**：嗯…
>
> **候选者**：随后，主服务器会在后台生成RDB文件，通过前面建立好的连接发给从服务器
>
> **候选者**：从服务器收到RDB文件后，首先把自己的数据清空，然后对RDB文件进行加载恢复
>
> **候选者**：这个过程中，主服务器也没闲着（继续接收着客户端的请求）
>
> **面试官**：嗯…
>
> **候选者**：主服务器把生成RDB文件「之后修改的命令」会用「buffer」记录下来，等到从服务器加载完RDB之后，主服务器会把「buffer」记录下的命令都发给从服务器
>
> **候选者**：这样一来，主从服务器就达到了数据一致性了（复制过程是异步的，所以数据是『最终一致性』）

**面试官**：嗯…

**面试官**：**那「部分重同步」的过程呢？**

> **候选者**：嗯，其实就是靠「offset」来进行部分重同步。每次主服务器传播命令的时候，都会把「offset」给到从服务器
>
> **候选者**：主服务器和从服务器都会将「offset」保存起来（如果两边的offset存在差异，那么说明主从服务器数据未完全同步）
>
> **候选者**：从服务器断连之后，就会发「PSYNC」命令给主服务器，同样也会带着RUNID和offset（重连之后，这些信息还是存在的）
>
> **面试官**：嗯…
>
> **候选者**：主服务器收到命令之后，看RUNID是否能对得上，对得上，说明这可能以前就复制过一部分了
>
> **候选者**：接着检查该「offset」是否在主服务器记录的offset还存在
>
> **候选者**：（这里解释下，因为主服务器记录offset使用的是一个环形buffer，如果该buffer满了，会覆盖以前的记录）

![图片](redis_imgs\640aduisafbuaibf.png)

> **候选者**：如果找到了，那就把从缺失的一部分offer开始，把对应的修改命令发给从服务器
>
> **候选者**：如果从环形buffer没找到，那只能使用「完全重同步」模式再次进行主从复制了

**面试官**：**主从复制这块我了解了，那你说到现在，Redis主库如果挂了，你还是得「手动」将从库升级为主库啊**

**面试官**：**你知道有什么办法能做到「自动」进行故障恢复吗？**

> **候选者**：必须的啊，接下来就到了「哨兵」登场了
>
> **面试官**：开始你的表演吧。
>
> **候选者**：「哨兵」干的事情主要就是：监控（监控主服务器的状态）、选主（主服务器挂了，在从服务器选出一个作为主服务器）、通知（故障发送消息给管理员）和配置（作为配置中心，提供当前主服务器的信息）
>
> **候选者**：可以把「哨兵」当做是运行在「特殊」模式下的Redis服务器，为了「高可用」，哨兵也是集群架构的。

![图片](redis_imgs\640sgjsigbfdjisgob.png)

> **候选者**：首先它需要跟Redis主从服务器创建对应的连接（获取它们的信息）
>
> **候选者**：每个哨兵不断地用ping命令看主服务器有没有下线，如果主服务器在「配置时间」内没有正常响应，那当前哨兵就「主观」认为该主服务器下线了
>
> **候选者**：其他「哨兵」同样也会ping该主服务器，如果「足够多」（还是看配置）的哨兵认为该主服务器已经下线，那就认为「客观下线」，这时就要对主服务器执行故障转移操作。
>
> **面试官**：嗯…
>
> **候选者**：「哨兵」之间会选出一个「领头」，选出领头的规则也比较多，总的来说就是先到先得(哪个快，就选哪个)
>
> **候选者**：由「领头哨兵」对已下线的主服务器进行故障转移
>
> **面试官**：嗯…
>
> **候选者**：首先要在「从服务器」上挑选出一个，来作为主服务器
>
> **候选者**：（这里也挑选讲究，比如：从库的配置优先级、要判断哪个从服务器的复制offset最大、RunID大小、跟master断开连接的时长…)
>
> **候选者**：然后，以前的从服务器都需要跟新的主服务器进行「主从复制」
>
> **候选者**：已经下线的主服务器，再次重连的时候，需要让他成为新的主服务器的从服务器

![图片](redis_imgs\640afsdagfsgfd.png)

**面试官**：**嗯…我想问问，Redis在主从复制的和故障转移的过程中会导致数据丢失吗**

> **候选者**：显然是会的，从上面的「主从复制」流程来看，这个过程是异步的（在复制的过程中：主服务器会一直接收请求，然后把修改命令发给从服务器）
>
> **候选者**：假如主服务器的命令还没发完给从服务器，自己就挂掉了。这时候想要让从服务器顶上主服务器，但从服务器的数据是不全的（：
>
> **候选者**：还有另一种情况就是：有可能哨兵认为主服务器挂了，但真实是主服务器并没有挂( 网络抖动)，而哨兵已经选举了一台从服务器当做是主服务器了，此时「客户端」还没反应过来，还继续写向旧主服务器写数据
>
> **候选者**：等到旧主服务器重连的时候，已经被纳入到新主服务器的从服务器了…所以，那段时间里，客户端写进旧主服务器的数据就丢了

![图片](D:\mmdz-blog\docs\Interview\redis_imgs\640csdadfsabfdsb.png)

> **候选者**：上面这两种情况（主从复制延迟&&脑裂），都可以通过配置来「尽可能」避免数据的丢失
>
> **候选者**：（达到一定的阈值，直接禁止主服务器接收写请求，企图减少数据丢失的风险）

?>**解决方案**

> redis的配置文件中，存在两个参数
>
> ```text
> min-slaves-to-write 3
> min-slaves-max-lag 10
> ```
>
> **第一个参数表示连接到master的最少slave数量**
> **第二个参数表示slave连接到master的最大延迟时间**
> 按照上面的配置，要求至少3个slave节点，且数据复制和同步的延迟不能超过10秒，否则的话master就会拒绝写请求，配置了这两个参数之后，如果发生集群脑裂，原先的master节点接收到客户端的写入请求会拒绝，就可以减少数据同步之后的数据丢失。
>
> 注意：较新版本的redis.conf文件中的参数变成了
>
> ```text
> min-replicas-to-write 3
> min-replicas-max-lag 10
> ```
>
> redis中的异步复制情况下的数据丢失问题也能使用这两个参数

#### **《对线面试官》 Redis 分片集群**

**面试官**：**聊下Redis的分片集群**

> **候选者**：1. 主从模式下实现读写分离的架构，可以让多个从服务器承载「读流量」，但面对「写流量」时，始终是只有主服务器在抗。
>
> **候选者**：2. 「纵向扩展」升级Redis服务器硬件能力，但升级至一定程度下，就不划算了。
>
> **候选者**：纵向扩展意味着「大内存」，Redis持久化时的”成本”会加大（Redis做RDB持久化，是全量的，fork子进程时有可能由于使用内存过大，导致主线程阻塞时间过长）
>
> **候选者**：所以，「单实例」是有瓶颈的
>
> **候选者**：「纵向扩展」不行，就「横向扩展」呗。
>
> **候选者**：用多个Redis实例来组成一个集群，按照一定的规则把数据「分发」到不同的Redis实例上。当集群所有的Redis实例的数据加起来，那这份数据就是全的
>
> **候选者**：其实就是「分布式」的概念
>
> ------
>
> 【**Redis Cluster数据路由**】
>
> **候选者**：从前面就得知了，要「分布式存储」，就肯定避免不了对数据进行「分发」(也是路由的意思)
>
> **候选者**：从Redis Cluster讲起吧，它的「路由」是做在客户端的（SDK已经集成了路由转发的功能）
>
> **候选者**：Redis Cluster对数据的分发的逻辑中，涉及到「哈希槽」(Hash Solt)的概念
>
> **候选者**：Redis Cluster默认一个集群有16384个哈希槽，这些哈希槽会分配到不同的Redis实例中
>
> **候选者**：至于怎么「瓜分」，可以直接均分，也可以「手动」设置每个Redis实例的哈希槽，全由我们来决定
>
> **候选者**：重要的是，我们要把这16384个都得瓜分完，不能有剩余！
>
> **候选者**：当客户端有数据进行写入的时候，首先会对key按照CRC16算法计算出16bit的值（可以理解为就是做hash），然后得到的值对16384进行取模
>
> **候选者**：取模之后，自然就得到其中一个哈希槽，然后就可以将数据插入到分配至该哈希槽的Redis实例中
>
> **面试官**：**那问题就来了，现在客户端通过hash算法算出了哈希槽的位置，那客户端怎么知道这个哈希槽在哪台Redis实例上呢？**
>
> **候选者**：是这样的，在集群的中每个Redis实例都会向其他实例「传播」自己所负责的哈希槽有哪些。这样一来，每台Redis实例就可以记录着「所有哈希槽与实例」的关系了（：
>
> **候选者**：有了这个映射关系以后，客户端也会「缓存」一份到自己的本地上，那自然客户端就知道去哪个Redis实例上操作了
>
> ------
>
> 

**面试官**：**那我又有问题了，在集群里也可以新增或者删除Redis实例啊，这个怎么整？**

> **候选者**：当集群删除或者新增Redis实例时，那总会有某Redis实例所负责的哈希槽关系会发生变化
>
> **候选者**：发生变化的信息会通过消息发送至整个集群中，所有的Redis实例都会知道该变化，然后更新自己所保存的映射关系
>
> **候选者**：但这时候，客户端其实是不感知的（：
>
> **候选者**：所以，当客户端请求时某Key时，还是会请求到「原来」的Redis实例上。而原来的Redis实例会返回「moved」命令，告诉客户端应该要去新的Redis实例上去请求啦
>
> **候选者**：客户端接收到「moved」命令之后，就知道去新的Redis实例请求了，并且更新「缓存哈希槽与实例之间的映射关系」
>
> **候选者**：总结起来就是：数据迁移完毕后被响应，客户端会收到「moved」命令，并且会更新本地缓存

**面试官**：**那数据还没完全迁移完呢？**

> **候选者**：如果数据还没完全迁移完，那这时候会返回客户端「ask」命令。也是让客户端去请求新的Redis实例，但客户端这时候不会更新本地缓存
>
> **面试官**：了解了
>
> **面试官**：说白了就是，如果集群Redis实例存在变动，由于Redis实例之间会「通讯」
>
> **面试官**：所以等到客户端请求时，Redis实例总会知道客户端所要请求的数据在哪个Redis实例上
>
> **面试官**：如果已经迁移完毕了，那就返回「move」命令告诉客户端应该去找哪个Redis实例要数据，并且客户端应该更新自己的缓存(映射关系)
>
> **面试官**：如果正在迁移中，那就返回「ack」命令告诉客户端应该去找哪个Redis实例要数据
>
> **候选者**：不愧是你…

**面试官**：**那你知道为什么哈希槽是16384个吗？**

> **候选者**：嗯，这个。是这样的，Redis实例之间「通讯」会相互交换「槽信息」，那如果槽过多（意味着网络包会变大），网络包变大，那是不是就意味着会「过度占用」网络的带宽
>
> **候选者**：另外一块是，Redis作者认为集群在一般情况下是不会超过1000个实例
>
> **候选者**：那就取了16384个，即可以将数据合理打散至Redis集群中的不同实例，又不会在交换数据时导致带宽占用过多

**面试官**：**那你知道为什么对数据进行分区在Redis中用的是「哈希槽」这种方式吗？而不是一致性哈希算法**

> **候选者**：在我理解下，一致性哈希算法就是有个「哈希环」，当客户端请求时，会对Key进行hash，确定在哈希环上的位置，然后顺时针往后找，找到的第一个真实节点
>
> **候选者**：一致性哈希算法比「传统固定取模」的好处就是：如果集群中需要新增或删除某实例，只会影响一小部分的数据
>
> **候选者**：但如果在集群中新增或者删除实例，在一致性哈希算法下，就得知道是「哪一部分数据」受到影响了，需要进行对受影响的数据进行迁移
>
> **面试官**：嗯…
>
> **候选者**：而哈希槽的方式，我们通过上面已经可以发现：在集群中的每个实例都能拿到槽位相关的信息
>
> **候选者**：当客户端对key进行hash运算之后，如果发现请求的实例没有相关的数据，实例会返回「重定向」命令告诉客户端应该去哪儿请求
>
> **候选者**：集群的扩容、缩容都是以「哈希槽」作为基本单位进行操作，总的来说就是「实现」会更加简单（简洁，高效，有弹性）。过程大概就是把部分槽进行重新分配，然后迁移槽中的数据即可，不会影响到集群中某个实例的所有数据。

### 扩缩容

- **扩容原理**

  - redis cluster可以实现对节点的灵活上下线控制
  - 3个主节点分别维护自己负责的槽和对应的数据，如果希望加入一个节点实现扩容，就需要把一部分槽和数据迁移和新节点

- **缩容原理**

  - 如果下线的是slave，那么通知其他节点忘记下线的节点

  - 如果下线的是master，那么将此master的slot迁移到其他master之后，通知其他节点忘记此master节点

  - 其他节点都忘记了下线的节点之后，此节点就可以正常停止服务了

### 故障转移

1. 当slave发现自己的master挂了
2. 将自己记录的currentEpoch加1,并向其他节点请求投票给自己成为master
3. 其他节点收到请求,只有master会回应,判断请求的合法性,并投票,可能会有多个slave请求,每个master只能投一票
4. slave收集master的投票
5. 当slave收到的投票超过半数后就可以成为master
6. 广播消息通知其他节点
   - 当slave发现自己的master挂了并不会立即进行请求投票,会有一定的延时,确保其他的master也意识到当前的master挂了,否则master可能会拒绝投票
   - 延时计算公式Delay=500ms+random(0-500)ms+Slave_rank* 100ms(slave_rank为复制数据的等级,等级越小表示复制数据越多也是为了保证能让拥有最新数据的slave最先发起选举)

<!-- tabs:end -->

## Redis 分布式锁

### 分布式锁

<!-- tabs:start -->

#### **Redis 分布式锁**

> 想要实现分布式锁，必须要求 Redis 有「互斥」的能力；
>
> Redis 是单线程，可以保证命令的原子性；同时可以使用 SETNX 命令，这个命令表示SET if Not Exists，即如果 key 不存在，才会设置它的值，否则什么也不做。
>
> 但是会出现一些 业务场景下 带来的一些问题：时间过期死锁、锁被别人释放、锁过期时间小于业务执行时间
>
> - **为了避免死锁，设置过期时间**
>
>   在 Redis 2.6.12 之后，Redis 扩展了 SET 命令的参数，用这一条命令就可以了：**SET lock 1 EX 10 NX**
>
> - **锁被别人释放怎么办？**
>
>   使用Lua脚本来保证原子操作，设置一个只有自己知道的「唯一标识」进去。
>
> - **锁过期时间不好评估怎么办？**
>
>   **分布式锁加入看门狗**
>
>   加锁时，先设置一个过期时间，然后我们开启一个「守护线程」，定时去检测这个锁的失效时间，如果锁快要过期了，操作共享资源还未完成，那么就自动对锁进行「续期」，重新设置过期时间。
>
>   这个守护线程我们一般也把它叫做「看门狗」线程。
>
> **Redisson中的分布式锁**
>
> Redisson 在**基于NIO的Netty框架**上，生产环境使用分布式锁。
>
> 通过Redisson ，我们可以直接使用 RLock 对象进行加锁、解锁操作就可以了。
>
> **看门狗机制**
>
> lock.lock(); 是阻塞式等待的，默认加锁时间是30s；如果业务超长，运行期间会自动续期到30s。不用担心业务时间长，锁自动过期被删掉；加锁的业务只要运行完成，就不会给当前锁续期，即使不手动解锁，锁默认会在30s内自动过期，不会产生死锁问题；
>
> 也可以自己指定解锁时间lock.lock(10,TimeUnit.SECONDS)，10秒钟自动解锁，自己指定解锁时间redis不会自动续期；
>
> 指定解锁时间带来的问题：如果业务执行的时间超过指定时间，redis会自动解锁；当前业务执行完后又要解锁，可能会解锁到另一条线程加的锁，所以自己指定的解锁时间一定大于业务执行的时间！
>
> 看门狗原理
>
> 1、如果我们指定了锁的超时时间，就发送给redis执行脚本，进行占锁，默认超时就是我们制定的时间，不会自动续期；
> 2、如果我们未指定锁的超时时间，就使用 lockWatchdogTimeout = 30 * 1000 【看门狗默认时间】
>
> 只要占锁成功，就会启动一个定时任务【重新给锁设置过期时间，新的过期时间就是看门狗的默认时间】,每隔10秒都会自动再续成30秒；
> 自动续期时间：internalLockLeaseTime 【看门狗时间 30s】 / 3， 10s

Redisson中的分布式锁原理（了解）



#### **Zookeeper 实现分布式锁**

Bonjour!

<!-- tabs:end -->



### 集群下的锁还安全么？

> 之前分析的场景都是，锁在「单个」Redis实例中可能产生的问题，并没有涉及到 Redis 的部署架构细节。
>
> 而我们在使用 Redis 时，一般会采用主从集群 +哨兵的模式部署，这样做的好处在于，当主库异常宕机时，哨兵可以实现「故障自动切换」，把从库提升为主库，继续提供服务，以此保证可用性。
>
> 但是因为主从复制是异步的，那么就不可避免会发生的锁数据丢失问题（**加了锁却没来得及同步过来**）。从库被哨兵提升为新主库，这个锁在新的主库上，丢失了！

### 守护线程续命的方案有什么问题吗/

> Redisson 使用看门狗（守护线程）“续命”的方案在大多数场景下是挺不错的，也被广泛应用于生产环境，但是在极端情况下还是会存在问题。
>
> 问题例子如下：
>
> 线程1首先获取锁成功，将键值对写入 redis 的 master 节点
> 在 redis 将该键值对同步到 slave 节点之前，master 发生了故障
> redis 触发故障转移，其中一个 slave 升级为新的 master
> 此时新的 master 并不包含线程1写入的键值对，因此线程2尝试获取锁也可以成功拿到锁
> 此时相当于有两个线程获取到了锁，可能会导致各种预期之外的情况发生，例如最常见的脏数据
> 解决方法：上述问题的根本原因主要是由于 redis 异步复制带来的数据不一致问题导致的，因此解决的方向就是保证数据的一致。
>
> 当前比较主流的解法和思路有两种：
>
> 1）Redis 作者提出的 RedLock；2）Zookeeper 实现的分布式锁。

### RedLock

> Redis 作者提出的 Redlock方案，是如何解决主从切换后，锁失效问题的。
>
> **Redlock 的方案基于一个前提：**
>
> 不再需要部署从库和哨兵实例，只部署主库；但主库要部署多个，官方推荐至少 5 个实例。
>
> **注意：不是部署 Redis Cluster，就是部署 5 个简单的 Redis 实例。它们之间没有任何关系，都是一个个孤立的实例。**
>
> `Redlock实现整体流程`
>
> 1. 客户端先获取「当前时间戳T1」
> 2. 客户端依次向这 5 个 Redis 实例发起加锁请求
> 3. 如果客户端从 >=3 个（大多数）以上Redis 实例加锁成功，则再次获取「当前时间戳T2」，如果 T2 - T1 &#x3c; 锁的过期时间，此时，认为客户端加锁成功，否则认为加锁失败。
> 4. 加锁成功，去操作共享资源
> 5. 加锁失败/释放锁，向「全部节点」发起释放锁请求。
>
> 所以总的来说：客户端在多个 Redis 实例上申请加锁；必须保证大多数节点加锁成功；大多数节点加锁的总耗时，要小于锁设置的过期时间；释放锁，要向全部节点发起释放锁请求。
>
> 该方案看着挺美好的，但是实际上我所了解到的在实际生产上应用的不多，主要有两个原因：1）该方案的成本似乎有点高，需要使用5个实例；2）该方案一样存在问题。
>
> **该方案主要存以下问题：**
>
> 严重依赖系统时钟。如果线程1从3个实例获取到了锁，但是这3个实例中的某个实例的系统时间走的稍微快一点，则它持有的锁会提前过期被释放，当他释放后，此时又有3个实例是空闲的，则线程2也可以获取到锁，则可能出现两个线程同时持有锁了。
> 如果线程1从3个实例获取到了锁，但是万一其中有1台重启了，则此时又有3个实例是空闲的，则线程2也可以获取到锁，此时又出现两个线程同时持有锁了。

## 数据一致性&&缓存穿透、击穿、雪崩

### 数据一致性

> 1. 先写 Redis，再写 MySQL
>
>    这种方案，我肯定不会用，万一 DB 挂了，你把数据写到缓存，DB 无数据，这个是灾难性的；
>
>    我之前也见同学这么用过，如果写 DB 失败，对 Redis 进行逆操作，那如果逆操作失败呢，是不是还要搞个重试？
>
> 2. 先写 MySQL，再写 Redis
>
>    对于并发量、一致性要求不高的项目，很多就是这么用的，我之前也经常这么搞，但是不建议这么做；
>
>    当 Redis 瞬间不可用的情况，需要报警出来，然后线下处理。
>
> 3. 先删除 Redis，再写 MySQL
>
>    这种方式，我还真没用过，直接忽略吧。
>
> 4. 先删除 Redis，再写 MySQL，再删除 Redis
>
>    这种方式虽然可行，但是感觉好复杂，还要搞个消息队列去异步删除 Redis。
>
> 5. 先写 MySQL，再删除 Redis
>
>    比较推荐这种方式，删除 Redis 如果失败，可以再多重试几次，否则报警出来；
>
>    这个方案，是实时性中最好的方案，在一些高并发场景中，推荐这种。
>
> 6. 先写 MySQL，通过 Binlog，异步更新 Redis
>
>    对于异地容灾、数据汇总等，建议会用这种方式，比如 binlog + kafka，数据的一致性也可以达到秒级；
>
>    纯粹的高并发场景，不建议用这种方案，比如抢购、秒杀等。
>
> 个人结论：
>
> - 实时一致性方案：采用 “先写 MySQL，再删除 Redis” 的策略，这种情况虽然也会存在两者不一致，但是需要满足的条件有点苛刻，所以是满足实时性条件下，能尽量满足一致性的最优解。
>
> - 最终一致性方案：采用 “先写 MySQL，通过 Binlog，异步更新 Redis”，可以通过 Binlog，结合消息队列异步更新 Redis，是最终一致性的最优解。
>

### 缓存穿透、击穿、雪崩

> - **缓存穿透**
>
>   描述：访问一个缓存和数据库都不存在的 key，此时会直接打到数据库上，并且查不到数据，没法写缓存，所以下一次同样会打到数据库上。
>
>   此时，缓存起不到作用，请求每次都会走到数据库，流量大时数据库可能会被打挂。此时缓存就好像被“穿透”了一样，起不到任何作用。
>
>   解决方案：
>
>   1）接口校验。在正常业务流程中可能会存在少量访问不存在 key 的情况，但是一般不会出现大量的情况，所以这种场景最大的可能性是遭受了非法攻击。可以在最外层先做一层校验：用户鉴权、数据合法性校验等，例如商品查询中，商品的ID是正整数，则可以直接对非正整数直接过滤等等。
>
>   2）缓存空值。当访问缓存和DB都没有查询到值时，可以将空值写进缓存，但是设置较短的过期时间，该时间需要根据产品业务特性来设置。
>
>   3）布隆过滤器。使用布隆过滤器存储所有可能访问的 key，不存在的 key 直接被过滤，存在的 key 则再进一步查询缓存和数据库。
>
> - **缓存击穿**
>
>   描述：某一个热点 key，在缓存过期的一瞬间，同时有大量的请求打进来，由于此时缓存过期了，所以请求最终都会走到数据库，造成瞬时数据库请求量大、压力骤增，甚至可能打垮数据库。
>
>   解决方案：
>
>   1）加互斥锁。在并发的多个请求中，只有第一个请求线程能拿到锁并执行数据库查询操作，其他的线程拿不到锁就阻塞等着，等到第一个线程将数据写入缓存后，直接走缓存。
>
>   业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。
>
>   使用 redis 分布式锁的伪代码，仅供参考：
>
>   ![image.png](redis_imgs\d360eff05cd945739aa9c81ef633c300.png)
>
>   2）热点数据不过期。直接将缓存设置为不过期，然后由定时任务去异步加载数据，更新缓存。
>
>   这种方式适用于比较极端的场景，例如流量特别特别大的场景，使用时需要考虑业务能接受数据不一致的时间，还有就是异常情况的处理，不要到时候缓存刷新不上，一直是脏数据，那就凉了。
>
> - **缓存雪崩**
>
>   描述：大量的热点 key 设置了相同的过期时间，导在缓存在同一时刻全部失效，造成瞬时数据库请求量大、压力骤增，引起雪崩，甚至导致数据库被打挂。
>
>   缓存雪崩其实有点像“升级版的缓存击穿”，缓存击穿是一个热点 key，缓存雪崩是一组热点 key。
>
>   解决方案：
>
>   1）过期时间打散。既然是大量缓存集中失效，那最容易想到就是让他们不集中生效。可以给缓存的过期时间时加上一个随机值时间，使得每个 key 的过期时间分布开来，不会集中在同一时刻失效。
>
>   2）热点数据不过期。该方式和缓存击穿一样，也是要着重考虑刷新的时间间隔和数据异常如何处理的情况。
>
>   3）加互斥锁。该方式和缓存击穿一样，按 key 维度加锁，对于同一个 key，只允许一个线程去计算，其他线程原地阻塞等待第一个线程的计算结果，然后直接走缓存即可。

### 热点Key

> - **原因**
>
>   热点问题产生的原因大致有以下两种：
>
>   用户消费的数据远大于生产的数据（热卖商品、热点新闻、热点评论、明星直播）。
>
>   在日常工作生活中一些突发的事件，例如：双十一期间某些热门商品的降价促销，当这其中的某一件商品被数万次点击浏览或者购买时，会形成一个较大的需求量，这种情况下就会造成热点问题。同理，被大量刊发、浏览的热点新闻、热点评论、明星直播等，这些典型的读多写少的场景也会产生热点问题。
>
>   请求分片集中，超过单Server的性能极限。在服务端读数据进行访问时，往往会对数据进行分片切分，此过程中会在某一主机Server上对相应的Key进行访问，当访问超过Server极限时，就会导致热点Key问题的产生。
>
>   **危害**
>
>   1、流量集中，达到物理网卡上限。
>
>   2、请求过多，缓存分片服务被打垮。
>
>   3、DB击穿，引起业务雪崩。
>
> - **发现热点key**
>
>   1. 凭借业务经验，进行预估哪些是热key
>
>      针对业务提前预估出访问频繁的热点key，例如秒杀商品业务中，秒杀的商品都是热点key。
>
>      当然并非所有的业务都容易预估出热点key，可能出现漏掉或者预估错误的情况。
>
>   2. 在客户端进行收集
>
>      这个方式就是在操作redis之前，加入一行代码进行数据统计。那么这个数据统计的方式有很多种，也可以是给外部的通讯系统发送一个通知信息。缺点就是对客户端代码造成入侵。
>
>   3. 用redis自带命令
>
>      (1)monitor命令，该命令可以实时抓取出redis服务器接收到的命令，然后写代码统计出热key是啥。当然，也有现成的分析工具可以给你使用，比如redis-faina。但是该命令在高并发的条件下，有内存增暴增的隐患，还会降低redis的性能。
>
>      (2)hotkeys参数，redis 4.0.3提供了redis-cli的热点key发现功能，执行redis-cli时加上–hotkeys选项即可。但是该参数在执行的时候，如果key比较多，执行起来比较慢。
>
>   4. 自己抓包评估
>
>      Redis客户端使用TCP协议与服务端进行交互，通信协议采用的是RESP。自己写程序监听端口，按照RESP协议规则解析数据，进行分析。缺点就是开发成本高，维护困难，有丢包可能性。
>
>   5. 在Proxy层做收集
>
>      有些集群架构是下面这样的，Proxy可以是Twemproxy，是统一的入口。可以在Proxy层做收集上报，但是缺点很明显，并非所有的redis集群架构都有proxy。
>
> - **解决热点key**
>
>   发现热点key之后，需要对热点key进行处理。
>
>   1. 使用二级缓存
>
>      比如可以使用 ehcache，或者一个HashMap都可以。在你发现热key以后，把热key加载到系统的JVM中。
>
>      针对这种热key请求，会直接从jvm中取，而不会走到redis层。
>
>   2. key分散
>
>      将热点key分散为多个子key，然后存储到缓存集群的不同机器上，这些子key对应的value都和热点key是一样的。当通过热点key去查询数据时，通过某种hash算法随机选择一个子key，然后再去访问缓存机器，将热点分散到了多个子key上。

### BigKey

> - **BigKey问题是什么**
>
>   bigkey是指key对应的value所占的内存空间比较大，例如一个字符串类型的value可以最大存到512MB。
>
>   bigkey的危害体现在三个方面:
>
>   1、内存空间不均匀.(平衡):例如在Redis Cluster中，bigkey 会造成节点的内存空间使用不均匀。
>
>   2、超时阻塞:由于Redis单线程的特性，操作bigkey比较耗时，也就意味着阻塞Redis可能性增大。
>
>   3、网络拥塞:每次获取bigkey产生的网络流量较大
>
> - **BigKey问题怎么产生**
>
>   1. redis中的key-value键值对设置不当，造成key对应的**value值**特别大。
>   2. 对于list，set这种类型的结构，**无效的数据**没有及时的删除。
>   3. 对业务分析不准确，导致**实际业务中value值**过大，如热点问题。
>
> - **BigKey问题怎么定位**
>
>   1. 使用redis自带的命令 redis-cli --bigkeys  在线扫描大key，显示的信息不详细，并且这个命令不是阻塞的，所以不影响redis的正常使用。
>   2. 使用第三方工具redis-rdb-tools，使用过程中会先使用bgsave命令dump一个rdb镜像，然后对这个镜像进行分析，因为bgsave是redis中的一个子线程进行生成镜像的，并不影响redis对外提供服务。
>
> - **BigKey问题如何解决**
>
>   1. 针对BigKey进行**拆分**
>
>      通过将BigKey拆分成多个小Key的键值对，并且拆分后的对应的value大小和拆分成的成员数量比较合理，然后进行存储即可，在获取的时候通过get不同的key或是用mget批量获取存储的键值对。
>
>   2. 清理**无效**的数据
>
>      这个主要是针对像是list和set这种类型，在使用的过程中，list和set中对应的内容不断增加，但是由于之前存储的已经是无效的了，需要定时的对list和set进行清理。

### 数据倾斜

> 数据倾斜其实分为访问量倾斜或者数据量倾斜:
>
> 1、hotkey出现造成集群访问量倾斜
>
> 2、bigkey 造成集群数据量倾斜
>
> 解决方案前面已经说过了，这里不再赘述。

### Redis脑裂

> 所谓的脑裂，就是指在有主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。

## Redis 其它

### Redis 的 Java 客户端有哪些？官方推荐哪个？

> Redis 官网展示的 Java 客户端如下图所示，其中官方推荐的是标星的3个：Jedis、Redisson 和 lettuce。

### Redis 在项目中的使用场景

> 缓存（核心）、分布式锁（set + lua 脚本）、排行榜（zset）、计数（incrby）、消息队列（stream）、地理位置（geo）、访客统计（hyperloglog）等。

### Redis 里面有1亿个 key，其中有 10 个 key 是包含 java，如何将它们全部找出来？

> 1）keys *java* 命令，该命令性能很好，但是在数据量特别大的时候会有性能问题
>
> 2）scan 0 MATCH *java* 命令，基于游标的迭代器，更好的选择
>
> SCAN 命令是一个基于游标的迭代器（cursor based iterator）： SCAN 命令每次被调用之后， 都会向用户返回一个新的游标， 用户在下次迭代时需要使用这个新游标作为 SCAN 命令的游标参数， 以此来延续之前的迭代过程。
>
> 当 SCAN 命令的游标参数被设置为 0 时， 服务器将开始一次新的迭代， 而当服务器向用户返回值为 0 的游标时， 表示迭代已结束。
>

### 用过 Redis 做消息队列么？

> Redis 本身提供了一些组件来实现消息队列的功能，但是多多少少都存在一些缺点，相比于市面上成熟的消息队列，例如 Kafka、Rocket MQ 来说并没有优势，因此目前我们并没有使用 Redis 来做消息队列。
>
> 关于 Redis 做消息队列的常见方案主要有以下：
>
> 1）Redis 5.0 之前可以使用 List（blocking）、Pub/Sub 等来实现轻量级的消息发布订阅功能组件，但是这两种实现方式都有很明显的缺点，两者中相对完善的 Pub/Sub 的主要缺点就是消息无法持久化，如果出现网络断开、Redis 宕机等，消息就会被丢弃。
>
> 2）为了解决 Pub/Sub 模式等的缺点，Redis 在 5.0 引入了全新的 Stream，Stream 借鉴了很多 Kafka 的设计思想，有以下几个特点：
>
> 提供了消息的持久化和主备复制功能，可以让任何客户端访问任何时刻的数据，并且能记住每一个客户端的访问位置，还能保证消息不丢失。
> 引入了消费者组的概念，不同组接收到的数据完全一样（前提是条件一样），但是组内的消费者则是竞争关系。
> Redis Stream 相比于 pub/sub 已经有很明显的改善，但是相比于 Kafka，其实没有优势，同时存在：尚未经过大量验证、成本较高、不支持分区（partition）、无法支持大规模数据等问题。

### Redis 和 Memcached 的比较

> 1. 数据结构：memcached 支持简单的 key-value 数据结构，而 redis 支持丰富的数据结构：String、List、Set、Hash、SortedSet 等。
> 2. 数据存储：memcached 和 redis 的数据都是全部在内存中。
>
> 3. 网上有一种说法 “当物理内存用完时，Redis可以将一些很久没用到的 value 交换到磁盘，同时在内存中清除”，这边指的是 redis 里的虚拟内存（Virtual Memory）功能，该功能在 Redis 2.0 被引入，但是在 Redis 2.4 中被默认关闭，并标记为废弃，而在后续版中被完全移除。
>
> 4. 持久化：memcached 不支持持久化，redis 支持将数据持久化到磁盘
>
> 5. 灾难恢复：实例挂掉后，memcached 数据不可恢复，redis 可通过 RDB、AOF 恢复，但是还是会有数据丢失问题
> 6. 事件库：memcached 使用 Libevent 事件库，redis 自己封装了简易事件库 AeEvent
>
> 7. 过期键删除策略：memcached 使用惰性删除，redis 使用惰性删除+定期删除
>
> 8. 内存驱逐（淘汰）策略：memcached 主要为 LRU 算法，redis 当前支持8种淘汰策略，见本文第16题
>
> 9. 性能比较
>    1. 按“CPU 单核” 维度比较：由于 Redis 只使用单核，而 Memcached 可以使用多核，所以在比较上：在处理小数据时，平均每一个核上 Redis 比 Memcached 性能更高，而在 100k 左右的大数据时， Memcached 性能要高于 Redis。
>    2. 按“实例”维度进行比较：由于 Memcached 多线程的特性，在 Redis 6.0 之前，通常情况下 Memcached 性能是要高于 Redis 的，同时实例的 CPU 核数越多，Memcached 的性能优势越大。
>    3. 至于网上说的 redis 的性能比 memcached 快很多，这个说法就离谱。

