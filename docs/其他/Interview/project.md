# 项目

> 4年半开发经验，参与过网页及 App 的开发，以及多款数据采集的对接，涉足贸易、教育、工业 Mes、Wms 、物联网多个行业。具有分布式、高并发、高可用、大数据量的系统研发经验，同时拥有扎实的技术功底，对 spring、spring boot、spring cloud、mybatis 等开源框架熟练使用，并阅读过源码。
> 本人有过担任项目经理的角色，根据项目需求输出项目开发计划，主导项目计划进度的推进，并在项目开发周期内，准时上线项目并获取较满意的评价。

## 项目描述

> CN项目管理中心 是我们公司根据自己的业务自实现的一个系统；主要是研发 公司产品（从项目竞标，拿下合同，再进行多阶段的产品研发，最终实现量产的 整个产品）的过程中，去监控 员工工作饱和度，同时实现 项目人力成本和非人力成本 预算把控。

## 项目技能点

![](project_imgs\up-82e9722ecb846786405a904bafcf19f73f3.png)



![](https://pic2.zhimg.com/v2-39671a2880f35c89d4a0d5dd324dbdb9_r.jpg)

### Mysql优化

**设计技术：**对于慢查询的统计类型的动态SQL进行优化，查询速度慢，严重影响用户体验，通过对SQL进行优化，重新设计索引，利用数仓的思想，把数据分段缓存，等手段把整个结果时间优化到了1秒左右。

**解决过程：**

- 问题发现

  线上的慢查询问题。对于项目中的慢查询，运维会定期统计慢查询SQL（开启慢查询日志slow_query_log），超过我们标准的，就需要看 当前的业务 是否 有需要优化的必要（例如：一些不常用的功能）；

  而当时的这个 报表是我写的，因此让我去优化

- 问题定位

  

- 问题解决

- 由于财务部门和一些部门领导的需要月、季度、年等时间跨度的项目数据和成本数据的报表，用于做项项目进度分析、项目成本分析、季度考核和年度考核KPI等数据报告分析；

  所以报表分析具有 每月、每季度、每年的项目投入成本、项目阶段投入成本、部门人力成本等不同维度的报表数据（提供分析）

- 问题：

  - 由于需要展示很多统计信息，当时**考虑到项目开发时间限制**，我选择在DB端计算出结果直接展示，问题在于sum，max，min类的聚合函数在DB端执行会消耗到CPU资源，如果这个时候还遇到索引不合理的情况，往往会带来灾难性的后果。

    （统计例如：部门-项目成本维度的报表：由于员工具体薪资屏蔽，给的是等级薪资，还有就是每日工时不同，包含加班，请假等情况，有的部门有加班费，有的没有，所以需按照财务给的公式计算具体的成本结果）

  - 行转列的，动态项目、动态阶段展示

- 解决思路：这种情况DB端除了增加索引，对CPU的消耗是无法优化的，所以DB性能必然下降。一般这种情况分为2种：在程序端计算，再进行缓存结果，或者是在 sql 上操作，再进行缓存结果；

  由于在程序端计算的话，首先需要明细数据做基础，再进行分组计算，最后包装成所需要的格式输出（例如：行数据：项目；列数据：二级部门、项目耗时、项目直接成本等）；但是随着报告分析的时间跨度变长时，那么加载进内存的数据更多，计算时间也会增长（哪怕使用并行流计算，也会飙升CUP的）。
  
  最后采取类型数仓的思想，把大结果数据划分为粒度更小的结果（ 例如要获取年报告，就按月/周获取数据，而在mysql中获取每月/周的数据就很快，同时尽量建索引，查询明细数据是可以使用索引优化的 ），然后把结果集存放到redis缓存中（这里使用线程池定时运行sql，不采用Binlog，异步更新 Redis，成本高），后面每次获取数据时，只需要取出缓存中一个或者多个结果数据，使用parallelStream() 并行流在进行业务计算就好了，提高了效率。

------

### Redis

**设计技术：**基于Redis消息中间件，使用 Redis + Lua + AOP实现令牌桶限流和接口幂等性，限制高流量接口访问速率和重复消费的问题，提升了接口安全性；使用Redis 的 Hash 和 Sorted Set 实现项目进度周期功能；同时搭建Redis Sentinel确保服务高可用。

**解决过程：**

- **接口安全性**

  由于高流量 API 接口无法控制调用方的行为，因此当遇到瞬时请求量激增时，会导致接口占用过多服务器资源，使得其他请求响应速度降低或是超时，更有甚者可能导致服务器宕机。

  因此需要实现有效的限流方式，最常用的限流算法：固定窗口计数器；滑动窗口计数器；漏桶；令牌桶等

  而在考虑到限流的同时，接口调用也有可能重复提交的问题，例如：（在填写一些表格时候，用户填写完成提交，很多时候会因网络波动没有及时对用户做出提交成功响应，致使用户认为没有成功提交，然后一直点提交按钮，这时就会发生重复提交表单请求。）；

  首先针对限流这个问题，最适合的限流算法就是令牌桶算法。基于Redis消息中间件，使用 Redis + Lua + AOP实现令牌桶限流；对应用服务的请求进行限制，例如某一接口的请求限制为 100 个每秒,对超过限制的请求则进行快速失败或丢弃。可以方便地控制整个服务集群的请求限制，且由于整个集群的请求数量得到了限制，因此服务依赖的各种资源也得到了限流的保护。

  > - 令牌以固定速率生成；
  > - 生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃，当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行；
  > - 如果桶空了，那么尝试取令牌的请求会被直接丢弃。

  针对重复提交，使用 Redis + Lua 实现接口幂等性；使用幂等性最大的优势在于使接口保证任何幂等性操作，免去因重试等造成系统产生的未知的问题。

  > - ① 服务端提供获取 Token 的接口，该 Token 可以是一个序列号，也可以是一个分布式 ID 或者 UUID 串。
  >- ② 客户端调用接口获取 Token，这时候服务端会生成一个 Token 串。
  > - ③ 然后将该串存入 Redis 数据库中，以该 Token 作为 Redis 的键（注意设置过期时间）。
  > - ④ 将 Token 返回到客户端，客户端拿到后应存到表单隐藏域中。
  > - ⑤ 客户端在执行提交表单时，把 Token 存入到 Headers 中，执行业务请求带上该 Headers。
  > - ⑥ 服务端接收到请求后从 Headers 中拿到 Token，然后根据 Token 到 Redis 中查找该 key 是否存在。
  > - ⑦ 服务端根据 Redis 中是否存该 key 进行判断，如果存在就将该 key 删除，然后正常执行业务逻辑。如果不存在就抛异常，返回重复提交的错误信息。
  
- **使用Redis 的 Hash 和 Sorted Set 实现项目进度周期功能**

  场景：例如 需要查看某个项目的目前的进度情况（包含项目的完成阶段、关口；项目的阶段任务完成了哪些，那些项目成员完成的，以及完成的任务版本描述；还包含任务时间完成时间间隔及每个人员的工时投入等信息），所以，**这种数据的特点是，包含信息多，但是每个任务进度完成后是不可修改的（如果有问题的化，就需要返工，再次记录该阶段）**。由于有进度，可以以时间为序，可以使用 **Sorted Set 实现**；信息多，使用 **Hash** 结构存储；

  同时使用 Hash 和 Sorted Set，可以满足单个时间点和一个时间范围内的数据查询需求了，但是我们又会面临一个新的问题，也就是我们要解答的第二个问题：**如何保证写入 Hash 和 Sorted Set 是一个原子性的操作呢？**

  使用Lua 脚本

- **哨兵机制**

### 分布式事务

**设计技术：**基于RocketMQ支持消息事务这一特点，在项目开发过程中使用半消息事务这一特点，采用最大努力通知的分布式事务解决方案去处理分布式事务场景。

**解决过程：**基于项目的多个服务节点组成多个事务之间的事务一致性问题，无法避免分布式事务。而目前主流的分布式事务实现方案从类型上去分刚性事务、柔型事务；

刚性事务满足CAP的CP理论，要使分布式事务，达到像本地式事务一样，具备数据强一致性，从CAP来看，就是说，要达到CP状态。实现方案：XA 协议（2PC、JTA、JTS）、3PC

柔性事务满足BASE理论（基本可用，最终一致），最终一致性，实现补偿接口。柔性事务分为：补偿型、异步确保型、最大努力通知型。实现方案：TCC、Saga、本地事务消息、消息事务

经过我和同事商讨的结果就是，我们的业务更多的是倾向于数据结果的一致性（因为涉及到成本，所以需要准确的数据报告去分析），而为了保证消息的一致性投递，采用最大努力通知事务，基于MQ自身的事务消息方案，采用MQ的ack机制就可以实现最大努力通知。

步骤：

1. Rocket发送事务消息是二次提交的，第一次发送 半消息 提交到服务器时消息主题会替换为RMQ_SYS_TRANS_HALF_TOPIC。等到本地事务执行完毕以后才进行二次提交，这时会发送给原本消息的topic。

   由producer发送 半消息 给 MQ 的broker。MQ会把消息记录到本地，然后回复prepare消息状态给producer。半消息 消息发送以后获取发送状态，如果是成功则执行本地业务（本地事务）；

2. 执行本地事务；本地事务使用 @RocketMQTransactionListener 监听对应的 txProducerGroup，通过 executeLocalTransaction 执行相应的业务，执行成功就给MQ发送commit消息，执行失败就给MQ发送rollback消息；

3. 如果【执行本地事务】发生异常，checkLocalTransaction 回查本地事务，这个时候MQ的定时器会检查half消息。MQ回调方法，去检查本地事务的执行情况。如果执行成功，就返回commit消息。如果执行失败，就返回rollback消息。

   如果MQ收到的是commit消息，此时会把 半消息 消息复制到真正的topic中

4. 消费者对消息进行消费，

**使用过程中的问题**：

1. ##### 消息重复消费

   保证每条消息都有唯一编号且保证消息处理成功与去重表的日志同时出现；

   只要保持幂等性，不管来多少条重复消息，最后处理的结果都一样。就是利用一张日志表来记录已经处理成功的msgId，如果新到的msgId已经在日志表中，那么就不再处理这条消息。

2. **死信队列**

   在RocketMQ中，这种正常情况下无法被消费的消息被称为**死信消息**（Dead-Letter Message），存储死信消息的特殊队列称为**死信队列**（Dead-Letter Queue）。

   数据库宕机，消息无法正常处理，重试16次，进入死信队列；

   死信队列中的消息可以后台开一个线程，订阅`%DLQ%ConsumerGroup`，并不停重试

**扩展**：搭建多 master 模式


### JVM

**设计技术：**性能优化，在一次使用过程中，发现某个接口延时忽然很高，而且占用了大量的 CPU 资源。通过排查发现程序大量的 Full GC，为了减少对业务影响，直接将生产服务器上的项目进行重启。后续压测复现问题，定位并解决问题；最后复盘，并做出预警措施来预防后期可能出现的类似问题。

**解决过程（**问题&临时解决方案&定位问题&最终解决方案）：

> `常用命令`
>
> - **Jstat 命令**：查看堆内存各部分的使用量，加载类的数量以及GC的情况
> - **Jstack 命令**：主要是用来查看java线程的堆栈信息，分析线程有没有死锁，比如下面的这个两个线程互相等待对方释放锁而产生的死锁信息
> - **Jmap**：主要是用来dump java进程内存快照的，便于我们去分析内存中对象的存储情况

`案例说明`

> 正常情况下，我们生产环境都会配置监控措施，服务器资源比如CPU、内存的使用达到我们预设的报警阈值，就会触发报警，提示我们相应的维护人员，这时我们开发人员就需要快速定位原因，采取相应措施。
>
> - **问题**
>
>   项目上线试运行阶段（当时系统提前上线，主要给部门人员使用，有一个磨合的阶段；同时让他们测试系统功能以及提出自己的看法，有什么需要改进的方向；）
>
>   业务部门反馈程序用的十分卡，同时测试自己测的也十分卡，从ELK收集的请求日志发现确实存在问题，线上是两台部署：两台机器上都是，一次请求耗时由原来的几毫秒变为10几秒，同时伴随的其他现象还有 CPU跑的过高，当时是8核，CPU持续飙到200%+；
>
>   第一感觉存在代码死循环，或者请求线程太多。但试运行阶段这个时间点请求量很少，也没有修改过代码。
>
> - **临时解决方案**
>
>   领导来询问了情况；
>
>   当时为了减少业务人员对系统意见、以及业务操作的影响，直接将生产服务器上的项目进行重启
>
>   由于当时情况紧急，项目启动参数中没有设置（垃圾回收日志打印的文件、首次遭遇内存溢出时导出此时堆中相关信息、指定导出堆信息时的路径）这些配置信息，重启后出问题时项目的JVM信息丢失了
>
>   重启后，现象有所好转（但是只重启，指标不治本，如果没有定位到溢出的原因，重启一段时间可能又会溢出。）
>
> - **复现问题方式**
>
>   晚上加班，Jmeter持续(循环)压发消息接口10分钟，日志出现了问题
>
> - **定位问题**
>
>   top命令查看最耗CPU的进程
>
>   【top -Hp 17038】查看该进程中最耗CPU的线程(发现有 几个 线程占用CPU较高)
>
>   【printf '%x\n' 17045】将这几个线程的线程id分别转换成16进制
>
>   使用【jstack 17038 | grep -20 d70】命令查询该线程阻塞的地方。根据上面 线程的线程id在文件中查找线程日志
>
>   可以看到**最耗CPU的线程都是在进行GC**
>
>   【jmap -heap 17038】用Jmap命令查看当前堆的使用情况(发现老年代现在已占用99.8%+)（*# 其中17038为进程号*）
>
>   接着使用【jstat -gc 17038 5000】打印垃圾回收日志进行确认，发现jvm很短时间内进行了多次的FullGC操作，可以看出在频繁FullGC但是老年代有资源一直释放不掉（*# 其中17038为进程号,5000是指每5秒(5000毫秒)输出一次*）
>
>   只能使用【jmap -dump:file=dump.hprof 18713】强制进行一次内存dump。导出文件到本地目录，文件通常会很大。所以建议jvm堆内存上限不要设置的太大。否则内存分析工具分析也成问题。
>
> - **分析问题产生原因**
>
>   使用 JDK 自带的 **离线分析工具(VisualVM)**
>
>   发现有一个对象占用比较大，这两个类约占对象总数的**75%**（计算方式:5873361*2/14100000=83%）
>
>   问题原因：有一个静态集合类中持有对象的引用（并且该对象主要是用来做不同项目 在不同的阶段 的数据 统计、计算的，数据还是有一些大的），在使用完后未清空(只把对象设为null，而不是从集合中移除)，使JVM不能回收，即内存泄漏
>
> - **优化后再次进行验证**
>
>   修复代码之后，再次重启跑批，发现问题也得到了解决。优化前后接口吞吐量也提升10.5%
>
>   进行线上发布，观察一周后，对内存分析发现正常
>
> - **复盘总结**
>
>   分析和解决内存溢出相关问题的步骤，不是固定的，还需要根据实际情况去做调整，**止损是第一位的**，正常情况我们需要快速重启的先，重启可以使服务快速恢复，但是只重启，指标不治本，如果没有定位到溢出的原因，重启一段时间可能又会溢出。所以一定要留存排查依据，比如内存文件，线程的文件等。留存内存文件有两种方式：一是配置jvm启动参数: -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=xxxx(文件导出路径)，JVM发生OOM时，自动生成dump文件；二是采用jmap命令，手动进行内存dump。
>
>   - 程序预警：为减少业务影响，增加接口耗时的预警；实现方式： - 在每次程序处理完进行预警（比如本次请求>阈值）;缺点：消耗性能影响正常业务 - 在ELK清洗时用相关插件进行预警；优点：和业务解耦，对业务无影响
>
>   - 服务器预警：运维增加CPU内存，日志内存溢出监控

------

## 项目中常用的Linux命令

文件和目录常用命令及其详解

| 序号 | 命令                   | 作用                                       |
| ---- | ---------------------- | ------------------------------------------ |
| 3.1  | ls                     | 查看目录内容                               |
| 3.2  | cd [目录名]            | 进入目录                                   |
| 3.3  | touch [文件名]         | 创建文件                                   |
| 3.4  | mkdir [目录名]         | 创建目录                                   |
| 3.5  | rm [文件名]            | 删除文件或目录                             |
| 3.6  | tree [目录名]          | 以树状图列出文件目录结构                   |
| 3.7  | cp [源文件] [目标文件] | 拷贝                                       |
| 3.8  | mv [源文件] [目标文件] | 移动文件                                   |
| 3.9  | cat [文件名]           | 查看文件内容、创建文件、追加文件内容等功能 |
| 3.10 | more [文件名]          | 分屏显示文件内容                           |
| 3.11 | grep [word] [文件名]   | 在文件名中搜索word                         |
| 3.12 | >，>>                  | 重定向，请参照目录3.12                     |
| 3.13 | A\|B                   | 管道，将A命令的结果作为B命令的输入         |

————————————————

系统信息相关命令

| 序号 | 命令            | 作用                         |
| ---- | --------------- | ---------------------------- |
| 6.1  | date            | 查看系统时间                 |
| 6.2  | cal             | 查看日历                     |
| 6.3  | df              | 显示磁盘剩余空间             |
| 6.4  | ps              | 查看当前进程的详细状况       |
| 6.5  | top             | 动态显示运行中的进程并且排序 |
| 6.6  | kill [进程代号] | 终止指定代号的进程           |

## GIT常用操作和命令

> `工作流程下，每步操作对应的命令：`
>
> 1. 初始化仓库（或者检出仓库）
>
>    **git clone（git checkout test）**
>
> 2. 查看当前状态
>
>    **git status**
>
> 3. 将工作目录中修改的文件加入缓冲区（撤销加入缓冲区的文件）
>    git add（git reset filename）
>
> 4. 修改备注内容，提交到本地仓库
>
>    **git commit -m '备注'**
>
> 5. 拉取远程仓库（有冲突解决冲突）
>
>    git pull
>
> 6. 将本地仓库的改动提交到远程
>
>    **git push**
>
> 7. 查看当前的提交日志
>
>    **git log**
>
> ![img](D:/mmdz-blog/docs/Interview/git_imgs/20180912150918599.png)

------

## 项目中的设计模式

<!-- tabs:start -->

#### **模板方法**

在austin项目代码上用到模板方法的地方还是蛮多的，比较有代表性的就是**去重**的功能。老读者可能都知道，我认为去重的功能的核心无非是**唯一Key+存储**

模板方法模式要点：

1、把公共的代码抽取出来，如果该功能是不确定的，那我们将其修饰成抽象方法。

2、将几个固定步骤的功能封装到一个方法中，对外暴露这个方法，就可以非常方便调用了。



模板方法模式优点：**封装不变的部分，扩展可变的部分**。把认为是不变的部分的算法封装到父类，可变部分的交由子类来实现。

[模板方法](https://www.zhihu.com/search?q=模板方法&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A2490379356})模式缺点：抽象类定义了部分抽象方法，这些抽象的方法由子类来实现，子类执行的结果影响了父类的结果(**子类对父类产生了影响**)，会带来阅读代码的难度！

我们在实际写代码的时候，一般存储和和步骤都已经确认下来了，唯一Key则可以由子类实现

#### **French**

Bonjour!

<!-- tabs:end -->

## ELK

**ELK工作流程：**

> 一般都是再需要收集日志的服务上部署logstash，作为logstash shipper 用于监控并手机、过滤日志，接着，将过滤后的日志发送给broker,然后，logstash indexer将存放再broker中的数据再写入elasticsearch 、elasticsearch对这些数据创建索引，左后kibana对其进行各 种分析并以图表的形式展示。

![](project_imgs\501562b6bc28db6e63c699ed9e1e63f1.png)





------

## 场景题

### 多级缓存的实现思路

> 从用户请求数据到数据返回，数据经过了浏览器，CDN，代理服务器，应用服务器，以及数据库各个环节。每个环节都可以运用缓存技术。
>
> 从浏览器/客户端开始请求数据，通过 HTTP 配合 CDN 获取数据的变更情况，到达代理服务器（Nginx）可以通过反向代理获取静态资源。
>
> 再往下来到应用服务器可以通过进程内（堆内）缓存，分布式缓存等递进的方式获取数据。如果以上所有缓存都没有命中数据，才会回源到数据库。
>
> **缓存的请求顺序是：用户请求 → HTTP 缓存 → CDN 缓存 → 代理服务器缓存 → 进程内缓存 → 分布式缓存 → 数据库。**
>
> 1. 【HTTP缓存】：当用户通过浏览器请求服务器的时候，会发起 HTTP 请求，如果对每次 HTTP 请求进行缓存，那么可以减少应用服务器的压力。
>
>    当第一次请求的时候，浏览器本地缓存库没有缓存数据，会从服务器取数据，并且放到浏览器的缓存库中，下次再进行请求的时候会根据缓存的策略来读取本地或者服务的信息。
>
> 2. 【CDN 缓存】：CDN 的全称是 Content Delivery Network，即内容分发网络。主要是对静态数据进行缓存。（客户端发送 URL 给 DNS 服务器。DNS 通过域名解析，把请求指向 CDN 网络中的 DNS 负载均衡器。）
>
> 3. 【负载均衡缓存】：以 Nginx 为例，我们看看它是如何工作的：
>
>    用户请求在达到应用服务器之前，会先访问 Nginx 负载均衡器，如果发现有缓存信息，直接返回给用户。
>
>    如果没有发现缓存信息，Nginx 回源到应用服务器获取信息。
>
>    另外，有一个缓存更新服务，定期把应用服务器中相对稳定的信息更新到 Nginx 本地缓存中。
>
> 4. 【进程内缓存】：
>
>    进程内缓存又叫托管堆缓存，以 Java 为例，这部分缓存放在 JVM 的托管堆上面，同时会受到托管堆回收算法的影响。
>
>    由于其运行在内存中，对数据的响应速度很快，通常我们会把热点数据放在这里。
>
>    目前比较流行的实现有 Ehcache、GuavaCache、Caffeine。这些架构可以很方便的把一些热点数据放到进程内的缓存中。
>
> 5. 【分布式缓存】：Redis
>
> 6. 【数据库】

### 实现微博热搜榜

> 可以使用**Redis的有序集合ZSET**来实现，搜索榜其实主要分为两步：
>
> - 保存搜索词，将搜索词保存到redis的同时需要给他一个分值，如果是同一个搜索词分值加一，另外搜索榜一般都是当日的不像微博那么多人使用可以是每个小时的，所以我们要设计一个统一过期时间，这里我设置的是当日晚上十二点
> - 获取搜索词，我们只需要获取搜索词的前五位获取前十位就可以了，同时我们也要获取他的分值也就是搜索次数

### 系统需求多变，你如何设计？

> **面试官**：我想问个问题哈，项目里比较常见的问题
>
> **面试官**：**我现在有个系统会根据请求的入参，做出不同动作。但是，这块不同的动作很有可能是会发生需求变动的，这块系统你会怎么样设计？**
>
> **面试官**：**实际的例子：现在有多个第三方渠道，系统需要对各种渠道进行订单归因。但是归因的逻辑很有可能会发生变化，不同的渠道归因的逻辑也不太一样，此时系统里的逻辑相对比较复杂。**
>
> **面试官**：**如果让你优化，你会怎么设计？**
>
> ------
>
> **候选者**：归根到底，就是处理的逻辑相对复杂，if else的判断太多了
>
> **候选者**：虽然新的需求来了，都可以添加if else进行解决
>
> **候选者**：但你想要的就是，系统的可扩展性和可维护性更强
>
> **候选者**：想要我这边出一个方案，来解决类似的问题
>
> **候选者**：对吧？
>
> **面试官**：嗯…
