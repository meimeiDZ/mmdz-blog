# MySQL

# 《对线面试官》 MySQL 索引

**面试官**：**我看你简历上写了MySQL，对MySQL InnoDB引擎的索引了解吗？**

> **候选者**：嗯啊，使用索引可以加快查询速度，其实上就是将无序的数据变成有序（有序就能加快检索速度）
>
> **候选者**：在InnoDB引擎中，索引的底层数据结构是B+树

**面试官**：**那为什么不使用红黑树或者B树呢？**

> **候选者**：MySQL的数据是存储在硬盘的，在查询时一般是不能「一次性」把全部数据加载到内存中
>
> **候选者**：红黑树是「二叉查找树」的变种，一个Node节点只能存储一个Key和一个Value
>
> **候选者**：B和B+树跟红黑树不一样，它们算是「多路搜索树」，相较于「二叉搜索树」而言，一个Node节点可以存储的信息会更多，「多路搜索树」的高度会比「二叉搜索树」更低。
>
> **候选者**：了解了区别之后，其实就很容易发现，在数据不能一次加载至内存的场景下，数据需要被检索出来，选择B或B+树的理由就很充分了（一个Node节点存储信息更多（相较于二叉搜索树），树的高度更低，树的高度影响检索的速度）
>
> **候选者**：B+树相对于B树而言，它又有两种特性。
>
> **候选者**：一、B+树非叶子节点不存储数据，在相同的数据量下，B+树更加矮壮。（这个应该不用多解释了，数据都存储在叶子节点上，非叶子节点的存储能存储更多的索引，所以整棵树就更加矮壮）
>
> **候选者**：二、B+树叶子节点之间组成一个链表，方便于遍历查询（遍历操作在MySQL中比较常见）
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbicmaLKV1XausXay56RtYQOpm2ic2Gd9hgwkCRTwd2ACtlRqu3uS23JkW4rHJEAiaawd8qFOZTniaUqQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：我稍微解释一下吧，你可以脑补下画面
>
> **候选者**：我们在MySQL InnoDB引擎下，每创建一个索引，相当于生成了一颗B+树。
>
> **候选者**：如果该索引是「聚集(聚簇)索引」，那当前B+树的叶子节点存储着「主键和当前行的数据」
>
> **候选者**：如果该索引是「非聚簇索引」，那当前B+树的叶子节点存储着「主键和当前索引列值」
>
> **候选者**：比如写了一句sql：select * from user where id >=10，那只要定位到id为10的记录，然后在叶子节点之间通过遍历链表(叶子节点组成的链表)，即可找到往后的记录了。
>
> **候选者**：由于B树是会在非叶子节点也存储数据，要遍历的时候可能就得跨层检索，相对麻烦些。
>
> **候选者**：基于树的层级以及业务使用场景的特性，所以MySQL选择了B+树作为索引的底层数据结构。
>
> **候选者**：对于哈希结构，其实InnoDB引擎是「自适应」哈希索引的（hash索引的创建由InnoDB存储引擎引擎自动优化创建，我们是干预不了）

**面试官**：嗯…**那我了解了，顺便想问下，你知道什么叫做回表吗？**

> **候选者**：所谓的回表其实就是，当我们使用索引查询数据时，检索出来的数据可能包含其他列，但走的索引树叶子节点只能查到当前列值以及主键ID，所以需要根据主键ID再去查一遍数据，得到SQL 所需的列
>
> **候选者**：举个例子，我这边建了给订单号ID建了个索引，但我的SQL 是：select orderId,orderName from orderdetail where orderId = 123
>
> **候选者**：SQL都订单ID索引，但在订单ID的索引树的叶子节点只有orderId和Id，而我们还想检索出orderName，所以MySQL 会拿到ID再去查出orderName给我们返回，这种操作就叫回表
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbicmaLKV1XausXay56RtYQOdym1gY4RCuOY8djlNsc8icbzQwZuPvqbQiciaTb43f0Jic8VFC0m6Z4I0g/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：想要避免回表，也可以使用覆盖索引（能使用就使用，因为避免了回表操作）。
>
> **候选者**：所谓的覆盖索引，实际上就是你想要查出的列刚好在叶子节点上都存在，比如我建了orderId和orderName联合索引，刚好我需要查询也是orderId和orderName，这些数据都存在索引树的叶子节点上，就不需要回表操作了。

**面试官**：**既然你也提到了联合索引，我想问下你了解最左匹配原则吗？**

> **候选者**：嗯，说明这个概念，还是举例子比较容易说明
>
> **候选者**：如有索引 (a,b,c,d)，查询条件 a=1 and b=2 and c>3 and d=4，则会在每个节点依次命中a、b、c，无法命中d
>
> **候选者**：先匹配最左边的，索引只能用于查找key是否存在（相等），遇到范围查询 (>、<、between、like左匹配)等就不能进一步匹配了，后续退化为线性查找
>
> **候选者**：这就是最左匹配原则
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbicmaLKV1XausXay56RtYQOhtwEXwIaj9TkwEFOtzHE4wfyiaRoYsXV4q2SCuo7OFwvqLbiaKxcT4WQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**面试官**：**嗯嗯，我还想问下你们主键是怎么生成的？**

**候选者**：主键就自增的

**面试官**：**那假设我不用MySQL自增的主键，你觉得会有什么问题呢？**

> **候选者**：首先主键得保证它的唯一性和空间尽可能短吧，这两块是需要考虑的。
>
> **候选者**：另外，由于索引的特性（有序），如果生成像uuid类似的主键，那插入的的性能是比自增的要差的
>
> **候选者**：因为生成的uuid，在插入时有可能需要移动磁盘块（比如，块内的空间在当前时刻已经存储满了，但新生成的uuid需要插入已满的块内，就需要移动块的数据）

**面试官**：OK…

![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKbicmaLKV1XausXay56RtYQOVCd2ZV0cUVToEhxgqichPwjhKTaLVNapdlWWYc5ABOibHVTnSfBibZRGQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

------

# 《对线面试官》 MySQL 事务、锁和MVCC

**面试官**：**你是怎么理解InnoDB引擎中的事务的？**

> **候选者**：在我的理解下，事务可以使「一组操作」要么全部成功，要么全部失败
>
> **候选者**：事务其目的是为了「保证数据最终的一致性」。
>
> **候选者**：举个例子，我给你发支付宝转了888块红包。那自然我的支付宝余额会扣减888块，你的支付宝余额会增加888块。
>
> **候选者**：而事务就是保证我的余额扣减跟你的余额增添是同时成功或者同时失败的，这样这次转账就正常了
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkAKxJTaBtVe32xiaymVw7CicBdluWTibIas5LQJBLTygC7Js99TQ5Ot40w/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**面试官**：**嗯，那你了解事务的几大特性吗？**

> **候选者**：嗯，就是ACID嘛，分别是原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。
>
> **候选者**：原子性指的是：当前事务的操作要么同时成功，要么同时失败。原子性由undo log日志来保证，因为undo log记载着数据修改前的信息。
>
> **候选者**：比如我们要 insert 一条数据了，那undo log 会记录的一条对应的 delete 日志。我们要 update 一条记录时，那undo log会记录之前的「旧值」的update记录。
>
> **候选者**：如果执行事务过程中出现异常的情况，那执行「回滚」。InnoDB引擎就是利用undo log记录下的数据，来将数据「恢复」到事务开始之前
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkE8pqn1s3E9Nqboh0Xib3JiaPzgKgC2Ixsasvgfr23DTxF4QbLld1iaNrg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：一致性我稍稍往后讲，我先来说下隔离性
>
> **面试官**：嗯…
>
> **候选者**：隔离性指的是：在事务「并发」执行时，他们内部的操作不能互相干扰。如果多个事务可以同时操作一个数据，那么就会产生脏读、重复读、幻读的问题。
>
> **候选者**：于是，事务与事务之间需要存在「一定」的隔离。在InnoDB引擎中，定义了四种隔离级别供我们使用：
>
> **候选者**：分别是：read uncommit(读未提交)、read commit (读已提交)、repeatable read (可重复复读)、serializable (串行)
>
> **候选者**：不同的隔离级别对事务之间的隔离性是不一样的（级别越高事务隔离性越好，但性能就越低），而隔离性是由MySQL的各种锁来实现的，只是它屏蔽了加锁的细节。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkIG6KWgbuVZbp7natNMTI3cqVtZL81micdZsJDBANGgCtaJniaRS8kzpA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：持久性指的就是：一旦提交了事务，它对数据库的改变就应该是永久性的。说白了就是，会将数据持久化在硬盘上。
>
> **候选者**：而持久性由redo log 日志来保证，当我们要修改数据时，MySQL是先把这条记录所在的「页」找到，然后把该页加载到内存中，将对应记录进行修改。
>
> **候选者**：为了防止内存修改完了，MySQL就挂掉了（如果内存改完，直接挂掉，那这次的修改相当于就丢失了）。
>
> **候选者**：MySQL引入了redo log，内存写完了，然后会写一份redo log，这份redo log记载着这次在某个页上做了什么修改。
>
> **候选者**：即便MySQL在中途挂了，我们还可以根据redo log来对数据进行恢复。
>
> **候选者**：redo log 是顺序写的，写入速度很快。并且它记录的是物理修改（xxxx页做了xxx修改），文件的体积很小，恢复速度也很快。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkAnSl1ahVTEJY1DficWiay2jZlunDPBUPaNwpuwq5dNico1X1IyjIMvlTg/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：回头再来讲一致性，「一致性」可以理解为我们使用事务的「目的」，而「隔离性」「原子性」「持久性」均是为了保障「一致性」的手段，保证一致性需要由应用程序代码来保证
>
> **候选者**：比如，如果事务在发生的过程中，出现了异常情况，此时你就得回滚事务，而不是强行提交事务来导致数据不一致。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkABXmN47ySQxgF0ReESdl5KuQE4GRreYRebJqoOVzKibrvPlAtvBicia5A/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)

**面试官**：嗯，挺好的，讲了蛮多的

**面试官**：刚才你也提到了隔离性嘛，**然后你说在MySQL中有四种隔离级别，能分别来介绍下吗？**

> **候选者**：嗯，为了讲清楚隔离级别，我顺带来说下MySQL锁相关的知识吧。
>
> **候选者**：在InnoDB引擎下，按锁的粒度分类，可以简单分为行锁和表锁。
>
> **候选者**：行锁实际上是作用在索引之上的（索引上次已经说过了，这里就不赘述了）。当我们的SQL命中了索引，那锁住的就是命中条件内的索引节点（这种就是行锁），如果没有命中索引，那我们锁的就是整个索引树（表锁）。
>
> **候选者**：简单来说就是：锁住的是整棵树还是某几个节点，完全取决于SQL条件是否有命中到对应的索引节点。
>
> **候选者**：而行锁又可以简单分为读锁（共享锁、S锁）和写锁（排它锁、X锁）。
>
> **候选者**：读锁是共享的，多个事务可以同时读取同一个资源，但不允许其他事务修改。写锁是排他的，写锁会阻塞其他的写锁和读锁。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkHcnHuT3go1n2Dvs3KmPHUUx5sxwHgULpeIZvob8K9Rhdy27XtmSRtA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：我现在就再回到隔离级别上吧，就直接以例子来说明啦。
>
> **面试官**：嗯…
>
> **候选者**：首先来说下read uncommit(读未提交)。比如说：A向B转账，A执行了转账语句，但A还没有提交事务，B读取数据，发现自己账户钱变多了！B跟A说，我已经收到钱了。A回滚事务【rollback】，等B再查看账户的钱时，发现钱并没有多。
>
> **候选者**：简单的定义就是：事务B读取到了事务A还没提交的数据，这种用专业术语来说叫做「脏读」。
>
> **候选者**：对于锁的维度而言，其实就是在read uncommit隔离级别下，读不会加任何锁，而写会加排他锁。读什么锁都不加，这就让排他锁无法排它了。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkdaMujEgBNL1IuqNwaBBNazBxV91cu0ZqSBVOz7Ea87RNa5ywfCcEvA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：而我们又知道，对于更新操作而言，InnoDB是肯定会加写锁的（数据库是不可能允许在同一时间，更新同一条记录的）。而读操作，如果不加任何锁，那就会造成上面的脏读。
>
> **候选者**：脏读在生产环境下肯定是无法接受的，那如果读加锁的话，那意味着：当更新数据的时，就没办法读取了，这会极大地降低数据库性能。
>
> **候选者**：在MySQL InnoDB引擎层面，又有新的解决方案（解决加锁后读写性能问题），叫做MVCC(Multi-Version Concurrency Control)多版本并发控制
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkMxJcNgibZnuFibEHo4FeGPNvTHyZWmrCXgvKMo39VY5ZlSibQqTVEhKTQ/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：在MVCC下，就可以做到读写不阻塞，且避免了类似脏读这样的问题。那MVCC是怎么做的呢？
>
> **候选者**：MVCC通过生成数据快照（Snapshot)，并用这个快照来提供一定级别（语句级或事务级）的一致性读取
>
> **候选者**：回到事务隔离级别下，针对于 read commit (读已提交) 隔离级别，它生成的就是语句级快照，而针对于repeatable read (可重复读)，它生成的就是事务级的快照。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkhUaj9HkfofHuvuRMJtMIqVBickM84E7jL3McmTDYnCYbOyK85LJhV5g/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：前面提到过read uncommit隔离级别下会产生脏读，而read commit (读已提交) 隔离级别解决了脏读。思想其实很简单：在读取的时候生成一个”版本号”，等到其他事务commit了之后，才会读取最新已commit的”版本号”数据。
>
> **候选者**：比如说：事务A读取了记录(生成版本号)，事务B修改了记录(此时加了写锁)，事务A再读取的时候，是依据最新的版本号来读取的(当事务B执行commit了之后，会生成一个新的版本号)，如果事务B还没有commit，那事务A读取的还是之前版本号的数据。
>
> **候选者**：通过「版本」的概念，这样就解决了脏读的问题，而「版本」其实就是对应快照的数据。
>
> **候选者**：read commit (读已提交) 解决了脏读，但也会有其他并发的问题。「不可重复读」：一个事务读取到另外一个事务已经提交的数据，也就是说一个事务可以看到其他事务所做的修改。
>
> **候选者**：不可重复读的例子：A查询数据库得到数据，B去修改数据库的数据，导致A多次查询数据库的结果都不一样【危害：A每次查询的结果都是受B的影响的】
>
> **候选者**：了解MVCC基础之后，就很容易想到repeatable read (可重复复读)隔离级别是怎么避免不可重复读的问题了（前面也提到了）。
>
> **候选者**：repeatable read (可重复复读)隔离级别是「事务级别」的快照！每次读取的都是「当前事务的版本」，即使当前数据被其他事务修改了(commit)，也只会读取当前事务版本的数据。
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkGek0TdDYQVwBNo1F7LdqKMTvfXjAVbRSyib2MBM6xsic6E0fDeV7JOPA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：而repeatable read (可重复复读)隔离级别会存在幻读的问题，「幻读」指的是指在一个事务内读取到了别的事务插入的数据，导致前后读取不一致。
>
> **候选者**：在InnoDB引擎下的的repeatable read (可重复复读)隔离级别下，快照读MVCC影响下，已经解决了幻读的问题（因为它是读历史版本的数据）
>
> **候选者**：而如果是当前读（指的是 select * from table for update），则需要配合间隙锁来解决幻读的问题。
>
> **候选者**：剩下的就是serializable (串行)隔离级别了，它的最高的隔离级别，相当于不允许事务的并发，事务与事务之间执行是串行的，它的效率最低，但同时也是最安全的。

**面试官**：嗯，可以的。**我看你提到了MVCC了，不妨来说下他的原理？**

> **候选者**：MVCC的主要是通过read view和undo log来实现的
>
> ![图片](https://mmbiz.qpic.cn/mmbiz_jpg/E44aHibktsKa23y7eBdg7ZkHNEoIDMgVkcZbr7670ibA1w8icW2bjgpcjyewAD2a5a7yWhK2F50RNicnSNvGOnahvA/640?wx_fmt=jpeg&wxfrom=5&wx_lazy=1&wx_co=1)
>
> **候选者**：undo log前面也提到了，它会记录修改数据之前的信息，事务中的原子性就是通过undo log来实现的。所以，有undo log可以帮我们找到「版本」的数据
>
> **候选者**：而read view 实际上就是在查询时，InnoDB会生成一个read view，read view 有几个重要的字段，分别是：trx_ids（尚未提交commit的事务版本号集合），up_limit_id（下一次要生成的事务ID值），low_limit_id（尚未提交版本号的事务ID最小值）以及creator_trx_id（当前的事务版本号）
>
> **候选者**：在每行数据有两列隐藏的字段，分别是DB_TRX_ID（记录着当前ID）以及DB_ROLL_PTR（指向上一个版本数据在undo log 里的位置指针）
>
> **候选者**：铺垫到这了，很容易就发现，MVCC其实就是靠「比对版本」来实现读写不阻塞，而版本的数据存在于undo log中。
>
> **候选者**：而针对于不同的隔离级别（read commit和repeatable read），无非就是read commit隔离级别下，每次都获取一个新的read view，repeatable read隔离级别则每次事务只获取一个read view

**面试官**：嗯，OK的。细节就不考究了，今天就到这里吧。

------

# 【对线面试官】MySQL调优

?>**MySql的执行顺序：** FROM->JOIN->ON->WHERE->GROUP BY->HAVING->SELECT->DISTINCT->ORDER BY->LIMIT

**面试官**：**你们对MySQL怎么调优的**

> **候选者**：sql 优化可以从 硬件、系统配置、数据库表结构、SQL及索引 这几个方面优化（然而实际上我们只能决定 数据库表结构、SQL及索引 的优化，有可能 数据库表结构 我们也没权限）
>
> **候选者**：对于开发者而言，对MySQL的调优重点一般是【开发规范】【数据库索引】又或者说解决线上慢查询
>
> **候选者**：首先从【开发规范】【数据库索引】开始
>
> **候选者**：首先在开发环境下，创建数据库表（有DBA的话可能需要审批，没有的话 根据公司的开发规范与自己平时积累的经验来 创建）；我们要有创建索引的习惯，其次 设置合理的字段类型，尽量让 字段存储空间小，可以节省存储空间，减少磁盘IO（注意设置字符集，不同表的字符集不同，也会引起慢SQL查询）
>
> 例如：
>
> - 尽量使用数字型字段
>
>   尽量使用数字型字段（如性别，男：1 女：2），若只含数值信息的字段尽量不要设计为字符型，这会降低查询和连接的性能，并会增加存储开销。
>   这是因为引擎在处理查询和连接时会 逐个比较字符串中每一个字符，而对于数字型而言只需要比较一次就够了。
>
> - 用varchar/nvarchar 代替 char/nchar
>
>   尽可能的使用 varchar/nvarchar 代替 char/nchar ，因为首先变长字段存储空间小，可以节省存储空间，其次对于查询来说，在一个相对较小的字段内搜索效率显然要高些。
>   不要以为 NULL 不需要空间，比如：char(100) 型，在字段建立时，空间就固定了， 不管是否插入值（NULL也包含在内），都是占用 100个字符的空间的，如果是varchar这样的变长字段， null 不占用空间。
>
> **候选者**：【数据库索引】
>
> **候选者**：是否能使用【覆盖索引】/【联合索引】，减少【回表】所消耗的时间，并且MySQL5.6对非聚簇索引提供的一项索引优化功能【索引下推】，可以在非聚簇索引遍历过程中，对索引中包含的字段先做判断，过滤掉不符合条件的记录，减少回表次数。意味着，我们在 select 的时候，一定要指明对应的列，而不是 select *；【准守最左匹配原则】
>
> **候选者**：考虑组建【覆盖索引】/【联合索引】或者是其它的索引时，尽量选择合适的字段
>
> - **非空字段**：在mysql中，含有空值的列很难进行查询优化，因为它们使得索引、索引的统计信息以及比较运算更加复杂。你应该用0、一个特殊的值或者一个空串代替空值；
> - **取值离散大的字段**：返回值越大说明字段的唯一值越多字段的离散程度高；
> - **索引字段越小越好**：数据库的数据存储以页为单位一页存储的数据越多一次IO操作获取的数据越大效率越高。
> - 频繁查询、排序、表连接……字段
>
> **候选者**：【SQL 写法上】通过索引访问（尽可能的不让索引失效）
>
> - **不要在索引上进行任何操作;（在索引列上进行计算、函数、类型转换等操作）**
> - **查询条件中使用 or，且 or 的前后条件中有一个列没有索引，涉及的索引都不会被使用到;**
> - **复合索引不能使用不等于（!= <>）或 is null (is not null)，否则自身以及右侧所有全部失效**
> - 尽量不要使用类型转换（显示、隐式），否则索引失效
> - **以 % 开头的 LIKE 查询比如 `like '%abc';`;**
>
> **候选者**：【减少交互次数】批量DML操作，函数存储等减少数据连接次数
>
> **候选者**：`最主要还是要通过 explain 命令来查看 SQL 的执行计划，看看自己写的 SQL 是否走索引，走什么索引。通过 show profile 来查看 SQL 对资源损耗情况（用的比较少）`
>
> **候选者**：在开启事务后，在事务内尽可能只操作数据库，并有意识的减少锁的持有时间（比如在事务内需要插入&&修改数据，那可以先插入后修改。因为修改是更新操作，会加行锁。如果先更新，那并发下可能会导致多个事务的请求等待行锁释放）

**面试官**：**你们线上使用的什么隔离级别**

> **候选者**：REPEATABLE READ
>
> **候选者**：问题
>
> - 可能因为【间隙锁】导致死锁的问题（解决：软删除）
>
> - 解决了【主从不一致】问题
>
>   **问题：**在mysql5.0以前binlog只支持statement这种格式，这种格式在读已提交（read commited）这个隔离级别下主从复制是有bug的。
>
>   产生bug的原因：在主库上面执行先删除后插入，但是在从库如果binlog为statement格式，记录的顺序就是先插入后删除，从库执行的顺序和主库不一致，最后主库有数据，从库的数据被删掉了。
>
>   **解决：**将binlog_format设置为row格式，基于行的复制，就不会出现sql执行顺序不一样的问题。但是这个格式是mysql5.1以后才有的。由于历史的原因，mysql将默认的隔离级别设置为可重复读，并一直延续了下来，保证主从复制不出问题。

**面试官**：**解决线上慢查询**

> **候选者**：
>
> - 分析语句，是否加载了不必要的字段/数据
> - 分析 SQL 执行句话，是否命中索引等
>
> **候选者**：如果走对了索引，但查询还是很慢，那一般来说就是表的数据量太大了
>
> - 首先，考虑能不能把【旧的数据】给 ”删掉“ ；如果这些【旧的数据】已经没有查询的业务了，那最简单的方法肯定就是”删掉“部分数据了。数据量降低了，那检索的速度就很快了；【但是一般是不会删掉的】
>
>   所以可以考虑做【离线数据】，把数据同步到 Hive 离线存储。
>
> - 随后，就可以考虑走缓存（Redis）；而走缓存的话，又要看业务能不能忍受【数据的非实时性】（毕竟Redis和MySQL的数据一致性需要保证），如果查询条件 复杂且多变的话（涉及各种group by和sum），那么走缓存 可能也不是 一个好的办法，维护起来就不方便了。
>
> - 再看看是不是有【字符串】检索的场景导致查询低效，如果是的话，可以考虑把表的数据导入至Elasticsearch的搜索引擎，后续线上查询就直接走ES。（但是需要增加 MySQL -> ES 需要对应的同步程序，一般就是监听MySQL的binlog，解析binlog后导入ES）
>
> - 还可以考虑根据查询条件的维度，做相应的聚合表，线上的请求就查询聚合表的数据，不走原表。
>
>   比如：有一份订单明细，而该订单明细表的数据量很大。但实际上 用户在页面上只关心 以天为维度的 数据信息。所以 就可以将 每个用户 每天的数据 聚合起来，汇总成一条数据。查询走聚合后的表，那速度肯定杠杠的。
>
>   【思路大致就是 `以空间换时间`，相同的数据换别的地方页存储一份，提高查询效率】
>
> - 最后就是【分库分表】；而【分库分表】的代价时比较大的；`例如：`
>
>   - 分库分表键
>   - 分库分表ID
>   - 数据迁移
>   - 后期扩容
>   - 业务上的统计查询、排序……

**分库分表键**：【主要按照业务来】，按照我们这边来说，一般来说时按照 userId 的（因为按照用户的维度查询比较多）/也有按照 时间 的（这个一般是做 时间跨度统计、计算的）

**分库分表ID**：

- （在分布式的环境下必须【全局且唯一】 。

- 一般都需【要单调递增】，因为一般唯一ID都 会存到数据库，而 innodb 的特性就是将内容存储在主键索引树上的叶子节点而且是从左往右，递增的，所以考虑到数据库性能，一般生成的 id 也最好是单调递增。）

  涉及到分布式ID生成的方式了，思路有很多，有 MySQL 自增，Redis 自增，【雪花算法】自增；

**数据迁移**：一般采取【同步双写】的方式，大致步骤

1. 增量的消息各自往新表和旧表写一份
2. 将旧表的数据迁移至新库
3. 迟早新表的数据会 超过 旧表
4. 校验 新表和旧表 的数据是否正常
5. 开启双读（一部分流量走新表，一部分走老表）这里最好采用灰度的方式来切换，比如开始切换 10% 的流量，如果没有问题再切换到 50% 的流量，最后再切换到 100%。
6. 读流量全部更新至新表，就停止老表的写入
7. 另外，提前准备回滚机制，防止 因为切换失败而影响业务正常运行的程序



**雪花算法**

![](mysql_imgs\20201004105635931.png)
